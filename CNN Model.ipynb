{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3 Final CNN model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sDj7Dd2Xtjk",
        "colab_type": "code",
        "outputId": "7c0e561e-47c0-42e7-e66a-51352d7ef554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Mounting the Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO26r4EtEFKP",
        "colab_type": "code",
        "outputId": "ac2227dc-21f7-4598-da83-9c560769ea48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/657A3part2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/657A3part2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDZc2scOEzmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading basic Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLtDmaQHE4C4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting basic data in correct format to process\n",
        "fea = []\n",
        "for i in range(1,785):\n",
        "  fea.append(str(i))\n",
        "X = pd.read_csv('train.csv', usecols = fea)\n",
        "y = pd.read_csv('train.csv', usecols= ['Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqOHMDa-S_xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the Dataset into training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.1,random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtfaO_geV2k8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting Dataframe to Numpy array\n",
        "X_train =np.array(X_train, dtype ='float32')\n",
        "X_test =np.array(X_test,dtype ='float32')\n",
        "y_train =np.array(y_train,dtype ='float32')\n",
        "y_test =np.array(y_test,dtype ='float32')\n",
        "X = np.array(X, dtype ='float32')\n",
        "y = np.array(y, dtype ='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPWPtrfQVG8D",
        "colab_type": "code",
        "outputId": "51c7b8f6-0da6-41d3-8577-f6562fa8c91a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# lets see how an image looks like in training data\n",
        "import random\n",
        "i=random.randint(1,54000)\n",
        "plt.imshow(X_train[i,:].reshape(28,28))\n",
        "label=y_train[i,0]\n",
        "label"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qhn-5RgXLAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocessing the Data before fitting to the model (all pixels are brought to same range i.e. all values lie between 0 and 1 now)\n",
        "X_train =X_train.reshape(X_train.shape[0],*(28,28,1))\n",
        "X_test = X_test.reshape(X_test.shape[0],*(28,28,1))\n",
        "X_train=X_train[:,:]/255\n",
        "X_test= X_test[:,:]/255\n",
        "X =X.reshape(X.shape[0],*(28,28,1))\n",
        "X= X[:,:]/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIf5v42EYtDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout,BatchNormalization, Activation, add, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvkjeBscoqwB",
        "colab_type": "code",
        "outputId": "99b16634-d6a8-4093-b8a7-564ac54cc070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "image_rows = 28\n",
        "\n",
        "image_cols = 28\n",
        "\n",
        "batch_size = 512\n",
        "image_shape = (image_rows,image_cols,1)\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(filters=32,kernel_size=5,activation='relu',padding='same',input_shape = image_shape),\n",
        "    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n",
        "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same'),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Conv2D(filters=128,kernel_size=1,activation='relu',padding='same'),\n",
        "    Dropout(0.2),\n",
        "    Flatten(), # 1flatten out the layers\n",
        "    Dense(1024,activation='relu'),\n",
        "    Dropout(0.25),\n",
        "    Dense(32,activation='relu'),\n",
        "    Dense(5,activation = 'softmax')\n",
        "])\n",
        "cnn_model.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0001),metrics =['accuracy'])\n",
        "history = cnn_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=1024,\n",
        "    epochs=400,\n",
        "    verbose=1,\n",
        "    validation_data=(X_test,y_test)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.2046 - accuracy: 0.4687 - val_loss: 0.8790 - val_accuracy: 0.6242\n",
            "Epoch 2/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.7892 - accuracy: 0.6653 - val_loss: 0.6768 - val_accuracy: 0.7218\n",
            "Epoch 3/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6527 - accuracy: 0.7307 - val_loss: 0.5810 - val_accuracy: 0.7627\n",
            "Epoch 4/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5757 - accuracy: 0.7653 - val_loss: 0.5265 - val_accuracy: 0.7908\n",
            "Epoch 5/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5307 - accuracy: 0.7853 - val_loss: 0.4899 - val_accuracy: 0.8052\n",
            "Epoch 6/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5002 - accuracy: 0.7993 - val_loss: 0.4739 - val_accuracy: 0.8092\n",
            "Epoch 7/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4741 - accuracy: 0.8103 - val_loss: 0.4525 - val_accuracy: 0.8183\n",
            "Epoch 8/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4652 - accuracy: 0.8145 - val_loss: 0.4276 - val_accuracy: 0.8330\n",
            "Epoch 9/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4429 - accuracy: 0.8263 - val_loss: 0.4117 - val_accuracy: 0.8375\n",
            "Epoch 10/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.4281 - accuracy: 0.8314 - val_loss: 0.4080 - val_accuracy: 0.8353\n",
            "Epoch 11/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.4196 - accuracy: 0.8342 - val_loss: 0.4152 - val_accuracy: 0.8342\n",
            "Epoch 12/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4080 - accuracy: 0.8393 - val_loss: 0.3898 - val_accuracy: 0.8450\n",
            "Epoch 13/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3984 - accuracy: 0.8415 - val_loss: 0.3754 - val_accuracy: 0.8480\n",
            "Epoch 14/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3880 - accuracy: 0.8469 - val_loss: 0.3698 - val_accuracy: 0.8505\n",
            "Epoch 15/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3795 - accuracy: 0.8508 - val_loss: 0.3630 - val_accuracy: 0.8563\n",
            "Epoch 16/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3749 - accuracy: 0.8529 - val_loss: 0.3567 - val_accuracy: 0.8562\n",
            "Epoch 17/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3661 - accuracy: 0.8555 - val_loss: 0.3548 - val_accuracy: 0.8563\n",
            "Epoch 18/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3603 - accuracy: 0.8588 - val_loss: 0.3439 - val_accuracy: 0.8622\n",
            "Epoch 19/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3557 - accuracy: 0.8593 - val_loss: 0.3425 - val_accuracy: 0.8638\n",
            "Epoch 20/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3562 - accuracy: 0.8588 - val_loss: 0.3423 - val_accuracy: 0.8618\n",
            "Epoch 21/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3451 - accuracy: 0.8629 - val_loss: 0.3310 - val_accuracy: 0.8690\n",
            "Epoch 22/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3384 - accuracy: 0.8666 - val_loss: 0.3255 - val_accuracy: 0.8700\n",
            "Epoch 23/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3346 - accuracy: 0.8685 - val_loss: 0.3256 - val_accuracy: 0.8690\n",
            "Epoch 24/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3291 - accuracy: 0.8692 - val_loss: 0.3244 - val_accuracy: 0.8688\n",
            "Epoch 25/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3263 - accuracy: 0.8715 - val_loss: 0.3200 - val_accuracy: 0.8703\n",
            "Epoch 26/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3231 - accuracy: 0.8729 - val_loss: 0.3163 - val_accuracy: 0.8732\n",
            "Epoch 27/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3189 - accuracy: 0.8749 - val_loss: 0.3098 - val_accuracy: 0.8780\n",
            "Epoch 28/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3167 - accuracy: 0.8749 - val_loss: 0.3098 - val_accuracy: 0.8777\n",
            "Epoch 29/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3149 - accuracy: 0.8761 - val_loss: 0.3048 - val_accuracy: 0.8812\n",
            "Epoch 30/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3106 - accuracy: 0.8773 - val_loss: 0.3006 - val_accuracy: 0.8842\n",
            "Epoch 31/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3078 - accuracy: 0.8783 - val_loss: 0.2998 - val_accuracy: 0.8842\n",
            "Epoch 32/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3021 - accuracy: 0.8809 - val_loss: 0.3013 - val_accuracy: 0.8790\n",
            "Epoch 33/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3026 - accuracy: 0.8793 - val_loss: 0.2942 - val_accuracy: 0.8858\n",
            "Epoch 34/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2968 - accuracy: 0.8843 - val_loss: 0.2935 - val_accuracy: 0.8828\n",
            "Epoch 35/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2967 - accuracy: 0.8820 - val_loss: 0.2927 - val_accuracy: 0.8873\n",
            "Epoch 36/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2963 - accuracy: 0.8819 - val_loss: 0.3008 - val_accuracy: 0.8817\n",
            "Epoch 37/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2878 - accuracy: 0.8852 - val_loss: 0.2846 - val_accuracy: 0.8903\n",
            "Epoch 38/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2841 - accuracy: 0.8894 - val_loss: 0.2871 - val_accuracy: 0.8890\n",
            "Epoch 39/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2821 - accuracy: 0.8894 - val_loss: 0.2832 - val_accuracy: 0.8888\n",
            "Epoch 40/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2809 - accuracy: 0.8900 - val_loss: 0.2818 - val_accuracy: 0.8930\n",
            "Epoch 41/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2771 - accuracy: 0.8906 - val_loss: 0.2796 - val_accuracy: 0.8918\n",
            "Epoch 42/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2768 - accuracy: 0.8910 - val_loss: 0.2796 - val_accuracy: 0.8918\n",
            "Epoch 43/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2756 - accuracy: 0.8910 - val_loss: 0.2845 - val_accuracy: 0.8893\n",
            "Epoch 44/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2750 - accuracy: 0.8911 - val_loss: 0.2744 - val_accuracy: 0.8947\n",
            "Epoch 45/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2729 - accuracy: 0.8935 - val_loss: 0.2786 - val_accuracy: 0.8925\n",
            "Epoch 46/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2675 - accuracy: 0.8939 - val_loss: 0.2725 - val_accuracy: 0.8975\n",
            "Epoch 47/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2674 - accuracy: 0.8937 - val_loss: 0.2730 - val_accuracy: 0.8928\n",
            "Epoch 48/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2679 - accuracy: 0.8939 - val_loss: 0.2742 - val_accuracy: 0.8955\n",
            "Epoch 49/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2635 - accuracy: 0.8972 - val_loss: 0.2796 - val_accuracy: 0.8873\n",
            "Epoch 50/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2664 - accuracy: 0.8956 - val_loss: 0.2772 - val_accuracy: 0.8908\n",
            "Epoch 51/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2645 - accuracy: 0.8950 - val_loss: 0.2736 - val_accuracy: 0.8935\n",
            "Epoch 52/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2596 - accuracy: 0.8975 - val_loss: 0.2723 - val_accuracy: 0.8955\n",
            "Epoch 53/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2553 - accuracy: 0.8999 - val_loss: 0.2644 - val_accuracy: 0.8993\n",
            "Epoch 54/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2520 - accuracy: 0.9006 - val_loss: 0.2730 - val_accuracy: 0.8953\n",
            "Epoch 55/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2527 - accuracy: 0.9004 - val_loss: 0.2620 - val_accuracy: 0.9037\n",
            "Epoch 56/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2502 - accuracy: 0.9008 - val_loss: 0.2631 - val_accuracy: 0.8962\n",
            "Epoch 57/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2467 - accuracy: 0.9035 - val_loss: 0.2652 - val_accuracy: 0.8985\n",
            "Epoch 58/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2453 - accuracy: 0.9036 - val_loss: 0.2577 - val_accuracy: 0.9043\n",
            "Epoch 59/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2467 - accuracy: 0.9027 - val_loss: 0.2554 - val_accuracy: 0.9028\n",
            "Epoch 60/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2425 - accuracy: 0.9050 - val_loss: 0.2575 - val_accuracy: 0.8985\n",
            "Epoch 61/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2425 - accuracy: 0.9046 - val_loss: 0.2568 - val_accuracy: 0.9010\n",
            "Epoch 62/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2402 - accuracy: 0.9051 - val_loss: 0.2568 - val_accuracy: 0.9023\n",
            "Epoch 63/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2372 - accuracy: 0.9065 - val_loss: 0.2530 - val_accuracy: 0.9067\n",
            "Epoch 64/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2376 - accuracy: 0.9061 - val_loss: 0.2565 - val_accuracy: 0.9022\n",
            "Epoch 65/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2369 - accuracy: 0.9065 - val_loss: 0.2552 - val_accuracy: 0.9042\n",
            "Epoch 66/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2366 - accuracy: 0.9077 - val_loss: 0.2514 - val_accuracy: 0.9052\n",
            "Epoch 67/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2340 - accuracy: 0.9078 - val_loss: 0.2496 - val_accuracy: 0.9067\n",
            "Epoch 68/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2303 - accuracy: 0.9081 - val_loss: 0.2498 - val_accuracy: 0.9062\n",
            "Epoch 69/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2305 - accuracy: 0.9094 - val_loss: 0.2595 - val_accuracy: 0.8990\n",
            "Epoch 70/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2283 - accuracy: 0.9109 - val_loss: 0.2527 - val_accuracy: 0.9030\n",
            "Epoch 71/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2295 - accuracy: 0.9098 - val_loss: 0.2536 - val_accuracy: 0.9003\n",
            "Epoch 72/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2304 - accuracy: 0.9089 - val_loss: 0.2459 - val_accuracy: 0.9053\n",
            "Epoch 73/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2261 - accuracy: 0.9114 - val_loss: 0.2425 - val_accuracy: 0.9060\n",
            "Epoch 74/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2235 - accuracy: 0.9114 - val_loss: 0.2495 - val_accuracy: 0.9033\n",
            "Epoch 75/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2267 - accuracy: 0.9101 - val_loss: 0.2426 - val_accuracy: 0.9048\n",
            "Epoch 76/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2203 - accuracy: 0.9131 - val_loss: 0.2479 - val_accuracy: 0.9050\n",
            "Epoch 77/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2203 - accuracy: 0.9125 - val_loss: 0.2461 - val_accuracy: 0.9073\n",
            "Epoch 78/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2191 - accuracy: 0.9138 - val_loss: 0.2466 - val_accuracy: 0.9062\n",
            "Epoch 79/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2193 - accuracy: 0.9144 - val_loss: 0.2434 - val_accuracy: 0.9065\n",
            "Epoch 80/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2162 - accuracy: 0.9155 - val_loss: 0.2424 - val_accuracy: 0.9052\n",
            "Epoch 81/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2133 - accuracy: 0.9169 - val_loss: 0.2409 - val_accuracy: 0.9077\n",
            "Epoch 82/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2147 - accuracy: 0.9152 - val_loss: 0.2376 - val_accuracy: 0.9113\n",
            "Epoch 83/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2107 - accuracy: 0.9176 - val_loss: 0.2399 - val_accuracy: 0.9077\n",
            "Epoch 84/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2097 - accuracy: 0.9166 - val_loss: 0.2449 - val_accuracy: 0.9087\n",
            "Epoch 85/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2089 - accuracy: 0.9176 - val_loss: 0.2377 - val_accuracy: 0.9105\n",
            "Epoch 86/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2072 - accuracy: 0.9182 - val_loss: 0.2444 - val_accuracy: 0.9027\n",
            "Epoch 87/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2061 - accuracy: 0.9189 - val_loss: 0.2414 - val_accuracy: 0.9077\n",
            "Epoch 88/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2052 - accuracy: 0.9193 - val_loss: 0.2395 - val_accuracy: 0.9053\n",
            "Epoch 89/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2048 - accuracy: 0.9207 - val_loss: 0.2350 - val_accuracy: 0.9112\n",
            "Epoch 90/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2016 - accuracy: 0.9213 - val_loss: 0.2394 - val_accuracy: 0.9065\n",
            "Epoch 91/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2013 - accuracy: 0.9217 - val_loss: 0.2356 - val_accuracy: 0.9113\n",
            "Epoch 92/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1972 - accuracy: 0.9238 - val_loss: 0.2361 - val_accuracy: 0.9113\n",
            "Epoch 93/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1990 - accuracy: 0.9218 - val_loss: 0.2420 - val_accuracy: 0.9077\n",
            "Epoch 94/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2028 - accuracy: 0.9195 - val_loss: 0.2516 - val_accuracy: 0.8985\n",
            "Epoch 95/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1998 - accuracy: 0.9210 - val_loss: 0.2311 - val_accuracy: 0.9120\n",
            "Epoch 96/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1971 - accuracy: 0.9226 - val_loss: 0.2417 - val_accuracy: 0.9065\n",
            "Epoch 97/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1934 - accuracy: 0.9251 - val_loss: 0.2312 - val_accuracy: 0.9117\n",
            "Epoch 98/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1927 - accuracy: 0.9253 - val_loss: 0.2333 - val_accuracy: 0.9103\n",
            "Epoch 99/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1908 - accuracy: 0.9250 - val_loss: 0.2374 - val_accuracy: 0.9080\n",
            "Epoch 100/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1918 - accuracy: 0.9243 - val_loss: 0.2311 - val_accuracy: 0.9128\n",
            "Epoch 101/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1908 - accuracy: 0.9247 - val_loss: 0.2375 - val_accuracy: 0.9070\n",
            "Epoch 102/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1881 - accuracy: 0.9265 - val_loss: 0.2324 - val_accuracy: 0.9100\n",
            "Epoch 103/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1865 - accuracy: 0.9261 - val_loss: 0.2316 - val_accuracy: 0.9130\n",
            "Epoch 104/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1873 - accuracy: 0.9264 - val_loss: 0.2294 - val_accuracy: 0.9123\n",
            "Epoch 105/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1878 - accuracy: 0.9264 - val_loss: 0.2323 - val_accuracy: 0.9098\n",
            "Epoch 106/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1871 - accuracy: 0.9264 - val_loss: 0.2288 - val_accuracy: 0.9118\n",
            "Epoch 107/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1819 - accuracy: 0.9297 - val_loss: 0.2295 - val_accuracy: 0.9087\n",
            "Epoch 108/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1831 - accuracy: 0.9284 - val_loss: 0.2273 - val_accuracy: 0.9117\n",
            "Epoch 109/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1812 - accuracy: 0.9285 - val_loss: 0.2364 - val_accuracy: 0.9083\n",
            "Epoch 110/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1805 - accuracy: 0.9294 - val_loss: 0.2274 - val_accuracy: 0.9117\n",
            "Epoch 111/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1789 - accuracy: 0.9304 - val_loss: 0.2273 - val_accuracy: 0.9102\n",
            "Epoch 112/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1782 - accuracy: 0.9303 - val_loss: 0.2305 - val_accuracy: 0.9118\n",
            "Epoch 113/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1782 - accuracy: 0.9301 - val_loss: 0.2339 - val_accuracy: 0.9073\n",
            "Epoch 114/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1783 - accuracy: 0.9301 - val_loss: 0.2289 - val_accuracy: 0.9108\n",
            "Epoch 115/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1766 - accuracy: 0.9306 - val_loss: 0.2289 - val_accuracy: 0.9130\n",
            "Epoch 116/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1771 - accuracy: 0.9302 - val_loss: 0.2311 - val_accuracy: 0.9105\n",
            "Epoch 117/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1729 - accuracy: 0.9319 - val_loss: 0.2243 - val_accuracy: 0.9148\n",
            "Epoch 118/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1744 - accuracy: 0.9322 - val_loss: 0.2268 - val_accuracy: 0.9127\n",
            "Epoch 119/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1719 - accuracy: 0.9332 - val_loss: 0.2297 - val_accuracy: 0.9103\n",
            "Epoch 120/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1713 - accuracy: 0.9319 - val_loss: 0.2288 - val_accuracy: 0.9102\n",
            "Epoch 121/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1708 - accuracy: 0.9327 - val_loss: 0.2243 - val_accuracy: 0.9148\n",
            "Epoch 122/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1710 - accuracy: 0.9331 - val_loss: 0.2230 - val_accuracy: 0.9158\n",
            "Epoch 123/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1674 - accuracy: 0.9340 - val_loss: 0.2341 - val_accuracy: 0.9100\n",
            "Epoch 124/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1664 - accuracy: 0.9344 - val_loss: 0.2241 - val_accuracy: 0.9145\n",
            "Epoch 125/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1656 - accuracy: 0.9359 - val_loss: 0.2230 - val_accuracy: 0.9167\n",
            "Epoch 126/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1629 - accuracy: 0.9361 - val_loss: 0.2214 - val_accuracy: 0.9132\n",
            "Epoch 127/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1631 - accuracy: 0.9366 - val_loss: 0.2281 - val_accuracy: 0.9113\n",
            "Epoch 128/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1614 - accuracy: 0.9379 - val_loss: 0.2236 - val_accuracy: 0.9117\n",
            "Epoch 129/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1599 - accuracy: 0.9378 - val_loss: 0.2239 - val_accuracy: 0.9133\n",
            "Epoch 130/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1592 - accuracy: 0.9384 - val_loss: 0.2285 - val_accuracy: 0.9123\n",
            "Epoch 131/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1580 - accuracy: 0.9394 - val_loss: 0.2264 - val_accuracy: 0.9110\n",
            "Epoch 132/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1577 - accuracy: 0.9381 - val_loss: 0.2207 - val_accuracy: 0.9153\n",
            "Epoch 133/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1575 - accuracy: 0.9391 - val_loss: 0.2237 - val_accuracy: 0.9138\n",
            "Epoch 134/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1562 - accuracy: 0.9397 - val_loss: 0.2254 - val_accuracy: 0.9138\n",
            "Epoch 135/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1563 - accuracy: 0.9389 - val_loss: 0.2284 - val_accuracy: 0.9127\n",
            "Epoch 136/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1567 - accuracy: 0.9390 - val_loss: 0.2320 - val_accuracy: 0.9095\n",
            "Epoch 137/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1558 - accuracy: 0.9392 - val_loss: 0.2311 - val_accuracy: 0.9100\n",
            "Epoch 138/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1540 - accuracy: 0.9392 - val_loss: 0.2226 - val_accuracy: 0.9162\n",
            "Epoch 139/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1511 - accuracy: 0.9416 - val_loss: 0.2281 - val_accuracy: 0.9127\n",
            "Epoch 140/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1516 - accuracy: 0.9418 - val_loss: 0.2214 - val_accuracy: 0.9153\n",
            "Epoch 141/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1503 - accuracy: 0.9415 - val_loss: 0.2255 - val_accuracy: 0.9098\n",
            "Epoch 142/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1500 - accuracy: 0.9414 - val_loss: 0.2276 - val_accuracy: 0.9138\n",
            "Epoch 143/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1502 - accuracy: 0.9416 - val_loss: 0.2234 - val_accuracy: 0.9162\n",
            "Epoch 144/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1474 - accuracy: 0.9424 - val_loss: 0.2192 - val_accuracy: 0.9192\n",
            "Epoch 145/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1451 - accuracy: 0.9439 - val_loss: 0.2250 - val_accuracy: 0.9107\n",
            "Epoch 146/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1462 - accuracy: 0.9429 - val_loss: 0.2244 - val_accuracy: 0.9130\n",
            "Epoch 147/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1436 - accuracy: 0.9448 - val_loss: 0.2228 - val_accuracy: 0.9135\n",
            "Epoch 148/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1445 - accuracy: 0.9436 - val_loss: 0.2252 - val_accuracy: 0.9132\n",
            "Epoch 149/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1419 - accuracy: 0.9452 - val_loss: 0.2345 - val_accuracy: 0.9102\n",
            "Epoch 150/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1417 - accuracy: 0.9450 - val_loss: 0.2230 - val_accuracy: 0.9138\n",
            "Epoch 151/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1400 - accuracy: 0.9464 - val_loss: 0.2185 - val_accuracy: 0.9170\n",
            "Epoch 152/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1415 - accuracy: 0.9445 - val_loss: 0.2196 - val_accuracy: 0.9160\n",
            "Epoch 153/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1403 - accuracy: 0.9458 - val_loss: 0.2231 - val_accuracy: 0.9128\n",
            "Epoch 154/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1431 - accuracy: 0.9439 - val_loss: 0.2265 - val_accuracy: 0.9128\n",
            "Epoch 155/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1405 - accuracy: 0.9458 - val_loss: 0.2246 - val_accuracy: 0.9143\n",
            "Epoch 156/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1403 - accuracy: 0.9453 - val_loss: 0.2246 - val_accuracy: 0.9142\n",
            "Epoch 157/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1352 - accuracy: 0.9487 - val_loss: 0.2205 - val_accuracy: 0.9148\n",
            "Epoch 158/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1334 - accuracy: 0.9489 - val_loss: 0.2231 - val_accuracy: 0.9158\n",
            "Epoch 159/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1345 - accuracy: 0.9487 - val_loss: 0.2199 - val_accuracy: 0.9160\n",
            "Epoch 160/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1315 - accuracy: 0.9493 - val_loss: 0.2218 - val_accuracy: 0.9162\n",
            "Epoch 161/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1327 - accuracy: 0.9486 - val_loss: 0.2231 - val_accuracy: 0.9175\n",
            "Epoch 162/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1317 - accuracy: 0.9488 - val_loss: 0.2284 - val_accuracy: 0.9135\n",
            "Epoch 163/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1323 - accuracy: 0.9494 - val_loss: 0.2216 - val_accuracy: 0.9187\n",
            "Epoch 164/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1306 - accuracy: 0.9493 - val_loss: 0.2245 - val_accuracy: 0.9157\n",
            "Epoch 165/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1273 - accuracy: 0.9510 - val_loss: 0.2222 - val_accuracy: 0.9162\n",
            "Epoch 166/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1289 - accuracy: 0.9502 - val_loss: 0.2251 - val_accuracy: 0.9180\n",
            "Epoch 167/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1307 - accuracy: 0.9499 - val_loss: 0.2268 - val_accuracy: 0.9153\n",
            "Epoch 168/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1275 - accuracy: 0.9504 - val_loss: 0.2242 - val_accuracy: 0.9160\n",
            "Epoch 169/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1252 - accuracy: 0.9523 - val_loss: 0.2238 - val_accuracy: 0.9152\n",
            "Epoch 170/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1280 - accuracy: 0.9500 - val_loss: 0.2259 - val_accuracy: 0.9132\n",
            "Epoch 171/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1254 - accuracy: 0.9522 - val_loss: 0.2327 - val_accuracy: 0.9128\n",
            "Epoch 172/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1289 - accuracy: 0.9492 - val_loss: 0.2210 - val_accuracy: 0.9172\n",
            "Epoch 173/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1242 - accuracy: 0.9528 - val_loss: 0.2279 - val_accuracy: 0.9140\n",
            "Epoch 174/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1232 - accuracy: 0.9538 - val_loss: 0.2219 - val_accuracy: 0.9150\n",
            "Epoch 175/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1216 - accuracy: 0.9525 - val_loss: 0.2338 - val_accuracy: 0.9108\n",
            "Epoch 176/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1218 - accuracy: 0.9520 - val_loss: 0.2304 - val_accuracy: 0.9150\n",
            "Epoch 177/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1208 - accuracy: 0.9542 - val_loss: 0.2226 - val_accuracy: 0.9160\n",
            "Epoch 178/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1190 - accuracy: 0.9538 - val_loss: 0.2253 - val_accuracy: 0.9135\n",
            "Epoch 179/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1181 - accuracy: 0.9553 - val_loss: 0.2375 - val_accuracy: 0.9073\n",
            "Epoch 180/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1193 - accuracy: 0.9544 - val_loss: 0.2288 - val_accuracy: 0.9147\n",
            "Epoch 181/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1183 - accuracy: 0.9550 - val_loss: 0.2254 - val_accuracy: 0.9153\n",
            "Epoch 182/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1151 - accuracy: 0.9562 - val_loss: 0.2241 - val_accuracy: 0.9178\n",
            "Epoch 183/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1163 - accuracy: 0.9555 - val_loss: 0.2257 - val_accuracy: 0.9150\n",
            "Epoch 184/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1142 - accuracy: 0.9573 - val_loss: 0.2361 - val_accuracy: 0.9113\n",
            "Epoch 185/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1185 - accuracy: 0.9547 - val_loss: 0.2314 - val_accuracy: 0.9185\n",
            "Epoch 186/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1136 - accuracy: 0.9574 - val_loss: 0.2271 - val_accuracy: 0.9142\n",
            "Epoch 187/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1136 - accuracy: 0.9564 - val_loss: 0.2245 - val_accuracy: 0.9192\n",
            "Epoch 188/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1138 - accuracy: 0.9562 - val_loss: 0.2344 - val_accuracy: 0.9118\n",
            "Epoch 189/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1108 - accuracy: 0.9584 - val_loss: 0.2249 - val_accuracy: 0.9167\n",
            "Epoch 190/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1121 - accuracy: 0.9573 - val_loss: 0.2271 - val_accuracy: 0.9160\n",
            "Epoch 191/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1112 - accuracy: 0.9573 - val_loss: 0.2282 - val_accuracy: 0.9157\n",
            "Epoch 192/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1088 - accuracy: 0.9580 - val_loss: 0.2366 - val_accuracy: 0.9122\n",
            "Epoch 193/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1078 - accuracy: 0.9592 - val_loss: 0.2250 - val_accuracy: 0.9165\n",
            "Epoch 194/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1097 - accuracy: 0.9586 - val_loss: 0.2325 - val_accuracy: 0.9135\n",
            "Epoch 195/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1073 - accuracy: 0.9594 - val_loss: 0.2240 - val_accuracy: 0.9175\n",
            "Epoch 196/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1083 - accuracy: 0.9585 - val_loss: 0.2287 - val_accuracy: 0.9160\n",
            "Epoch 197/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1079 - accuracy: 0.9594 - val_loss: 0.2278 - val_accuracy: 0.9173\n",
            "Epoch 198/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1059 - accuracy: 0.9595 - val_loss: 0.2352 - val_accuracy: 0.9160\n",
            "Epoch 199/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1038 - accuracy: 0.9606 - val_loss: 0.2271 - val_accuracy: 0.9163\n",
            "Epoch 200/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1057 - accuracy: 0.9596 - val_loss: 0.2270 - val_accuracy: 0.9162\n",
            "Epoch 201/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1048 - accuracy: 0.9599 - val_loss: 0.2259 - val_accuracy: 0.9168\n",
            "Epoch 202/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1011 - accuracy: 0.9625 - val_loss: 0.2312 - val_accuracy: 0.9175\n",
            "Epoch 203/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1044 - accuracy: 0.9602 - val_loss: 0.2449 - val_accuracy: 0.9093\n",
            "Epoch 204/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1035 - accuracy: 0.9608 - val_loss: 0.2305 - val_accuracy: 0.9140\n",
            "Epoch 205/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0991 - accuracy: 0.9622 - val_loss: 0.2360 - val_accuracy: 0.9155\n",
            "Epoch 206/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1044 - accuracy: 0.9603 - val_loss: 0.2480 - val_accuracy: 0.9085\n",
            "Epoch 207/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.1000 - accuracy: 0.9622 - val_loss: 0.2268 - val_accuracy: 0.9172\n",
            "Epoch 208/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0987 - accuracy: 0.9624 - val_loss: 0.2396 - val_accuracy: 0.9108\n",
            "Epoch 209/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0990 - accuracy: 0.9630 - val_loss: 0.2294 - val_accuracy: 0.9182\n",
            "Epoch 210/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0981 - accuracy: 0.9630 - val_loss: 0.2352 - val_accuracy: 0.9155\n",
            "Epoch 211/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0951 - accuracy: 0.9643 - val_loss: 0.2302 - val_accuracy: 0.9197\n",
            "Epoch 212/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0947 - accuracy: 0.9643 - val_loss: 0.2358 - val_accuracy: 0.9153\n",
            "Epoch 213/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0968 - accuracy: 0.9633 - val_loss: 0.2288 - val_accuracy: 0.9175\n",
            "Epoch 214/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0944 - accuracy: 0.9650 - val_loss: 0.2295 - val_accuracy: 0.9173\n",
            "Epoch 215/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0942 - accuracy: 0.9645 - val_loss: 0.2325 - val_accuracy: 0.9160\n",
            "Epoch 216/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0959 - accuracy: 0.9644 - val_loss: 0.2369 - val_accuracy: 0.9153\n",
            "Epoch 217/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0926 - accuracy: 0.9654 - val_loss: 0.2345 - val_accuracy: 0.9193\n",
            "Epoch 218/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0923 - accuracy: 0.9658 - val_loss: 0.2296 - val_accuracy: 0.9168\n",
            "Epoch 219/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0910 - accuracy: 0.9664 - val_loss: 0.2337 - val_accuracy: 0.9162\n",
            "Epoch 220/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0914 - accuracy: 0.9655 - val_loss: 0.2404 - val_accuracy: 0.9130\n",
            "Epoch 221/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0908 - accuracy: 0.9664 - val_loss: 0.2343 - val_accuracy: 0.9158\n",
            "Epoch 222/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0884 - accuracy: 0.9671 - val_loss: 0.2394 - val_accuracy: 0.9150\n",
            "Epoch 223/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0907 - accuracy: 0.9664 - val_loss: 0.2495 - val_accuracy: 0.9098\n",
            "Epoch 224/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0902 - accuracy: 0.9661 - val_loss: 0.2337 - val_accuracy: 0.9178\n",
            "Epoch 225/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0891 - accuracy: 0.9675 - val_loss: 0.2373 - val_accuracy: 0.9170\n",
            "Epoch 226/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0880 - accuracy: 0.9670 - val_loss: 0.2426 - val_accuracy: 0.9167\n",
            "Epoch 227/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0865 - accuracy: 0.9682 - val_loss: 0.2407 - val_accuracy: 0.9147\n",
            "Epoch 228/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0865 - accuracy: 0.9675 - val_loss: 0.2371 - val_accuracy: 0.9165\n",
            "Epoch 229/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0855 - accuracy: 0.9683 - val_loss: 0.2327 - val_accuracy: 0.9188\n",
            "Epoch 230/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0853 - accuracy: 0.9686 - val_loss: 0.2366 - val_accuracy: 0.9173\n",
            "Epoch 231/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0865 - accuracy: 0.9669 - val_loss: 0.2405 - val_accuracy: 0.9158\n",
            "Epoch 232/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0856 - accuracy: 0.9683 - val_loss: 0.2378 - val_accuracy: 0.9138\n",
            "Epoch 233/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0860 - accuracy: 0.9680 - val_loss: 0.2372 - val_accuracy: 0.9168\n",
            "Epoch 234/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0834 - accuracy: 0.9691 - val_loss: 0.2367 - val_accuracy: 0.9178\n",
            "Epoch 235/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0895 - accuracy: 0.9660 - val_loss: 0.2627 - val_accuracy: 0.9083\n",
            "Epoch 236/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0877 - accuracy: 0.9670 - val_loss: 0.2406 - val_accuracy: 0.9157\n",
            "Epoch 237/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0846 - accuracy: 0.9683 - val_loss: 0.2420 - val_accuracy: 0.9153\n",
            "Epoch 238/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0799 - accuracy: 0.9704 - val_loss: 0.2374 - val_accuracy: 0.9158\n",
            "Epoch 239/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0802 - accuracy: 0.9702 - val_loss: 0.2450 - val_accuracy: 0.9187\n",
            "Epoch 240/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0801 - accuracy: 0.9706 - val_loss: 0.2448 - val_accuracy: 0.9157\n",
            "Epoch 241/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0804 - accuracy: 0.9700 - val_loss: 0.2368 - val_accuracy: 0.9170\n",
            "Epoch 242/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0789 - accuracy: 0.9707 - val_loss: 0.2435 - val_accuracy: 0.9160\n",
            "Epoch 243/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0817 - accuracy: 0.9693 - val_loss: 0.2409 - val_accuracy: 0.9182\n",
            "Epoch 244/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0755 - accuracy: 0.9723 - val_loss: 0.2588 - val_accuracy: 0.9133\n",
            "Epoch 245/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0798 - accuracy: 0.9701 - val_loss: 0.2372 - val_accuracy: 0.9192\n",
            "Epoch 246/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0770 - accuracy: 0.9715 - val_loss: 0.2532 - val_accuracy: 0.9125\n",
            "Epoch 247/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0815 - accuracy: 0.9692 - val_loss: 0.2442 - val_accuracy: 0.9150\n",
            "Epoch 248/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0754 - accuracy: 0.9724 - val_loss: 0.2444 - val_accuracy: 0.9163\n",
            "Epoch 249/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0757 - accuracy: 0.9722 - val_loss: 0.2472 - val_accuracy: 0.9140\n",
            "Epoch 250/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0738 - accuracy: 0.9734 - val_loss: 0.2488 - val_accuracy: 0.9155\n",
            "Epoch 251/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0754 - accuracy: 0.9722 - val_loss: 0.2468 - val_accuracy: 0.9143\n",
            "Epoch 252/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0711 - accuracy: 0.9744 - val_loss: 0.2418 - val_accuracy: 0.9158\n",
            "Epoch 253/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0737 - accuracy: 0.9724 - val_loss: 0.2447 - val_accuracy: 0.9145\n",
            "Epoch 254/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0717 - accuracy: 0.9738 - val_loss: 0.2450 - val_accuracy: 0.9170\n",
            "Epoch 255/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0708 - accuracy: 0.9736 - val_loss: 0.2588 - val_accuracy: 0.9143\n",
            "Epoch 256/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0736 - accuracy: 0.9732 - val_loss: 0.2508 - val_accuracy: 0.9138\n",
            "Epoch 257/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0715 - accuracy: 0.9741 - val_loss: 0.2506 - val_accuracy: 0.9163\n",
            "Epoch 258/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0717 - accuracy: 0.9734 - val_loss: 0.2522 - val_accuracy: 0.9138\n",
            "Epoch 259/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0701 - accuracy: 0.9739 - val_loss: 0.2559 - val_accuracy: 0.9143\n",
            "Epoch 260/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0689 - accuracy: 0.9752 - val_loss: 0.2466 - val_accuracy: 0.9185\n",
            "Epoch 261/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0699 - accuracy: 0.9743 - val_loss: 0.2479 - val_accuracy: 0.9183\n",
            "Epoch 262/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0701 - accuracy: 0.9740 - val_loss: 0.2452 - val_accuracy: 0.9175\n",
            "Epoch 263/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0710 - accuracy: 0.9736 - val_loss: 0.2531 - val_accuracy: 0.9133\n",
            "Epoch 264/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0672 - accuracy: 0.9755 - val_loss: 0.2507 - val_accuracy: 0.9153\n",
            "Epoch 265/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0672 - accuracy: 0.9755 - val_loss: 0.2436 - val_accuracy: 0.9165\n",
            "Epoch 266/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0680 - accuracy: 0.9753 - val_loss: 0.2511 - val_accuracy: 0.9165\n",
            "Epoch 267/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0697 - accuracy: 0.9740 - val_loss: 0.2575 - val_accuracy: 0.9152\n",
            "Epoch 268/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0654 - accuracy: 0.9761 - val_loss: 0.2485 - val_accuracy: 0.9163\n",
            "Epoch 269/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0632 - accuracy: 0.9778 - val_loss: 0.2499 - val_accuracy: 0.9183\n",
            "Epoch 270/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0646 - accuracy: 0.9762 - val_loss: 0.2536 - val_accuracy: 0.9140\n",
            "Epoch 271/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0646 - accuracy: 0.9764 - val_loss: 0.2744 - val_accuracy: 0.9095\n",
            "Epoch 272/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0655 - accuracy: 0.9759 - val_loss: 0.2539 - val_accuracy: 0.9160\n",
            "Epoch 273/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0630 - accuracy: 0.9769 - val_loss: 0.2529 - val_accuracy: 0.9173\n",
            "Epoch 274/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0633 - accuracy: 0.9778 - val_loss: 0.2529 - val_accuracy: 0.9163\n",
            "Epoch 275/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0631 - accuracy: 0.9776 - val_loss: 0.2540 - val_accuracy: 0.9177\n",
            "Epoch 276/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0609 - accuracy: 0.9784 - val_loss: 0.2540 - val_accuracy: 0.9180\n",
            "Epoch 277/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0664 - accuracy: 0.9751 - val_loss: 0.2532 - val_accuracy: 0.9172\n",
            "Epoch 278/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0624 - accuracy: 0.9772 - val_loss: 0.2660 - val_accuracy: 0.9138\n",
            "Epoch 279/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0613 - accuracy: 0.9779 - val_loss: 0.2571 - val_accuracy: 0.9140\n",
            "Epoch 280/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0606 - accuracy: 0.9786 - val_loss: 0.2600 - val_accuracy: 0.9165\n",
            "Epoch 281/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0597 - accuracy: 0.9791 - val_loss: 0.2550 - val_accuracy: 0.9177\n",
            "Epoch 282/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0616 - accuracy: 0.9776 - val_loss: 0.2598 - val_accuracy: 0.9150\n",
            "Epoch 283/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0608 - accuracy: 0.9779 - val_loss: 0.2588 - val_accuracy: 0.9160\n",
            "Epoch 284/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0600 - accuracy: 0.9779 - val_loss: 0.2592 - val_accuracy: 0.9122\n",
            "Epoch 285/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0615 - accuracy: 0.9778 - val_loss: 0.2634 - val_accuracy: 0.9148\n",
            "Epoch 286/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0583 - accuracy: 0.9794 - val_loss: 0.2583 - val_accuracy: 0.9157\n",
            "Epoch 287/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0570 - accuracy: 0.9793 - val_loss: 0.2766 - val_accuracy: 0.9120\n",
            "Epoch 288/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0573 - accuracy: 0.9791 - val_loss: 0.2730 - val_accuracy: 0.9142\n",
            "Epoch 289/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0584 - accuracy: 0.9791 - val_loss: 0.2641 - val_accuracy: 0.9145\n",
            "Epoch 290/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0572 - accuracy: 0.9798 - val_loss: 0.2633 - val_accuracy: 0.9145\n",
            "Epoch 291/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0601 - accuracy: 0.9781 - val_loss: 0.2622 - val_accuracy: 0.9157\n",
            "Epoch 292/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0544 - accuracy: 0.9805 - val_loss: 0.2604 - val_accuracy: 0.9167\n",
            "Epoch 293/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0597 - accuracy: 0.9781 - val_loss: 0.2677 - val_accuracy: 0.9137\n",
            "Epoch 294/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0570 - accuracy: 0.9793 - val_loss: 0.2583 - val_accuracy: 0.9160\n",
            "Epoch 295/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0546 - accuracy: 0.9808 - val_loss: 0.2696 - val_accuracy: 0.9155\n",
            "Epoch 296/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0566 - accuracy: 0.9791 - val_loss: 0.2640 - val_accuracy: 0.9137\n",
            "Epoch 297/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0573 - accuracy: 0.9792 - val_loss: 0.2644 - val_accuracy: 0.9143\n",
            "Epoch 298/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0533 - accuracy: 0.9813 - val_loss: 0.2666 - val_accuracy: 0.9145\n",
            "Epoch 299/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0529 - accuracy: 0.9820 - val_loss: 0.2685 - val_accuracy: 0.9133\n",
            "Epoch 300/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0523 - accuracy: 0.9814 - val_loss: 0.2666 - val_accuracy: 0.9152\n",
            "Epoch 301/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0544 - accuracy: 0.9807 - val_loss: 0.2667 - val_accuracy: 0.9148\n",
            "Epoch 302/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0520 - accuracy: 0.9818 - val_loss: 0.2804 - val_accuracy: 0.9117\n",
            "Epoch 303/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0515 - accuracy: 0.9822 - val_loss: 0.2662 - val_accuracy: 0.9175\n",
            "Epoch 304/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0523 - accuracy: 0.9813 - val_loss: 0.2644 - val_accuracy: 0.9195\n",
            "Epoch 305/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0514 - accuracy: 0.9823 - val_loss: 0.2683 - val_accuracy: 0.9148\n",
            "Epoch 306/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0515 - accuracy: 0.9816 - val_loss: 0.2687 - val_accuracy: 0.9162\n",
            "Epoch 307/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0510 - accuracy: 0.9822 - val_loss: 0.2656 - val_accuracy: 0.9150\n",
            "Epoch 308/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0494 - accuracy: 0.9835 - val_loss: 0.2674 - val_accuracy: 0.9148\n",
            "Epoch 309/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0541 - accuracy: 0.9802 - val_loss: 0.2725 - val_accuracy: 0.9140\n",
            "Epoch 310/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0497 - accuracy: 0.9824 - val_loss: 0.2710 - val_accuracy: 0.9147\n",
            "Epoch 311/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0494 - accuracy: 0.9825 - val_loss: 0.2764 - val_accuracy: 0.9140\n",
            "Epoch 312/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0492 - accuracy: 0.9834 - val_loss: 0.2942 - val_accuracy: 0.9098\n",
            "Epoch 313/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0498 - accuracy: 0.9824 - val_loss: 0.2726 - val_accuracy: 0.9143\n",
            "Epoch 314/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0492 - accuracy: 0.9826 - val_loss: 0.2764 - val_accuracy: 0.9148\n",
            "Epoch 315/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0465 - accuracy: 0.9839 - val_loss: 0.2762 - val_accuracy: 0.9167\n",
            "Epoch 316/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0475 - accuracy: 0.9834 - val_loss: 0.2808 - val_accuracy: 0.9123\n",
            "Epoch 317/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0479 - accuracy: 0.9831 - val_loss: 0.2782 - val_accuracy: 0.9160\n",
            "Epoch 318/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0477 - accuracy: 0.9829 - val_loss: 0.2737 - val_accuracy: 0.9138\n",
            "Epoch 319/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0461 - accuracy: 0.9837 - val_loss: 0.2768 - val_accuracy: 0.9120\n",
            "Epoch 320/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0468 - accuracy: 0.9832 - val_loss: 0.2750 - val_accuracy: 0.9165\n",
            "Epoch 321/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0460 - accuracy: 0.9841 - val_loss: 0.2790 - val_accuracy: 0.9148\n",
            "Epoch 322/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0471 - accuracy: 0.9833 - val_loss: 0.2788 - val_accuracy: 0.9140\n",
            "Epoch 323/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0471 - accuracy: 0.9836 - val_loss: 0.2749 - val_accuracy: 0.9157\n",
            "Epoch 324/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0455 - accuracy: 0.9838 - val_loss: 0.2793 - val_accuracy: 0.9137\n",
            "Epoch 325/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0444 - accuracy: 0.9848 - val_loss: 0.2733 - val_accuracy: 0.9175\n",
            "Epoch 326/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0458 - accuracy: 0.9839 - val_loss: 0.2783 - val_accuracy: 0.9145\n",
            "Epoch 327/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0444 - accuracy: 0.9843 - val_loss: 0.2820 - val_accuracy: 0.9163\n",
            "Epoch 328/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0422 - accuracy: 0.9865 - val_loss: 0.2800 - val_accuracy: 0.9125\n",
            "Epoch 329/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0445 - accuracy: 0.9846 - val_loss: 0.2868 - val_accuracy: 0.9130\n",
            "Epoch 330/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0441 - accuracy: 0.9848 - val_loss: 0.2779 - val_accuracy: 0.9160\n",
            "Epoch 331/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0447 - accuracy: 0.9846 - val_loss: 0.3002 - val_accuracy: 0.9100\n",
            "Epoch 332/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0430 - accuracy: 0.9852 - val_loss: 0.2799 - val_accuracy: 0.9157\n",
            "Epoch 333/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0413 - accuracy: 0.9852 - val_loss: 0.2879 - val_accuracy: 0.9128\n",
            "Epoch 334/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0432 - accuracy: 0.9851 - val_loss: 0.2759 - val_accuracy: 0.9163\n",
            "Epoch 335/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0411 - accuracy: 0.9861 - val_loss: 0.2835 - val_accuracy: 0.9135\n",
            "Epoch 336/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0419 - accuracy: 0.9851 - val_loss: 0.2776 - val_accuracy: 0.9153\n",
            "Epoch 337/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0401 - accuracy: 0.9859 - val_loss: 0.2929 - val_accuracy: 0.9110\n",
            "Epoch 338/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0429 - accuracy: 0.9854 - val_loss: 0.2832 - val_accuracy: 0.9132\n",
            "Epoch 339/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0419 - accuracy: 0.9861 - val_loss: 0.2836 - val_accuracy: 0.9162\n",
            "Epoch 340/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0415 - accuracy: 0.9859 - val_loss: 0.2998 - val_accuracy: 0.9090\n",
            "Epoch 341/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0418 - accuracy: 0.9857 - val_loss: 0.2850 - val_accuracy: 0.9122\n",
            "Epoch 342/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0384 - accuracy: 0.9869 - val_loss: 0.2961 - val_accuracy: 0.9127\n",
            "Epoch 343/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0399 - accuracy: 0.9861 - val_loss: 0.2939 - val_accuracy: 0.9137\n",
            "Epoch 344/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0395 - accuracy: 0.9861 - val_loss: 0.3006 - val_accuracy: 0.9108\n",
            "Epoch 345/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0410 - accuracy: 0.9856 - val_loss: 0.2951 - val_accuracy: 0.9125\n",
            "Epoch 346/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0389 - accuracy: 0.9865 - val_loss: 0.2904 - val_accuracy: 0.9137\n",
            "Epoch 347/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0376 - accuracy: 0.9874 - val_loss: 0.2908 - val_accuracy: 0.9135\n",
            "Epoch 348/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0379 - accuracy: 0.9871 - val_loss: 0.2938 - val_accuracy: 0.9138\n",
            "Epoch 349/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 0.3037 - val_accuracy: 0.9142\n",
            "Epoch 350/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0400 - accuracy: 0.9864 - val_loss: 0.3113 - val_accuracy: 0.9100\n",
            "Epoch 351/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0398 - accuracy: 0.9857 - val_loss: 0.2968 - val_accuracy: 0.9123\n",
            "Epoch 352/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0368 - accuracy: 0.9876 - val_loss: 0.2988 - val_accuracy: 0.9137\n",
            "Epoch 353/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0402 - accuracy: 0.9859 - val_loss: 0.2946 - val_accuracy: 0.9137\n",
            "Epoch 354/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0391 - accuracy: 0.9867 - val_loss: 0.3011 - val_accuracy: 0.9128\n",
            "Epoch 355/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0376 - accuracy: 0.9868 - val_loss: 0.2887 - val_accuracy: 0.9160\n",
            "Epoch 356/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 0.3176 - val_accuracy: 0.9062\n",
            "Epoch 357/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0438 - accuracy: 0.9843 - val_loss: 0.2956 - val_accuracy: 0.9128\n",
            "Epoch 358/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0371 - accuracy: 0.9874 - val_loss: 0.2911 - val_accuracy: 0.9165\n",
            "Epoch 359/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0366 - accuracy: 0.9878 - val_loss: 0.2953 - val_accuracy: 0.9157\n",
            "Epoch 360/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0339 - accuracy: 0.9890 - val_loss: 0.2945 - val_accuracy: 0.9133\n",
            "Epoch 361/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0344 - accuracy: 0.9885 - val_loss: 0.2982 - val_accuracy: 0.9147\n",
            "Epoch 362/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0362 - accuracy: 0.9879 - val_loss: 0.2957 - val_accuracy: 0.9135\n",
            "Epoch 363/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0357 - accuracy: 0.9880 - val_loss: 0.3219 - val_accuracy: 0.9083\n",
            "Epoch 364/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0353 - accuracy: 0.9882 - val_loss: 0.2934 - val_accuracy: 0.9138\n",
            "Epoch 365/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 0.3069 - val_accuracy: 0.9135\n",
            "Epoch 366/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0331 - accuracy: 0.9886 - val_loss: 0.3044 - val_accuracy: 0.9135\n",
            "Epoch 367/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0335 - accuracy: 0.9890 - val_loss: 0.2999 - val_accuracy: 0.9162\n",
            "Epoch 368/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0316 - accuracy: 0.9897 - val_loss: 0.3086 - val_accuracy: 0.9142\n",
            "Epoch 369/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0326 - accuracy: 0.9888 - val_loss: 0.3037 - val_accuracy: 0.9140\n",
            "Epoch 370/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0332 - accuracy: 0.9886 - val_loss: 0.3114 - val_accuracy: 0.9125\n",
            "Epoch 371/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0324 - accuracy: 0.9893 - val_loss: 0.3026 - val_accuracy: 0.9150\n",
            "Epoch 372/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0308 - accuracy: 0.9899 - val_loss: 0.3020 - val_accuracy: 0.9150\n",
            "Epoch 373/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 0.3055 - val_accuracy: 0.9128\n",
            "Epoch 374/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0320 - accuracy: 0.9893 - val_loss: 0.3106 - val_accuracy: 0.9137\n",
            "Epoch 375/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 0.3074 - val_accuracy: 0.9132\n",
            "Epoch 376/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.3037 - val_accuracy: 0.9132\n",
            "Epoch 377/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 0.3093 - val_accuracy: 0.9118\n",
            "Epoch 378/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.3099 - val_accuracy: 0.9142\n",
            "Epoch 379/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0327 - accuracy: 0.9889 - val_loss: 0.3176 - val_accuracy: 0.9120\n",
            "Epoch 380/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0318 - accuracy: 0.9893 - val_loss: 0.3144 - val_accuracy: 0.9120\n",
            "Epoch 381/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0310 - accuracy: 0.9899 - val_loss: 0.3078 - val_accuracy: 0.9135\n",
            "Epoch 382/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0295 - accuracy: 0.9908 - val_loss: 0.3122 - val_accuracy: 0.9138\n",
            "Epoch 383/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 0.3165 - val_accuracy: 0.9118\n",
            "Epoch 384/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 0.3040 - val_accuracy: 0.9138\n",
            "Epoch 385/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0286 - accuracy: 0.9907 - val_loss: 0.3075 - val_accuracy: 0.9135\n",
            "Epoch 386/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0303 - accuracy: 0.9899 - val_loss: 0.3035 - val_accuracy: 0.9135\n",
            "Epoch 387/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0305 - accuracy: 0.9898 - val_loss: 0.3080 - val_accuracy: 0.9167\n",
            "Epoch 388/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0284 - accuracy: 0.9907 - val_loss: 0.3137 - val_accuracy: 0.9117\n",
            "Epoch 389/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.3173 - val_accuracy: 0.9135\n",
            "Epoch 390/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0308 - accuracy: 0.9900 - val_loss: 0.3189 - val_accuracy: 0.9133\n",
            "Epoch 391/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0341 - accuracy: 0.9880 - val_loss: 0.3081 - val_accuracy: 0.9150\n",
            "Epoch 392/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 0.3213 - val_accuracy: 0.9102\n",
            "Epoch 393/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0307 - accuracy: 0.9896 - val_loss: 0.3141 - val_accuracy: 0.9128\n",
            "Epoch 394/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0293 - accuracy: 0.9901 - val_loss: 0.3103 - val_accuracy: 0.9133\n",
            "Epoch 395/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0281 - accuracy: 0.9904 - val_loss: 0.3112 - val_accuracy: 0.9148\n",
            "Epoch 396/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 0.3222 - val_accuracy: 0.9130\n",
            "Epoch 397/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0265 - accuracy: 0.9917 - val_loss: 0.3171 - val_accuracy: 0.9142\n",
            "Epoch 398/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.3192 - val_accuracy: 0.9127\n",
            "Epoch 399/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0277 - accuracy: 0.9906 - val_loss: 0.3232 - val_accuracy: 0.9102\n",
            "Epoch 400/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.3136 - val_accuracy: 0.9118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnJCEEZ1yA2e",
        "colab_type": "code",
        "outputId": "299340a7-ede6-4a24-dcc6-20522f8ef167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "cnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 128)         8320      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              6423552   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                32800     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 6,484,165\n",
            "Trainable params: 6,484,165\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo-4o10LfMDg",
        "colab_type": "code",
        "outputId": "1407bfac-1175-428b-9ce4-e61bfba34b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "evaluation= cnn_model.evaluate(X_test,y_test)\n",
        "print('Test Accuracy:{:.3f}'.format(evaluation[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "188/188 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.9137\n",
            "Test Accuracy:0.914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaSxHjzlh74C",
        "colab_type": "code",
        "outputId": "cc97d53d-cbab-492e-a57c-00cc9b3f14d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plt.rcParams['xtick.labelsize'] = 17\n",
        "#plt.rcParams['ytick.labelsize'] = 17\n",
        "#plt.rcParams['xlabel.fontsize'] = 17\n",
        "plt.rcParams['font.size'] = 17\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKIAAAJyCAYAAAD3imifAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd5xU1d3H8c+ZsjOzvfddlg7SkY6IXewRWyDRaCwx0fT6mJhokidFkyeJ0RgVC2rQ2Ii9RywgICC9l2Vhl21snS1T7/PHDCu7LB12Xfm+X699Ddx77r3nzOCL8cs5v2Msy0JEREREREREROR4s3V3B0RERERERERE5MSgIEpERERERERERLqEgigREREREREREekSCqJERERERERERKRLKIgSEREREREREZEuoSBKRERERERERES6hIIoEREREcAYc5oxxjLGPHYM7mUZY4qPvlciIiIiXywKokREREREREREpEsoiBIRERERERERkS6hIEpERERERERERLqEgigRERHpEsaYomjtpHnGmExjzCxjzC5jTIsxZqkx5sJoO7sx5mfGmPXGmFZjzHZjzC+MMWY/973YGPOOMabWGOMzxmwyxvzZGJO2n/a9jTFzjDHVxpjm6LO/cpC+xxhjvmeMWWyMaYhet8IY82NjjPMYvDeTjTH/MMasNsbURce90RjzJ2NMygGu+5Ix5nVjTFV07DuNMa8YYy7qpO1IY8wTxpiSaNtKY8x8Y8wPOrTbb30rY8wd0fPXdjheHD0eY4z5pTFmQ/QZj0XPxxtjvm+MecsYsyN6rib6+2kHGF+2MeZuY8za6Hteb4xZtff7Yox5Jvrss/Zzj6HR8x/u7zkiIiLSdRzd3QERERE54SQD8wEv8G8gFfgy8B9jzJnAd4FxwOvAO8DlwG+AFuDPe9/IGPNL4E6gHngOqAZOBX4ATDfGnGJZVule7fsCHwMZwH+BxUAe8HD0efswxsQDbwETgdXAk0AAOB24CzjTGHOBZVmho3hPvg+MBz6K9sMNTAJ+CJxvjBlvWVZjh349ANwUHfuLQCmQE+3n9cDLe7W9JjpGA7wGrCHyOQwDfgH831H0fW/PA2OjY/gPUBk9XgTcDXwQPVcDFACXAGcbY260LGtWh/GNBN4EMoFFwD8AO9AfuJXI51AL3AdcAdxM5M9LR9+Mvv7jWAxQREREjo6CKBEREelqI4AHgG9ZlhUGMMa8AfwLmAtsAYZallUXPfcnYCPwU2PMX/cEPsaYccAdQBUwzrKs4j0PMMbcDfwIuB+4eK9n30ckhLrdsqzf7tX+78CC/fT3L0TCnV8Dd1iWZUWvsQMPAl8nEnbce2RvBwA/Bor33Huvfv2GSFD0LeCPex2/jkgItQY43bKsqg7XFez164HALMAPTLUsa8n+2h4DvYh8dtUdjhcDuZZlVe590BiTTyQMvMsY8y/Lslqix51EgsVM4BbLsv7R4boUImEglmW9b4xZDVxijMm1LKtsr3bxwNVE/ow8f+yGKSIiIkdKS/NERESkqzUDP94TQkX9m0iwkAL8dE8IBRANmD4iEiDl73XNDURm+Ny1dwgV9Ssis3EuNMbkABhj8oBzgV1EZue0sSzrEyJBWDvRwONaYB17hVDRa0JEZixZRMKOI2ZZ1raOIVTUX6Kv53Y4/v3o6y0dQ6jo/Xbs9dtbACeR92nJQdoerds7CaGwLMvbMYSKHt9JJHBKITKTao+LgL7AvI4hVPS6WsuyvHsduo/IP7De0KHpV4AE4GHLsvyHOxgRERE59jQjSkRERLraxo7LzCzLChljKoksk1vayTV7ZrnkA9ujvz45+rrPcizLspqNMfOBS4HRwKvRV4CFlmX5OnnGPOBrHY6NJ/J9yQ/8aj9lqlqAkzo7caiMMXFEliReCgwgEp7s/bC8Dm2HAV7Lst4/hNtPiL6+ejR9PESL93fCGDOZyBgnEpnpFNOhSd5evz7cPj8J/AG4wRjzv3stk7wZCBOZgSciIiKfAwqiREREpKvV7+d4EMCyrM7OB6OvexcGT4q+lu/nfnvCq+QO7Sv2076z++wpeD4i+nPMRZeh/ZdIXaxNRGYIVRAJvyAyu8u11yV7xlPGodlT7Lz0gK2OjU4/C2PMpUTGFQTeJrLU0kskJDoNmEr7MR5Wny3L8hpjZgPfAS4EXjTGTABGAq92MmNOREREuomCKBEREemp9gRW2XQegOR2aLfnNWs/98vu5NieJYIPWZZ102H38NBcQiSEegs4f++i59Flhb/aT59yOTS10dc8IssSD8Zi/98Rk/dzPHJh58sLIVJs3gacZVlWu93rokXXp3Zov3efD9U/gG8Tqdf1Ip8VKb//MO4hIiIix5lqRImIiEhPtWcJ3+kdTxhjPER2nbOAZdHDe14nGGNcHa8hMjOno8VEZu1MMftZl3cM9Iu+vtLJzntTOja2LKsJWAnEG2M6Bjid+Tj6esEh9qcWyIrO1OpozCHeo6N+QE0nIZQNmNxJ+z19Pv9QH2BZ1gYiyzTPMcaMBa4kUiS9090QRUREpHsoiBIREZGe6uHo60872fntV0RmPr26Zxc1y7JKgTeBHCK71LWJBhdf6fiAaCHw2cAg4I/GmI51jTDGpBtjRh7FOIqjr6d2uG8vInWPOvO36Ot9xpiMTvq0d1H3+4kUgv+JMWafIKlDW4BFRGZEXdeh3bV0HhodimIgxRgztMPxnwNDOmn/CrAVON0Y862OJ40xydEd8Tq6j0htrRcAN/BAh6L4IiIi0s20NE9ERER6JMuyFhljfgPcDqw0xjwL7CYS6EwCSvhsedYetxCZbfMbY8zpREKXfCKzZ14BvtTJo75DZEbPj4GrjDHziNRnyiCys9spRAKQ7x3hUF4GNgOXG2M+AhYQWXZ3EZHZPL07Gfsj0RpINwKbjDH/IVJPKYtIMfBNe8ZiWdZ6Y8yNwCxgoTHmVWANkZpZQ4kUPk/d6/Z3E9ml735jzJnADiK1liYQeY8uPIIx/gX4J/CRMeYZoInIZzQsOv6LOowvYIy5jMhyxfuMMVcT2TnRRuQ9Pyd6/fIOz3mZSDH7XkRqbD1yBH0VERGR40gzokRERKTHsizrl8B04FMiYdIPiNR6+gswxrKsnR3abyGyE97TRMKV7xMJY27gs1lGHZ/hBc4AbgK2ARcDPySybMwN/C+RIOpIx9AUvf8cIqHTt4FR0ft+9QDX3QRcAXxCpM7Uj4gESFuABzu0nU0kSHoWGBttewWR74J3dmj7XnSMS6KvNwDN0es729HwUMb4AJEZVsVEZp5dTSTMG89nSyY7XrOcyGf0VyCdyPtyPdAH+DufzSTb+5ow8Fj0t89bllV5JP0VERGR48fsv6akiIiIiEjPEp0ddgkwxbKsj7q7PyIiItKegigRERER+UIwxgwhUsh9hWVZo7u7PyIiIrIv1YgSERERkR7NGPNNInW1riGy3PC27u2RiIiI7I9mRImIiIhIj2aMKQYKiNSNuitak0pEREQ+hxREiYiIiIiIiIhIl9CueSIiIiIiIiIi0iVO6BpR6enpVlFRUXd3Q0RERERERETkC2Pp0qXVlmVldHbuhA6iioqKWLJkSXd3Q0RERERERETkC8MYs31/57Q0T0REREREREREuoSCKBERERERERER6RIKokREREREREREpEsoiBIRERERERERkS6hIEpERERERERERLqEgigREREREREREekSCqJERERERERERKRLOLrz4caYeODHwNjoTzpwp2VZdxzGPc4D7gCGA/XAM8BtlmV5j1U/GxoaqKysJBAIHKtbymFyOBy43W4yMjJwu93d3R0REREREREROQLdGkQRCZ5+CZQCy4BzDudiY8zZwCvAIuB7QBHwfWDQ4d5rfxoaGqioqCAvLw+Px4Mx5ljcVg6DZVkEg0G8Xi8lJSVkZWWRlJTU3d0SERERERERkcPU3UHULiDPsqwyY0w+sOMwr/8/YDNwumVZPgBjzBbgIWPMhZZlvXK0HaysrCQvL4/Y2NijvZUcIWMMTqeTlJQUXC4X5eXlCqJEREREREREeqBurRFlWZbPsqyyI7nWGDMYGAo8tCeEinoc8AJXHYMuEggE8Hg8x+JWcgx4PB58Pt/BG4qIiIiIiIjI505PLlY+Ovq6eO+DlmX5geV7nT9qWo73+aHPQkRERERERKTn6slBVE70dVcn53YBuV3YFxEREREREREROYieHETtWS/X2Tqt1r3Ot2OMuckYs8QYs6Sqquq4dU5ERERERERERNrryUFUS/TV1ck5917n27Es60HLssZYljUmIyPjuHVO4LHHHsMYQ3FxcXd3RUREREREREQ+B3pyELVnSV5nS/BygCMqgn6iWb58OXfccQclJSXd3RURERERERER+YLryUHUsujr2L0PGmNigJF7nZcDWL58OXfeeedxCaKuvvpqWlpa6NWr1zG/t4iIiIiIiIj0PD0iiDLGxBpjBhlj0vccsyxrHbAWuNEYs/fyvGuAeODZLu7mF15zc/Nhtbfb7bjdbu10JyIiIiIiIiLA5yCIMsbcaoz5BfCd6KFTjTG/iP7smUozDlgH3Nrh8h8C/YD/RouQ/w64F3gXeLkLut+j3XHHHVx33XUATJkyBWMMxhjmzZtHUVERZ511Fh988AGTJk3C4/Fw2223AfDSSy9x8cUXk5+fj8vlIj8/n29+85vU1dW1u39nNaJOO+00+vXrx+bNmzn33HOJi4sjMzOTn/3sZ4TD4S4bu4iIiIiIiIh0PUd3dwD4EbD32q3Toz8AHwHb93ehZVlvGGMuAu4E7gHqgVnA/1iWZR2f7n5xTJ8+nV27dvHggw9y++23M2DAAAAGDx4MwLZt27jkkkv4+te/znXXXUdmZiYAjzzyCHa7nVtvvZW0tDSWL1/Oww8/zKpVq/joo48O+tzGxkbOOusszjvvPC699FLefPNN/vjHP9K7d2++8Y1vHL8Bi4iIiIiIiEi36vYgyrKsokNoMw/odH2XZVmvAa8d216dGIYPH87EiRN58MEHOeecczjllFPand+6dSvPP/8806dPb3d8zpw5xMbGtjs2ceJErr76aubPn8/kyZMP+NzKykruv/9+br75ZgBuvvlmRo4cyaxZsxREiYiIiIiIiHyBdXsQ1VPd+fIa1pY1dHc3ADgpN5FfXTTkmN83JyeHSy+9dJ/je0Ioy7JobGzE7/e3hU9Lly49aBDldDq54YYb2h2bOnUqTz755DHquYiIiIiIiIh8HimIkv3q3bt3p4XG169fz09/+lPeeeedfQqYd6wT1Zm8vDwcjvZ/9FJSUqipqTm6DouIiIiIiIh0sZLdzdjthrxkDwDBUJj15Y3kp3hIjo1pa1ft9TFvQxWLtu5mY0Ujo3ulMG1INmOKUrHbTpxNvhREHaHjMQPp88bj8exzrKGhgalTp+J2u/n1r39N//79iY2NJRQKMW3atEMqOG63249Hd0VERERERKQHsiyLlTvr+c/yUjxOO984tS9Jsc5j+oxd9S3UtwQoSovD7fzs/0nrmwPM/XQnH26q5pT+6Vx+cj6xMQ4+2FTF66t2EQxbxMbYSYtzMSg7gUE5iRSlxWKMIRAK87d3NnHfvM1YFhSmxtIrLZblJXU0+oKkx8dw78zRTOiTxttrK/jhM8tpaA2SHOukf2Y8/1pUwqPzi0mPj+Hsk7I5b2g2E/qkEePo9n3ljisFUSe4zmY8Hch7771HZWUl8+bNY+rUqW3HN27ceKy7JiIiIiIiIl3EsiyCYQu7MdiOw+ycQCjM3GWlzNtYyeR+6VwwLIeWQIi5n5bywrJSNld6iXHYCITCPLW4hFvP6I/LYWNzpZfWQIiC1FiyEt1sqfKydHstlmXx43MHMa53KqGwxSsry3hzTTnVXj/1zQFGFiTzjal9yEvx8I/3tvCPeZsJhCxsBnKSPMS7HMQ4bGyoaMQfDJOd6Obd9ZX86c0NxLsdVDT4SHQ7SHA7aQmEqGv2E45uiZYWF8OEPmnsrGthxY46rjg5n5NyE/l4y25Kapq5cEQuowqT+ee8LXxl1iJOH5jBO+sqGZqXyO8vHc6Q3ERsNoPXF2TehkpeX13Oi8tLeWpxCb+fPowZ4wqP+fv/eaIg6gQXFxcHHNqSOgCbLZLMdpz5dPfddx/bjomIiIiIiEg7y0pqafIFmdI/o9PznxTXUBgNbA7H0u01/M8Lq9hY4QXA5bBxychcbjq1DwluJ/9auJ2XV+4iLS6GQTkJjMhP5rSBmWQkuGhoDfD6ql18UlxLXbOfhpYgQ/ISuWpsAQOzEije3cz7Gyp5eP42dtS0kBzr5LVV5dzx0hqCYQvLgjG9Uvj99GGcPyyHnbXN3PnyWn7zyloAPE47cS471V4/AA6bYUhuIlWNPq584GMuGJbDxopGNlV6yU1yk58aS16Kh/8sL+XZpTvITHBT3tDKJSNzOWNQJluqmijZ3URLIIQvGGZGYQFXjClgaF4SK3fW8fjH26lvCTB9VB5nDs5qm53UGgixqcLLmrJ6Fm+r4eOtu2kNhLh35iguHJ4LwHWTe7d7X88bms2Pnl3Bm2squHpCL35+weB2s7HiXQ4uHJ7LhcNzaQ2E+HBTNSf3Sjmsz64nUhB1ghs9ejTGGH7/+9+ze/duXC4XZ5xxxn7bT548mfT0dK655hq+/e1vExsbyyuvvEJlZWUX9lpEREREROSLZ1d9C2+tqeCqsQXtAguvL8gfX1/PEwu3Ywz89aqRXDIyr+18OGxx91sbuH/eFuw2w7lDsjh3SDaNrUF2e/0YA7ExduJdDjITXWQmuAmFLaoafby/sYonF20nN8nDd8/sD0B5fSsvrijlmSU7sdsMYcvilH7p+AJhXvy0jCcXlmAMDM5OZEuVF18wTEaCi4x4F7Exdp5cuJ1H5xeTHOukrjkAwLC8JO742hDOGJTJmrIGXlm5C7fTxqWj8uiVFtc2liRPEv++aQJrdzWQHBtDTqIbm83Q7A9SXt9KbrIHt9NOiz/Efe9t5sEPtlKYFsu9M0dx/tCcttlcVY0+Hpm/jWXba/n9ZcM4fWDmQd//4fnJ/OmK5E7PuZ12huUnMSw/iS+PK8SyIiHagWaPJbid/POrJ7Mr2u8DcTvtnH1S1kH7+EWgIOoE16dPH+655x7+/Oc/c/311xMKhXjvvff22z41NZXXX3+dH/7wh/zmN78hJiaG8847j8cff5ysrBPjPxoREREREek5yupa2FDeyOmDDh5EHKpw2GoXQGysaOSWfy0jGLbISXKTlegmzmUnLsaBBfiDYfyhMIHoa0VDKztqWmj2B5k2NIcrxuSzeFsN97y7iWZ/iCXba7nnyyMxxrC2rIEbH19CWX0LX5/cm7W76vnBMytwOexMG5qN1xfk53NX8eLyMq4aU0ByrJN/L9nBa6vKD2ksxsDXJhbxo3MHEu/6LCL46XmDeGpxCU2+IF8eW0hh2me7p6/d1cA7ayuZv6WaL48t4NLR+YzIT2or/VLT5OfF5aWsKq1ndGEKk/ult9VVAhial8TQvKQD9MkwJLf9+dgYB30y4tt+74mx86NzB3LrGf1w2m37FPvOSHDx02mDDuk9OBLGGA6l0o0x5qAh1InGWJbV3X3oNmPGjLGWLFlywDbr1q1j8ODBXdQjORT6TEREREREvpgsy6K2OUBKrLNdPdv65gDGBoluZ7u2u5v8NPtCBMJheqfF7TM7ZXNlIzMfWkRlo4+7LhvOlWMLDvr8YNiiNRCipslPaV0LO2qaWbmznhU76yitbaHJFyJsWVwzsYifTBtIWV0LVz6wEJuBcb1TKatrocrro8kXwusLYjMQY7cR47ARY7fhdNhIj3dRkOIhbMFba8tpDURKn5x9UhZ90uN44IOt/PjcgYzvncp1j31CvMvBvTNHc3KvFLy+IFc/vIhVO+uJdzvaZhz9ZNpAvjm1L8YYWgMhinc3kRIbQ0psDMZASyBEY2uQyoZWKhpacdhsZCS4yE32kJHgOlYfoQgAxpillmWN6eycZkSJiIiIiIhIlymvb2XehkqyEt3kpXjYWtXEgi3VLCuppbi6Ga8vyKkDMnj02rHYbYb65gDn3/MhgVCY2V8fx+CcRCobWrnpiaUs3/FZrds+GXFcN7k3Fw/PxR1jY0tlE1c/vAhjDGOLUrht7ioK02IZkZ/Mwx9t5ZWVu2j2h/AFI7WCfIEwvmCorSD13hJcDoYXJDGyIJl4l5PKxlYemb+NeRsqafaHsCyLOTdNoF9mwmG/Hw2tAd5YXU5ukodT+qdjWRYVDa3c/eYGXA4buckenrh+HPkpkRlJ8S4Hj103jj+/tYGwZZGb7GF0YQoT+qS13dPttDMoO7Hdc5x2G4luJ3manSPdTDOiNCOqx9FnIiIiIiLy+eELflbEuaElSFp8DOnxLnqnx5GX7Gk3S2nlzjqun72EqkZfu3t4nHZO7pVCv8zI0qvHFhTznTP78/2z+vOtfy3j7bUVpMbF0BII8T/nDebv/91EfUuAb5/Rn4wEF75giGc+2cGKnfXt7puT5OZfN4wnLd7F9H/Mp9rrx+20UdHgY2KfNLKT3LgctsiP0/7Zrx12kmIjoU1esofC1Nh9ZlvN31zNT55bSZM/yFM3TmBwTvvg52i0BkJc8/BiWgIhHrl2rGYsSY+jGVEiIiIiIiInkFDY4t11FZQ3tHLW4KyD1qhp8YeIcbSvsxMMhfn3kh389Z1NeJx2bjm9LxePyOPtdRXMXlDM+l0NkbpHof1PbvA47QzMTuDkXilkJ7r589sbSI938fw3JwEWO2tbyE32MCI/uW13MoDG1iB//+8myupaeH11ObedP4gLhudyzcOLuG3uKnKT3Dx38yROyv0s/Jk5rpBlJbUsKa6N7sZmceno/LYZQI9cO5bL7v+Y3GQP984czdii1CN8dyMm90vn3R9OpTUQIjk25qju1ZHbaefpmyZgDO2WKIp8EWhGlGZE9Tj6TERERESkJ2rxh/AHwyTFOvc5Fw5b7KhtJjPBjScmslvaxopGfvfaOvpmxPPTaYPaBTWdsSyLbdVNzN9czSPzi9lW3dR2bnRhMucPy+H8YTntQimvL8htL6zipRVlQCQ4So2LISvRRW1zgG3VTYzplYI/FGblznocNkMwbFGUFsvpgzJxO+14nHb6ZsQzJDeR1PgYarx+Kht9bK3ysrHCy+rSSH0lXzDMiIJkZl0z5qAzfJr9QS65dz6bKr1MjS7Ts9kMtU1+5iwu4YqT88lMdB/ye79HMBTGYT/w+ygiR+9AM6IURCmI6nH0mYiIiIhIT1LT5Gf2gmJmf1xMsy/EDVN6c+sZ/fAHw7y4vIx31lWwYkcdDa1B4mLsTBuaQ0qsk8cWFON22vH6gowsSOZ3lw7jvQ2VPLlwO2nxMfxh+nCG5iVR2dDK/729kTfWlLcVrh6en8RNp/ZhUHYib64p59WVu1i7qwGAEQXJTB2QwZDcRP74xnqKq5v42qQikjxOvK1Bapr8lDe0EgxZXD+lN+dEt5Sft7GKd9ZWcObgTE4bkHnAbes78gfDbK320ic9/qCB2h5bqrw89MFWfnTuQNLjtTRNpCdRELUfCqJ6Jn0mIiIiItIVwmHrsMKWvVU2tvLyil28v7GKhVt34w+GOfukLOJi7PxneRnp8TE0tATxh8L0z4xnTFEqQ/MSWbmjntdW7aLRF+Sy0fncdv4gFm+r4cfPrcTrCwIwuV8aGyu81DT5uWBYDu+sqyAQCnPxiDzGFqUwqjCFAVnx+yzp2lbdxGurdrUFX2ErssX932eMalfoWkTkaCmI2g8FUT2TPhMRERERORa2VHn5tKSO3GQ3OUke1pTVM29DFSt31lHt9VPX7Oe8oTncdflw4lwOWvwh/jFvM2vKGmgNhAhbFr1S4+ibGccp/TLa6hWtLq3n2kc/odrro29GHFMHZPLlcQUMyIrsqLakuIb7522hMC2WK04uaFfnCCKFqnc3+dvtbra1ystrq3Zx5uAsBuckUtfs59cvr+WFT0s556Qsbjt/MEXpcYc89rpmP5/uqGN4XhJpmm0kIseYgqj9UBDVM+kzERERETmxhcMWVV4fCW4HHqd9n5k/H26q4u21FdQ0+bEs+Mm0gfRK+yykqWv289d3NvHEwu2Ewu3/fyjR7WBc71SyovWHnlpcwoCsBL53Vn/uemMDW6ubOCknkdhoHafi3U1Ue/0AXDAsh9MGZnDHS2tIjo3hoWvG7BMyHWu1TX5S4o5toWwRkaOlXfNERERERKTHCoctttc0s3JnHfM3V/PehiqqGn0AuJ02zhuaw++nD8PttPPehkpunL0El8NGZqKbioZWyhtaeeYbE7HbDJsrG7nygYXUNfuZMa6QayYWUe31UVrXQt+MeEbkJ7UrZn3ukGxunbOMm59cRl6yhzk3jGdSv/R2/av2+nh8QTGzPtrGq6t2MTgnkceuG9sWZh1PCqFEpKdRECUiIiIiIsdMiz+EMZHt5/ewLIut1U3M21DFkuIabDZDgsvBSbmJzBhXiNNuw7Isnl2ykxdXlNLiD+ELhvEFw7QGQtQ2+Wnyh4DIjKVTB2QwtiiVZn+Ikpomnv5kB8W7m7j19H7cOudTBmQl8O9vTCDB7eSFZTv5wTMreGxBMZeNzuOG2UuwGXjl21PaZisNJGG/4zl1QAYv3noKb64pZ+b4QhLd++54lx7v4gfnDOTqiUW8uaaci0fmdtpORES0NE9L83ogfSYiIiIiXau+OcCTi7YDMCArgaxEFyU1zRRXNxHvcjA0L4l4t4M5i0p4bulOLAvOGJzJlH7prCqt5/2NVeysbQGgMDUWh93Q0BKk2utjSG4it50/mNkLinlrbQX9M+PJSnTjcthwO+24HDYSPU4G5yQwJDeJQdkJ7WYsAbyxehff+/dyWgNhClNjee6bE8lMiMxGsiyL62cvYcGWaobkJrFqZz1P3TSek3uldu2bKCJyAtHSPOkyxhh+9atfcccdd3R3V0RERERkL+X1rTy2oJjWQGTGUq/UWC4dnU+Sx0llYyv3/XczFQ0+fjd9GKnR5V6tgRCPzi/m/nmbaWgNHvQZMXYbF47IITbGzmurynl15S5iY7w06lUAACAASURBVOxM6pvOzVP7MnVABgWpsW3t31i9i9tfXMNXZi0ixm7j5+cP5vpTeh/2TnXThubwdJKHhz7Yyk+mDWwLoSDy/fR3lw7j7L+8z9LttfzpihEKoUREupGCKBERERGRHqi4uglfMEz/zHhsNoNlRQp4b67wsrnKS0VDK6MKUpjQN4231pRzx0traPaHiHM5CIctGn1B7npzA1MHZDBvQxWBUBibzXDxvR8x62tj2FbVxG9fXUdpXQtnDMrkJ9MGkpfsYVOll8qGVgpSY+mdHkdDS5DVpfVUNLZyzknZZCREdmC746IhbKlqond6HDEOW6djmDY0h4l90nliYTFnDMo6qsLeIwuSue8rozs9l53k5oGrT2ZnbQuXn5x/xM8QEZGjpyBKRERERORzxLIsFmzZzWMLitlV38KVYwq4bHQ+ca7Pvrq/vKKM7/17OaGwRYLbQVFaHCU1zdS3BNraGAOWBTYDYQvG9ErhT1eMoCg9snvc6tJ6Zi8o5o015Zw5OJMfnTOQupYANz2+hAvu+YhQ2GJQdgJP3TiBiX3T2u47ujClXX9jYxxkJ+1blNthtzEwe/+1l/ZIinVy6xn9D/t9OlyT+qYfvJGIiBx3CqJERERERI5QRUMr5fWtDM1Lwt5hOVmzP8inJXUs2lbD4m27Ka5u5v6vjmZUNMgJhsK8umoXvdPjGJKbRGsgxAuflvL4gmI2VXpJi4shJ9nNL19cw91vbuDSUXlccXIBGyoa+clzKxhTlMqVYwpYVlJLye5mLhyeQ7/MePpnJtA/K54kj5Nl22v5aHM1uckeZowrbNfHoXlJ3H3FCO6+YkS7fr906yn89tW1jOudysxxhfvUYxIRETkaCqJOYM8//zyXX345L7/8MhdeeGG7cx999BFTpkxh1qxZnHXWWdx99928++67lJSUYLfbGTduHL/+9a+ZNGlSN/VeRERE5Mj5g2FeWVnGoOxEBuckYEz7EOn9jVUUVzfx5XEFuBx2LMvipRVlvLWmoq1+0ZrSerZWNwGQHh/DuUOySYmNoay+ha1VTawurScYtrAZGJKbhIXFrXM+5bXvTCHR4+D2F9fw1OISAJJjnYTCFo2tQYblJfHnK0ZwwfAc3E47y0pqeWx+MU9/soPHP44UDD+lXzoPXTMGT4z9gEvNJvVLZ1K/w5sJlJ3k5t6ZnS9xExEROVoKok5gF1xwAYmJiTz99NP7BFFPPfUULpeLyy67jHfeeYf33nuP6dOn06tXL6qrq3n44Yc544wzWLJkCUOHDu2mEYiIiIgcmd+9to7HFhQDkJng4oxBmZw/LIchuYn87rX1PL9sJwCPzt/Gd87sz9xPS/lwUzU5SW48Tjshy6JvRjwzxhWSmejirbUVvLCsFH8oTFaCi/zUWG48tQ/je6dycq8UEtxOlu+o44p/LuDHz61gaF4STy0u4cYpvRmal8SHm6qxLJg5vpDRhcntgrHRhSmMLkyhviXAKyvL2FHTwvfO6o/bae+Ot05EROSoGMuyursP3WbMmDHWkiVLDthm3bp1DB48uIt61PWuvfZann/+eSorK/F4PAAEg0Fyc3OZPHkyc+fOpaWlpe3cHjU1NQwaNIhLLrmEhx56qO14V+ya90X/TEREROTYCoTClNe3kp/iwRjDG6vLufnJpXxlfCEjCpJ5f0MV8zZU0uQPAWC3Gb51Wl9GFSbz21fXsbWqiXiXg59OG8jM8b32WYK3hz8YxmY44FK2WR9u5bevrgNg+qg8/nzliH1mY4mIiPR0xpillmWN6eycZkQdqdd/BuWrursXEdnD4Lw/HNGlM2bMYPbs2bz88stceeWVALz77rtUVVUxY8YMgHYhVEtLC83NzViWxbhx41i6dOnR919EREROeOGwxac76thV38Jurx+7zdA/M54+GfFYWDT5QsTG2MlK3Lco9v58vGU3LyzbydvrKqhrDjCyIJkZ4wr47avrGJGfxK8uGkKMw8aVYwpoDYR4f2MVn2yr4ZKReQzLTwLglH4ZvLGmnHFFqZ0W5N7b/naG29v1p/RmQ3kjTf4gf7hsuEIoERE54SiIOsGdddZZZGZm8vTTT7cFUU8//TTx8fFcdNFFAPj9fu68806eeOIJduzY0e763r17d3mfRURE5Iuj2R/kuaU7eXR+Mdui9ZYOpCDVw9iiVFwOG/UtAcJh6J0RR9+MePpmxNEnI55qr4//fXUd/11fSYLLwVknZdE/K56nF+/gp8+vIsHt4N6Zo9sFR26nnXOHZHPukOx2z4tx2Lh4RO4xG68xZp/i4CIiIicSBVFH6ghnIH3e2O12rrzySh566CHq6+txu93MnTuXL33pS20zob773e/y4IMPcssttzB58mRSUlKw2Wz8/ve/Z8uWLd08AhEREemJQmGLZ5fs4E9vbaTa62NEQTJ/vWokg3MSSYuPwRcMs7nSy7YqL3abIc7loK45wKJtu/lgYzXGQKLbgQW8u76CQOizchPGQHyMg9vOH8Q1E4vaaindNKUP76yrJDvJTUFqbDeNXERE5MSmIEqYMWMG9957L3PnziUpKYn6+npmzpzZdv7pp5/mmmuu4Z577ml33S9/+cuu7qqIiIgcZyW7m3HYDbnJny3N/2BjFW+uKScjwUVavIsar5+SmmZiHIaZ43oxLD+JFn+Il1aUsrWqiavGFtAnI36fe4fCFqtL61mwZTcvLi9lfXkjY3qlcP9XRzOmV8o+y9Tykj1MHZDR7tjXT9l3NnYgFGZHTTNbq5rYUuWlJRDiqxN6kR7vatfOYbcxbWj2PteLiIhI11EQJUyaNImioiKefvppkpKSSE9P5+yzz247b7PZCIfD7a758MMPWbhwIYWFhV3dXRERETnGmv1Bnl+6k+eXlbJ8Rx1JHif/umE8Q/OSWLClmutnf4LdZmgNfPZ9IDvRTWNrgKcW72BEQTLF1U3UtwSwGXjow61cPCKXEQXJNPtD7Pb6WV1Wz5rS+raC4IOyE7hv5mjOH5Z91HWSnHYbfTIi9aTOIuuo7iUiIiLHl4IoAeDLX/4yf/rTn3A6nVx77bU4HJ/90bjkkkuYPXs28fHxjBw5knXr1jFr1iyGDBlCY2NjN/ZaREREjoY/GObfn5Twt3c3U+31MSg7gR+fO5A5i0r4yqxF3HnxEG5/cTVFaXE8981JeJx2apr8JMc6cTvtNLQGeOaTHTy3dCen9E/naxOL6J0ex6wPt/L4x9v5z/IyAFwOG0NyE7n85HxG90phUt90MhJcB+mdiIiIfBEpiBIAZs6cyR/+8AeCwWC7ZXkAf/vb33C73bzwwgs8+uijDBs2jOeee445c+Ywb9687umwiIiI7FdDa4B31lbw6spdlNa18MDVJ9MrLQ6I7CT3h9fXUd7Qym6vn2DYYlxRKvd/dTRji1IBuGh4LjMeWsj3/r2czAQXj319HEkeJ0C7neMS3U5umNKHG6b0aff8/zl/MN87awCtgRCeGDsuh027w4mIiAgAxrKsg7f6ghozZoy1ZMmSA7ZZt24dgwcP7qIeyaHQZyIiIieqQCjM6tJ6PimuYfvuZnzBMMFQmCG5SZw+KIMYu52HP9rKM0t20hIIkZvkpskfIsHt4NmbJ1Jc3cx1jy0mM8HNhD6ppMe7GN8njVP7p+8TFJXsbuauN9fzrdP6cVJuYjeNWERERHoiY8xSy7LGdHZOM6JEREREusCqnfXc995mVpXWc8OU3lw9oRcOuw0Ay7LYVd/KpkovcTF2hucnE+OwsXxHHQ99uJWVO+vwtgZpbA0SDEf+ETE1Lga3I3L9f5aX8b+vrQPAaTd8aWQeM8YXMjI/mTVlDcx4aCFXPbCQqkYfBSmxPHXThH0KeXdUmBbLvTNHH8d3RERERE5ECqJEREREjqEmX5CQZZHgcuD1BXlzTQVzP93J/M27SXA76J8Zz50vr+WpxSWMLEhmY4WXzZVevL5g2z1iY+zkp3jYWOElwe3g9IGZJHocJLidDM1NYmxRCpmJny2RK61rYd6GSuqaA1x+cj5Ze50blp/EI9eO5ZpHFlGQEsucGw8eQomIiIgcLwqiRERERDqxo6aZv727idomP1MHZjCpbxpNvhCldS24nTYm9U3H7bS3u2bR1t1c99gnNPtDuBw2LAv8oTD5KR5+fO5Arp7YiwSXg7fXVvCH19fz3/WV9M9MYProPPpnJdA/M566Zj8LtuxmfXkjt194EleNLSDedeCvbHnJHr4yvtd+z4/rncq7PzyNJI/zoPcSEREROZ70TUREREQEaPGH2FLlpby+lUXbdjN7wXZsNshIcPHu+sp92nucdqYOyOCrE3oxuV8aa8oauGH2ErKT3MwYW0i11wcGzh2SzaiC5HY1mM4Zks05Q7L325dpQ3OO+fjykj3H/J4iIiIih0tBlIiIiJzw1pY18PXHPqG8oRUAY2D6qHx+dO4AshPdbKtuYsn2WlJiY8hL9lDt9fH22gpeX13OG2vKGZGfRGldCwluB09eP55chT4iIiIinVIQJSIiIp8bobDFip11JLod5CR5iDvKZWSLt9XwPy+spKrRR4zDRlqciy+NyuPyk/PJSIjUSfpoUzU3P7mUBLeDv88YRWFqLPkpHtL2qqPUJyOePhnx7e596oAMfnHhYF5YVsr987YA8MQNCqFEREREDkRB1CGwLGufLY2le1iW1d1dEBGR48SyLH707ArmflradmxkQTI/OXcgk/qlH/J9QmELb2uQR+Zv4+//3URBaiyXjsojELbYVNHIH99Yz5/f2tBW0LuioZV+mfE8et1YcpIOL0RyOezMGFfIlWMKCITC+9SMEhEREZH2FEQdhMPhIBgM4nQ6u7srAgQCAex2fckXEfkiuuvNDcz9tJRvTO3DSTmJlOxu5qnFJcyctYjxvVPJT4kFINHjoE96XHSWUhzZiW7KG1p5/OPtPLd0J1WNvrZ7Th+dx68vGdquQPfmSi/PL9tJZUOkXWqck2+f2Z9E95H/XW+3Gew2/f0kIiIicjAKog7C7Xbj9XpJSUnp7q4I0NDQQEJCQnd3Q0REjoJlWXh9QXZ7/exu8lHV6OfTHbU88P5WvjK+kJ9NG9Q2E/nGU/vw5MLtzFlcws7aFgBqm/00+0Nt94uNseMLhrEsizMHZzEkN5EEt5P+mfGcOiBjn+f3y4znp9MGdc1gRURERKQdBVEHkZGRQUlJCS6XC4/HoyV63cCyLAKBAA0NDdTW1lJYWNjdXRIROaGFo3WchucnY7d99vdiZUMrqXExOOy2Tq+rbGzlyYUlzFlUEtlRroPzhmbz60uGtvu71u20c8OUPtwwpU/bMcuyKG9oZWtVE1urvGypaiI2JrJEriA19hiOVERERESONQVRB+F2u8nKyqK8vByfb98vzdI17HY7CQkJFBYW4nK5Dn6BiIgclQ3ljcS57G3L4fbwBUP86NmVvLyijIl90vjbjJHEuxz85pV1PLW4hIJUD9dP7s2VYwuIjfnsa8bsBcX89tW1BMMWZwzMZHyfVNLjXaTFu0iLiyE93kVWouuQ/sHHGENOkoecJA+TD6N2lIiIiIh0P3MiF38eM2aMtWTJku7uhoiIyHERDIX3Ozvp1ZW7+Of7W/D6grQGQpx9UhY/O28QsTEO/v1JCT+fuxqAK8YUcMvpfUmPd9HkC3LrnE/5eOtupo/O47VVu4h3OUn0ONhW3cSMcYWs39XAspI6cpLcPHD1yQzPT+aVlWXcOudTzhiUye0XnkTv9LiufBtEREREpIsZY5ZaljWm03MKohREiYhIz9caCLXt2BYMhXngg63c8+4mfnHhSVw9oVe7tm+sLueWOcvomxHHwOxEAsEwb64tp1dqLJP6pTNnUQlT+qdTlBbH05+UEAh99l3BYTPcfcVwLh2Vz4byRm6Zs4zG1gB/uXJk2852i7bu5gfPrKDa6+PGKX148IOtjChI4onrx2tXOREREZETgIKo/VAQJSIiXwTvb6zi+sc+oTA1lin901lWUseq0noyElzUtwR46dbJDMpObGt7w+xPGJqXxJPXjycuupvcwq27+eEzKyita2Hm+ELuvHgITruNnbXNvLpyFyHLwmCY2DeNkQXJbc8OhsKELAuXo33AtNvr45Y5y1i4tYY+GXG88M1JJMfGdN2bIiIiIiLdRkHUfiiIEhGRzzPLsmhoDZLoduy3dlJZXQsX3PMhKXEx9EqNZeHWGmJj7PzmS0MZ1zuVaX/9kNQ4J8/ePIlH52/jH+9toV9mPE/dOIGkWGe7ezW2Blhb1sC43qnHZHOOQCjMc0t3ctrADHKSPEd9PxERERHpGRRE7YeCKBER6W7BUBi7zewT/NQ0+fnZ8yt5a20FaXExjChIpm9GHBkJLrKTPIwqSCY7yc1VD3zMhvJGXvr2KfTNiMcXDGEzBme0NtT7G6v42iOLiYux0+QPcfGIXO68eAgpcZqdJCIiIiLHx4GCKO2aJyIi0k3K6lq46O8fEeOwMblfOqMLU3A5bDQHQtzz7ibqmwPcOKU3tc0BVuyoY/7manzBcNv1SR4n9S0B/j5jFH0z4gH2WSI3dUAG3z6jH6+t2sXtF57EaQMzu3SMIiIiIiJ704wozYgSEZFjIBy2eGlFGbXNfqaPyt9n2RtElqrtmakUClvMeHAha8rqOXVABgu27Ka+JdDWdmBWAn/98kgG5yS2HbMsC68vSElNM0uKa1m8rYbBOQncekb/4z9AEREREZFDpKV5+6EgSkREjoXNlY3c9sJqFhfXAOBx2vnSqFz6ZSaQ4HZQUd/Ku+srWbGzjqkDMrjz4iH859My/vLORv7vyhFMH51PKGyxq76FUNgiFLYoTI3FEQ2tRERERER6Ei3NExEROQqfltSys7YFt9NOnMtObpKHnGQ3K3bU869F23lt1S5iYxzcddlwhuQl8tj8Yp5fVop/r2V0IwqS+er4XrywbCdn/+UDgqEwXxqZy/TR+QDYbYb8lNjuGqKIiIiISJfQjCjNiBIROeFYlkV5QyubK73kJXvonR6HPxRm7rJSnvpkB0Vpsdw4pQ+5yR5++8paXvi0dL/3SnA7uGx0Pree0Y/0eFfb8WAojNcXpLE1SGyMnbToufL6Vv73tXWU1DTz5PXjSHDvu4RPRERERKQn09K8/VAQJSJy4giEwny4qYrnl5by0ebqdvWY0uJiMMZQ7fUxICuesrpWvL4gHqedQCjMN0/ry0UjcvEFwjT6ApTVtbKztpm8ZA8XDs/FE2M/wJNFRERERE4sWponIiInrDVl9bywrJQXl5dS7fWTGhfDtCHZDM1LpG9GPNujhb+bfEG+OqEXk/ul0dAa5KnFJWwob+TmqX0ZmJ3Q3cMQEREREflC0IwozYgSEflC2lLl5edzV7Fwaw1Ou+HMQVlcdnI+UwdkEONQEXARERERkeNFM6JERKRHqmxo5Y9vbMDCYkLvNPJTPCzYspsPN1czMCuen503mNS4GFoDIeYsKmFHbTNZiW4aWgLM+mgbboeN2y88iemj8kiJi+nu4YiIiIiInPAURImIyOfSe+sr+dGzK2jyB4mLcfDCskjBcLvNMDQvibmflvLOukpmjivk+WU72VXfSmyMnWZ/CIALhufwq4tOIjPB3Z3DEBERERGRvSiIEhGRo7a+vIEYu40+GfEHbesLhlheUsfSkloMhgS3gxZ/iFWl9awpq6exNUggFKa2OcCg7AT+PXMCfTPi2VzpZUdtMycXppIU62RDeSM/eX4l9763mZEFyfzlqpFM6JOG1xek2RckM1EBlIiIiIjI541qRKlGlIjIUVlTVs/l93+MPxTmaxOL+O5Z/UnyOPdpZ1kWf35rI7M+2kprILzP+dwkN0PykkiLi8Fpt5Gb7OG6yUW4nfvfkS4UtthR00yvtFiMMcd0XCIiIiIicmRUI0pERI6JumY/b6+toDA1lnG9U6n2+rlx9hKSY51MHZDBowu28eLyUr42qYivjC8kLd7Vdu3f3t3Eve9t5vxh2VwyMo8JvdNwOgze1iB2m2nX9lDZbYai9LhjOUQRERERETmOFESJiMhBba708qc3N/Df9ZX4Q5HZTCf3SiEYClPT7Oe5mycxNC+Jr07oxV1vbuD/3t7Ife9t5uyTspjQJ43aJj9/fWcTl5+cz12XDcdm+2z2UmyM/ioSERERETlR6Nu/iIgc0IoddVz76GLCFnx1Qi8uGZnLytJ6/jlvC6V1Lfx9xiiG5iUBMDQvice/Po5NFY08uqCYd9dV8MrKXQCcOySLP0wf1i6EEhERERGRE4tqRKlGlIicQBpaA/x3XSWLi2uYNiSbUwdktDvf5Avy8ooyNlZ46ZsZR2yMnV/MXU1qfAxPXj+eXmmfLYMLhMKU1bW0O9aRZVls391M8e4mJvZNw+XYf70nERERERH5YlCNKBGRE0xVo4+l22vYVOFla3UT1V4ftc1+NpZ78YfCOO2GOYtKOKVfOtNH51HR4GNzpZc3Vu+iyR8ixm5rW4LXPzOeJ64fT3ZS+13onHbbAUMoAGMiNZxUx0lEREREREBBlIhIjxQOW1R5fTS2Bmn2B0mJjSEv2UNzIMQ/523hoQ+34gtGgqTcJDcZiW4y4l1MnJTGtKE5DMlNZM6iEv7+3018tLkagJRYJ9OG5jBzfAGjClIorWth++5mRhQkkeDedxc8ERERERGRw6WleVqaJyI9RGsgxJ/f2sDHW3ezudJLayDc7nxsjB2HzdDQGuSSkblcO6mIAVkJxLn2/28OXl+QsroWcpM9xB+gnYiIiIiIyKHS0jwRkR6uvjnAjU8sYfG2Gk7pl87Mcb3onR5LosdJbIyDqkYfmyobqWsO8LVJRYwsSD6k+8a7HAzISjjOvRcREREREYlQECUi8jngC4Y6LeRd7fWxurSe3722jm3VTdwzYxQXj8jthh6KiIiIiIgcPQVRIiJdbG1ZA9uqm9hZ28yG8kaW76hja3UT+SkeJvZJIzvJzdqyBtaUNVDe0ApAgtvB7OvGMalfejf3XkRERERE5MgpiBIROU7eW1/Jm2vKuWRkHhP7ptHQGuD2/6zmxeVlbW0yElyMLEjmguE5bKxo5O11FTS0BOibEc/EvmkMyU3kpNxEhuWpYLiIiIiIiPR8CqJERA6BZVks31GHLxgmPd5FTpK70yLglmWxblcjf3xjPe9vrMJuMzz9yQ4m90tj++7m/2fvvsOrqrI+jn9PeiD0TugdBKQjHaQoAmJDqg0Vex103tFx1NEZHXvDjqIIiAI2rHSk9450CCWUEBLS2z3vHyuXm0BChwvk93keHuDctu9p9+x11l6b6PhUHu1Wm6suK09kiXCKHhVc8nhcMjyePIfpiYiIiIiIXOwUiBIROYH10Yf5z8/rmbM55siyoACHjnXK0OfyCpQqHJpdLDyRP9buZWtMEkXCgvhnr/r0b1mZ8Yt38v7MLRQODeTbe9vQrEqJfD8rIMAhNEBBKBERkZMWvRJCi0DJGv5uiYiInATHdV1/t8FvWrRo4S5ZssTfzRCRC0B6poeJy3axcmccQYEOgY7D/oQ0dh1KYe2eeIqEBfNw19rUK1+EmMQ01u45zOSVe9gTn3rkPYICHNrULEWPy8rTu1EFShQOOfJYakYWAY5DSFCAP76eyMXpcDQEBkPhC6Q2WmYaBIX6uxVyvkz7N8Rsgpu/BMfxd2vOTOIB+zuijH/bcS6kHIK3GkNYMXhgEYQU8neLREQEcBxnqeu6LfJ6TBlRIlKgua7LN0t28s60zeyOS6FU4RBcIDPLQ+kioVQqUYj7Otfk7g41KF7IF1jq2ySS/7u6Hqt2x5OR5aFMRCjlioYRHpJ3NlNYsLKcRI5r6ywoGgmla9n/U+Ph406QlQ43fgq1uvm3fbuXwmdXQ/M7oMeLEBRy4tecC0kxEFr0/H9+ciykJ0Hxysd/3vIxsPBDGDgOilU688+Ni4Iln0GLoVC8Sv7P82TBnDchJALq94Fikfk/N3oVBARCucvyf87SUfDn6/bvvauhQuPsz/FAeiKEFc3/tZlpsHMRxG6FOldBkfLHPmfuOxbcavtQ/u9ztrgufNkXDu+Cm0dDjU4nfk1aAsx5C8o3hPrX2vrKKSUOts22dX0qQTrXhWVfwrx34LoPoXLLU/sueVnwIaQdtj9z34IuT535e4qIyDmljChlRIkUWB6Py9Pfr2Hcoigur1ycx7vXoWPt0jgX+51vkfMpK8P+DjyDYvrpyfBqTQgvCffMhsKl4JcnYNEnUKoWHNwMXZ6GjsPz7vSuGGfP6frM6bchp4S9sGUGNLrJ972+vR3WTwZPBlRuDf2+gKIVzs7nHY/rwrZZsGaidfwPbQccC9rVuhJ6vQmBJ7ivmJEC+9bBvtVQpQ2Uqet7LC0BNvwG63+AqAVQojpUuNwCf3WusvW9exmMGwiZKXD/AihaMe/Pid0KH7SDjGQo1xCG/mbDpfKSlQH71kCFJnlv04wUmPu2BZcyUyGyBQz93fddo1dZYCq8OGRlwnf3wJoJvtdXamkBlAbXQolqvuUeD7x5mWXRDJkI1dod+9lRC2BUb6hyhf279T1w1X/ssSn/snaVawjVO0HLO6FUzex1mQiTH7X9JDPFljmBULcntHvUF3RZPQEm3mmPPbwcSlTNex0dLa+MvO1zLTh4vCDdjnnweU8ILQYZSdDrDWh+m+/xhL3w06NQpbUFWhP3w/ghELPBHi9RDTo+AU2H+F4z4U5b3+0fh27P2rKkg7BlOlx2fd775KEd8ONDtj+DBbH6f2X/zkixNjS+GWp1Pfa1KYcsgJUUY/ts/T72vJQ4y4aq3sHWzfrJ8OAiKFIRln9pAe3G/Y8NimZl2v5Xph4Ehx37ea5rrw0vnv96PV1710Di3rMfXHddO0eEFIZKeSYgHCvpIPzxNASHQ4O+ULX9ic8nFyqPB1Z9bb8FKXF2fr7igRNnyHk8dqNh4292rKNN3gAAIABJREFUbmx4EwRc4Nnrf/1i59lGN/mWpcTBnmV2nBcqAcWrnZvvkRQDh3fb55WqeXZuOPhDRiqs+96298W6z18EjpcRpUCUAlEilxzXdYlJTCfT46FCsfAjy5fuOMTLv66nfa0y3NAskrembmLisl3c37kmT1xVVwGogiI51jrzFZpc+Beb51pmOsTvtKyT5IPW2QsuBE0GnXyWw4Shls10zavWAT2d4+ivn+HrQfbvml3hyqfh027Q4k7o/rx1XtdMhDunQOVWuV+bkQpvNoDUw/CPXb5O5aHtsHik1Y458Bd0/zdcPuD47UiOtYyKhR9bIKHb89D+UYjbCW9fDm0esCDNjw9BRDm498/8Ay1nQ9RCmP4CbP/TOhfV2ltwJD0JDqyHdT/YOur1uq33lEOQsA/K1rPXZ2XCjBdh3rvgybRlRSrAsFlQpJwFID67ytZVkQoWWImLgr2rLOsnsrkFc2a+bMMjk2KgekcYNN46vX/8E7bOgD7v2HO/6G2d7Kv+Az89YoGCAeOOvciPXgk/PGif0/Vf0OFvuR9P2AdjbrRMpMtusG3+2/9lByOfsEDQ1Gct+6n57bYPr/sBuj0H9Xrbv9f/aJ8D0OWf0OkJ+/fORTCyOwQXtnV2649Qqbnvs7fPtaBjSGEYNsPauXMRPL7ejpG3G0P5xtZxj1pgwY/rP4TKV8DYfrBnuWVv1exqHbQ1E2DFWNu3erxo6+TjLlC6NuxbC81uhd5v2Gcv+RwO77H9/2j71sHnV8OVz0Cru21ZShy8Wsv2xbunWeaVxwOLPrbMQm+gY+JdsPEPC9B8f58Fizo+YeszIwVGXWPr2pMJIUUAF4LCLBMxLcGOid1Lod8oO8ajFsJnPaB4VYjbAT1fse/z3b2QuM+2Z9d/5W7/ht9g0jBwPdDj3xa0nP8+PLbWAgYLPrBtHBQGt3wHVdvmfv3Eu2D1t/Z4QLAF1Pq8Y+tr5n8tgF2oNLzXwrZPSizEbMx+sQM1r4SKTS3od2gHrBgDCdFQ9jL7nuUa5P68yY/Z9qjcGur3tvWwdRbEbrEgZ/VO0PDG4w91zMqELdNsv6nWHgqXhVkvWzac64GBX0Pdq+25qYdh8xQ7FuN322fWvDL/9z7ajvl2rtgxF8JLwKNrIDQi+73jbf8rWT33a+J2wujr7ZgPCLTARtFIy2ascHke3yfD1qW/Ou3ebLrAYPuNOtqSz2y7OYE2TDMl1mqGXfuurf+8bJ1lx8Th3YADuLZ9u/7LzgEpcb6bLZkpdsxGr7TjpkRVKFrJAuWp8Xb8tRoGhUrm/x08WZa5F17C9522TIeo+Xbe8Ab5N/4BCz+AywfZfpbzWmXeexY8DAqHJzb7tvN398HKsb7nRTaHnq/mPr+djLidtj/kdcNh7Xd2LHp/T0Ii4IGF5ycY9fvTdh1QvpFdv9XvnXs/TTxgx3RqnJ0Tc95wycv89+H3f9h5+WQzU13Xtndw+ImfezwZqeAE+C+z+jxSICofCkSJXFpiEtN4bPwKFm2LJS3TA8CDXWrxWPc6rN0Tz+BPFuI4cDg188hrHutWh4e71lIQqqBIT4KRPexOeJEKdle99b2+jIasDFj7vWUu5MyiOBMrxlr2xtUvHT9IE7PJOkfRK63TWfNK6PWaXQwf8z2Sc9/lzcq0jnedq3zPz0ixoUWX3XBsJwtg4Ufw+1O+C8qcbhyZ+06rV0qcXYB5szKSYuD1utY5TE+0IEDvNyGibP7f0+OB+e9aR718Q1v2/f3w12QLGPz6hHWGQwrBg4utQxG7Fd5pCn1H5M7KAFg2Gn580P59x29QtY39e9I91nGt0NgCG4VLwb1zfK+L2QSBIdaZcF1YNd46wilxlpWRdMACDQ8shMWf2sX/Iyst+2T7XBjVy9rS972jvl8WzH7NMh7CikOhUvYZxatC2fq+DKuDW2D6i9aRDi9uF/0d/mYX9K5r7zHjReu8dhxuAZejs2H+eMaGOPV40bbL9BctGFWjM7R92AII22bD5QOhXi/rNHw9yC7kB4yFL6+zddv/S6hxpa+zk5VpHZqZ/7PhXJVa2vNXT7AL974jYOdC6xSGFrNtX6srbPrDt40Wfwo//80CWde+a98xLRH+fM064oVK2X65daYvwAHWntHXW6ei3+e2T4N1ftZMgoY32HZt0BcCQ61j4mbBVf+1QGFOsdvg58dh11L421+2T/3+tO37986Bcf0h+ZAFKKt3sLYs/tS21aBvLKC3/ifLDho80YJuC96HB5fYOSMuCr651YJPEeWsM3rTZ7auc0qN9+3jwYVtW937pwX4Vn4Nj66yDu5XNwIuPLjUN0QVbJ/8pIutm/KN7bXgy6wKCLJtOnhidkbWj/Y5982x7fNGPdt/rnnVtu3kR2H5aFuWfNCyiAaOs31w3nu27Np3fcMbszIsYBmzGe6dbcHn+N3Zga37LZCMa9lFpWvbOhs43oIsmWkw+1X7U+Fyq7dVoprt/+82s2O+7UMW6C1e2b5r4j64fbKvkxmzCUa0su3b40Xbj765xTrwgaG27w0cZ8/983Wr7VWyBlz9snVGl4+x/eTQdttXnAAL0tXoAnPesCBTt+ctwBcQaAHsnx+HOj0hfpdlEjoBFsgqVdv2/UPb7N93T7NzFFiAa9di6wgf2mH7aUK0bzuGRNix0nSIBf5it8Fd0yArzfaxQ9vteUHh1tnt/A8LGOYMQmRlWoAt5zl901QL3EaUs+wv7zmh7UN2vh3Z3T5vwFionR2cjF4FY/vbb+LAcfbdNk+B356y/XXgODsmvJIOwshutv/d/IVv+ZqJdtyEFbNAYKN+vv3Gk2WP7V4Ke1bY71/7x/MPjKQnw+JPbL9OjrWATdW2cM1rFiCb8gzMzz7ftrzbtq83KJa43xeEvPVHW2fbZttNg0PboVZ3ywKsc7XvHJyw1zI4w0tApyehdg/Y8KtlPSbtz7uNTqDt5yGFLQibuM+Ov7DidtyEFoEr7rNgafQK25/LN7Rz/54Vdg5IOmAZnnV7WubtjuzfpdCiduPlwAYb3hxcyIKDZRvYObxQSdtuiz6Cis0s++mmzyxQlZ4Mr9W264amQ2zfmvOGta/FULjm9ZO78bZtNowbZM+9+Uv7LfHa8Kvtp5Va2rEYEGTnguodLah6Lq+jt8yA0dfZZ6cn280lN8vOERWbWtbnkcAzgJN94yo7CzV2K6z61m4sBYXab+x7LeHgJrveeGhJ3kOoc4rbCd/eZtvvwSWnXy8yPclutJWsAQPGnN57XEQUiMqHAlEil44tBxK5/fNFHEhIY1CrqlQpGc7aPYf5dukurqhRkvXRCRQJC+Kbe9qQ5XGZtGw3ZYuGMrDVcYYzyMnbMsMuss9GvY9zxXWzh1f9CJ2fsovEzVPtYrnNA1C1nV2AHlhvdznvmpL/ECSPxy4Uw0tAk4G+5VEL7P28w30OboH321hH45rXfJkMOaUehtmvWEYA2AVr8arWuStb34aueANlYLVrfnkShkywC0CwDJ5fn7DO/E2f2wXhz3+zTnVYMesUegM0ADsXW8eyegfrOBSvap2YsGKW1ZF4wIJAoRF2ATft3zY8K24HVOsAt/1kn7HwI/j1SevUb5kOM/5rF+J934fa3W19rPveAjuR2Z0Pb0exYjO4e7qtr9dq2/Ov/8iyKlZ9nTsYlpUBL5a1QM2V/8y9Tb1DwQ5ts4yY9o/Z8jfq2zC0fp/71s+9c6zDnhRjw3kykuxCNrSoZR1VagV93rLaQXE7rfNbpQ3sXmKd1pwdsKnP2bCx/mPszqzX7NcsMyG8hG1bN8v3WFgxqNvLHlv8iXWiKzaxjl/MJruw7fO2XVQv+gga3WztySsY6d0Pv7nFOjdg26ZGZwuWJB+0AGHvN3NnD6z9zo6DsGJ2QTzom7yHQoEFEbbOsv0sOMw+b9Q1tl1xocNw6+z+/Lh1SGv3sPfzdkjmvgPTnregb6thto8n7LG7/Ff9xzpaX/a1Y7HjcOs8bfzNtt/gb3MPL0qJs219eJe919X/s85SXJQFC47OoPHaPtfa3HcENBls271sPXv/Qzvgl+Gw7c/soXSOdSKv/KdvnWemwWt1rLOzc6EF1m74yPf+Ganw29/teO33Rd5D/bzbau5bFiToN8q2U+xWeLe5DQ3ZMs2Cc7Hbsr/ff32v+3qQBQnqXwtrJ9lwvpI1bDtun2v7yNeDfR3XjsNtny9bzzq7U5+D++b7gheua8fgnOxMrKtegjb3591ur9ht8FFHC6Il7oPrPrD9KiPFjtki5aHrs7btR3a37dL6PjtfJe6FJkMssJ4zk+DLvhbcavOABThvm2xZOyOvskDM0N8tIDfpHstye3S1LwMpM90yWdZ9D3dNte0DvuBHtfbHdhSzMm3/CQq3jECwAMb399v6Ld8Imt5qbal5pXWuAwJt/wqJyD1Mb+tMCxzWzA6CbZ5qnfL0RHvcCbDgR7NbLfC2/U8LIjTuZ+8dtxM+7mzrIynG3vu69+0c5ARYZs+qry1wcuNIOxe7rrV15Vg7zze8wfaPjzrYsXzfXNtvv+hjwYxHVtlzJz8GEeUtQ+jGTy3o+efrFjgaMtF3QwDsu46+wc6nfd62AIgn04LD27MDoN7zaMI+eKeJtdeTadssMBRa3mXbccH7to/j2BDrlFg7L9XpaQHC1DjbjmFFbVutHG/7SpU2NkQ4KBRWZZ9PKrWwdd7qHssimfeuBRN7v2nDUifdY+eg++ZBmTq+75OebMfc0lEWFCwaaUNTa/ewwMbORXDPrNzZM6mH7XgMCrfzpHc/Cgy275FzH87KtH3EcWy9zviv73xcqpad6/etteMyuJB9bpm6dp6LXmm/ux2G2zn2l+G+ddz6XjueNv5q73lws+8zWwy1LMQ3GliGbP/RvvP6rT/6asClJcC0F+y3JOf1R0aqfb+kGPvtKVzafgdjNlrWYskats0ObrIAf8masH+d/a6VbwS3fO+rkefNzrrpM6je2Y6dnQvtRkGz23Jfu+Tcx2a9Ysd0RFk7PsKyjy1vJlbxqpaNWLaebY8P2trv2b1/2vpPOWQBy2VfwMGtdn1TvaO1PSQCfnjAtt2wWTac/pMrszOjX4B2D8P2OXYzyZth2/BGy2zNTLff+0qtcmf+bZlhQf+0BKtbef3HcHl/e8x17fc7JdbadWCD/aYlH7T10KifL1gNlmW7fLQFK5/YfOzw39TDth26PWvXgBc5BaLyoUCUyIUnLTOL6ev30752aYqE5V1zxnVdflm9l3enbyI900O5omGs33uYQMfh09ta0LRKiSPP/XpRFP/6cS2lCofwzT1tqFxSs+mcdasnWLYCQIfH7S5uRjJsmmIXWTnvqp5PGal24bB3tWU+uS4sGGFDtNo9Ys9J2Gcd5RXZd6WKV4Ur7rfMkuKV4Y5ffCn0XsmxVo9m0x/2/9b3QY8XrLDvjP/YXcLB31jg4qsb7UK3wuV2V/ie2XaRnLAX1v1otVK2/Wl3fpsOsQtPb0dr87TsFPgsC6bU6mqZFyN72IVQuYb2fhkpli2UlW4X9j1fsQu58UOs87dzgV349R1hgar0RPiwPbjYRd3RF0HeYTftH7eO5hd97GK+1pXW4Vgz0YbO1LzSOlKeLF+Gxv71Vjtm/1ooVgXio2x5cCG7WA4Msc5nsUrWUb3lO1s2qpfdfW3Q1zr+0SvtzmfOO6xvNbIL0xs/9S3bOtPer+8ICwqVrmOdwgMbYURL60g1v9222Wt1fB38Kf+yjkyH4ZblcnAzdPq7PZ6zKPOct2wIGBw7LDAzHT7takM67ppqF8B7Vtiy+n2sowh2YRq3w4KSm6fChl/s4v/yQXah6b0Le3CL7a97ltv/r8jO/jjRXez0ZGtj1bbQ4DpbZ2kJVjerahvrOBxt2gvWEb3hYwsSnoqDW6x+UouhvuFurmtDS8o1PLaI966l9r0ObbPjoOcr1nnySoqxu8OHtkHhMhaw7P7vvIdV7F9vQ/8a3XTyd99dF0a0tgBpr9dsnz06sy4zDXYtsWM9r+zByY/DkpG2/z+wyLJ+8vqck2nT0c+beDes/sbuyg+bATNfsv3k8ewMrlmv2Hml56uWHfZ2Y8veueI+eKWGrYs+b1vgadb/LJOp3jXWgZ90t52PIlvAnb8f25Zlo23/bPvQybXdm4FVoQncPSP/fTN2K3zUGdLi7TzY7mH7++jPWPu9ZRgEhtp2v+MXe07MJpsYIDjcgjNf9rXzsrdOV851mRxr2Y5nwnUtoPX7Py1QVbKmBclPVB9q0ScWPKjeyQII5RvZcMEi5a1jnVftqZy2z7XvVrm1neNzZpK6rt1I+PXvdtwM/taCKdNfsCy3oBDbFzdPg0l35Q7cb50FX15rN1wWjLAsof6jLcC0Z5k9p3F/C0Dmte6SYy2wGTUPal9l7Vo+2oK/01+0rKp+o6yO3+KRdtOiVE3LPJr1CqwcZ0MPKzazfat2dzv+0hJtuNm8d+28FV7cggup8dnZT+0sCJwzqHxohw3z3TrDHuuQXSdw6Sj4ebh9Tq1usOn3vIeEemVl2nE17XkLqpRvbEOD+7yTu17a2RC30wIP3nOhJ8s3/DlnJnPCXnueN7Dl8dhQ3sJloGYX3/O89cpS4+y9StbIvtk0HJZ/ZcGM7+6xc9jj63L/hrkujLnJbm7cN8/ee2x/XxbW0Sq39gVgv73DAlZeFZvCkEm5hx5mZVqm3KEddn5Mjbfz+455dhOm5pWWnVu9o/1GrJloGYq49nuVmWKvTUvIfr8MCxh6b+DU6mb7yIZfYOgfed/szOvcu+E3y3jt8k8LsK3+1oI68bsskP/r3y34/LcNts/OecN+c9d+ZzdL6vaCm0batln4kWVLl65jNwbHDbT9edgM+6zfn/Zl6nkVr2KBzJgN9nejm+xY2LfGAta1e9g15A2f5P4Nzsq0dm+ZYTcbT2V47gVKgah8KBAlcmFZuuMQ/zdxFZv2J1K1VCFGDGpGw8hiuK7LlgOJ7DiYzJ74VH5csZvF2w9Rt1wRapWLYG98KqFBAbx0QyOqljo2cyDqYDKFQgMpHaFp10/bzkV216jnK7lno1r/E3xzm93BLFnNLoqKV4HD0XYXCqyGTY8Xz2xK7cQDVvdk3xq74D7Re2WkWBbBlhl2Z3znQgvUNLzJAhlHX7TsWmp3yxreaJ2HrbMsiFSxqd35L13LLnY2T7Psj8N7bKhd7Fa761ukgl08NbzJ3id2m2UYzH7Vhg9cdr1lRhWvDOUaWcczK93WVfVO0OIOX8ZQTnFRlia/f51l+yz+xC5WOzxu7ejztqWJT3/RLtLmvGkX28GFoFQNW5Z2GMb0sw5IodLW1v3rrJD00fWWvCbdY5kX3ruUt/1oF3GZafBOM+toXfe+ZQwdnU2RkWod531rbH1UbQPjb7VMs9AidiE89HfLbilV0zpvi0fCk1t9tS7y8kUf2653TfUtG9vfLr4fW2sZYBt/hSe2WAful+G+zBGA8bdkX4zPte9Q75rcQa28ZGVY4CKksLX56P1m/18WRPFk2MX2uh9sfd83L/86IZnp1vn3ZmQc/Xlz37L13vKuczfUwXXtbm3h0qf/+lNpW1qCnUNqdD529jWwdZJ80Parc/GdvfWHanW3zL0nNh+/jsvRvHWlGvU78T5zqg5sgK9usiBLg2t9hcWvfc/Wx5h+1lG5/iNbNx93tg5fp/+z7MXBE6yjD7m3i+tah2ftpNx378/UmkkQ2ezEQ5cPbLTj4ngzE2ZlWFZH0n649Yfcw4D2rLBjPi3BMlIeWZX3MXM2pSfbTYna3U9uaLbrwk8P2xDVer0tsJtf9mJ+kmIsAJrXcQFWlHrCHZYtd3i3ZUm2fdDqjDXqZ79tIRF2U8IbGHRd2193Lbasi/vmZmcgxVsQunZ335DX/HiyrAM+/QW7sXTF/fabN/U5C9APmQBjB1hAt89buV97cIsFTSo2y/t49nhsec7HPJ78A5uua0GboyeHiN9lx/bSL+xcdt+8E18bZKZbEP7P1+14u3HkuR1Sdi55s3p6v2WZyS3vsm10tPhddv1RriHg2vms95sW5AgrZus2eqWdg5vd6luHWZkWAAyJsOHlEeXz3kZ7V1vGUbmGFuQv18Dec/loC9Ym7vNlawaFWVCm09/zn2AhK9Pq/q2ZaPtg0n77fe3xwqmtn29vt2A3rgWkGlxr66F+HwtstRgKPf9n2YTvtbTjq3pHuxab85Zd15atbzch6vay4zs0wheAvmua71hr1M+GeIcVt2zAQiXtsT3LLWi6anx2xmCIBfJv/9luKlRq4ZuwwXXtfRd/atu0xR2n9n0vUApE5UOBKBH/2h6TxFtTN3IoOYOktEyWRh2iQtEw7u5Yg49nb+VgYjpd6pVh6Y44YhLTjryudEQoj3evQ/+WlQkMuEgvIM7UnuX2I93p72dWLPngFrv4iGye/4UwWB2UdT9Ascp2R6xYpF0gzPivDS265Ttrx9rvbXlkM/ux/2uy3f0sXdee4w1ixW6zO7Z1rrYsoNAIu/jYvcTuOnk7iSlxFtRY9qX9iMOJO1UZqdZB2/ZndubDYLsA37nYN7PSyVj7vQ2DyEy1C4zYbXaHuHhVu3j13plb/KkFgjr/wzJqEvZa1lJ8lAVZ7p5pKd7rfrRhVEHhdvHealjuIQT5SUvILjb8m3Uqhv5m2+vznpY5kJVhw4EGjrMAx0edbJveM9uXFp+Raq9f94MF0zo9aZ2Z/CTshXdbWKfqtp9yt3PJ51ZjJrKF7Yd/++v4NaHA1v+4QZauftdUu7jzFgoNKWLtHzT++O/x40NWo+KJ7CEKcTvhrYZ2DHR5yjojPz1stRumPQ97VlrtHW8nw3uHtGIza/cDC09czBTsLj7kHySL320ZVt4Z27zZYnLhSDkEr9ezY7lGF7j1+1N7vetakL3OVSfe10/H0QGkD9racZ203zIL7/zD1zn88w3bv2t2tSDEk1vzP6elHrYO14U8K9TSURZMvvbdYwMC2+faDYHWwyxL7kKUlWHboUrbczf5xY55FvQpd5ntu0GhMOVZC1oDDPoW6vTI/ZqNv8PYm3PPang6YrdZVkyz220fStxv2aneffbh5fkPYT9f0hItgybn8KcTOVEA8GLgybIh6BkpdgPkrun5199a9qX9hgYEWTDdW5PvbMlvfWamWXbmrkX2u1ir+/FvOB0tI9Wuu6p1OPWZeRP3W+ApspmVJwgIsLIGi7KHVt+/0DexR+w2C0h5h6mumWg35DwZlsnU7Xnfd0tLgNfrW5Z6zEa7vnlg4fGvxZNiLIC1bbYNASxR1ZfR9uRWO797Swi0fchu3l4iFIjKhwJRIufPzthkfl4dTcfaZWhQsSiLtsUybPQSsrJcapSNICwogMaVivFItzpEhAYRm5TOPyatYsXOOFpXL0X7WqWpXS6CyOLhlI4IJaCgBKAyUqzYdVyUDcUoUt7qs3x1E6QnZKfsTzz+zD1HSzxgWTPLv/KlZxcuY4Gjjk8ce1GZmWZDQCKbWyaNJ8suCBL3WSDp+g+PHb6W05bplo1SsanVL3Acq82wY75lBRWrbJ+9dpJlFYUUsSBJmXqWxZC43wI3bR60AFPxqpahA3ZH8IcH4MbPfBdg3jTp6z868SxpJ7Ou5rxhwabwklZ7pdltx850cnSGSMxmu0PZ7dncs7pELbACt6c6lMSTZRlpJWvAZdfZst3LrIAxjt0J9g4pStxvHdCcxY5PR8wmu7A/uuOdlWF1beJ2WHr54G9P/jvknC0oPck6NN7CyM1uPf7rvbWl/rHbLmS9NTGGzbR968AGy9C69l0r4l2vN1w3Ine736hvGWSX3WBDYc6mqAW27htce3bfV84O74xSF8OdZm+h97Ditn/nnO3MW+QbrDPZb5QfGngepcTZeehizVo5W1LjLavE2xnPSLGaXUUqWDZZXusneqVlqZztYIu3M9/ukQs3QFhQ/DzcMqVLVLegYH7HietahnbFZr6C9QVB6mHL6PIGiZNjrZRBuctsKPDx7Fxkv+k5a0B6/fp3qxMKvokZTpW3tED/r6x22cge2TPNjr24A6RHUSAqHwpEiZw9e+NTeXLiKioUDWNo++rULe+7MzB74wEeGrec+BQbqtWkcnHW7TlMpRLhfHZ7S6qVPsVU9nPB44Flo6wGSdW2UK3jmdedONP2zH0L5o+A5BjAseyU5rdbRkqR8tnDs4Zbunr9PnanJXG/pQ8fPVWx69rQtqVfWP0esAuXZrdaevRfky3bpGgk3PFr7iEQ3hl5Bn1rGTbjBljtpyv/mbvWy/F478b1+I9lO31/n005X66hFW6M3WJ3yhreYG1Z/5O9rlxDm5XMW4h25v+shsqjqyyA9UkXy24pVtkygGI2WRHu5rcfO1zgTKQetrvQpztLyrky+zX7u+Pw8/u5K8baNvQWzD1dc96yujaPrDpxMNVbn8ZbdHn6i5Yd8tQeXyHtV2vY/hy98tjaC5AdpBwB98+/JIqAyinYvx5++4cV1T2VYXn+kJZgx1fLu3IPV/P6oL3N5Jbf7JZSMPhrCvjE/fbb0+WpE9fRknPLOxlDxydyT+Qh+YvZZNlLJ5ol73gObrEbcpddf/o3tbIybKKWKm2tdEFmmk0EcKH/Pp2iCzYQ5ThOCPAMcBtQFtgIvOS67riTeG1h4N9AP6AcsBP4BHjNdXNOUZM/BaJEzo61e+K5c9QSDqdm4HFdUjM8NK9agorFwwkKcPhhxW7qlCvCKzc1ZtG2WMYsjCKyeDjvDWpK8ULn+QIqLwc2WJBk50IrmpqVBjg280izW62Gz+HdVhcoskXeHebMNLtzezZqWHiyLMtn5TjLOGn3iN31/P1pq4FTuq5lBBUpb3dsxt5sqemVWlqWUuI+m9XEO3Qs9TD8cL8Fdyq3tuEl1TvZnbGcQwmiFtrMOMWr2Ph1byBu8mM2m82TW09cfDU/rmvFTzdW80TIAAAgAElEQVRPseKPZepbwCsgwIbkpSfmvqDds9wuFhpcl/si+9AOG1ff5Z92R+vrgTaLztLPLXU7bofVgLh/3pkNWZTjc107Xiq3PrNMBde1YVMnc+G1ayl8eiUMGGf1ncYOsALXDyz0PWfMzVa0FqzY89E1RdKTLJXeG9gUuRjNe9cK7D625tSGI4nIpcV17cZQvV4KCp5vu5da5v6p1oXL6fv7rS6dE2DX3fnN/noRu5ADUaOBQcD7wCrgBuBqYIjrumOO87pAYAbQFvgIWJ3971uA913XfeBkPl+BKJEzcyAhjUnLdvH2tE0UDw9m5O0tKV80jLGLopiybh9xyenEpWTQpW5Z/nN9QwqFXIA1KjZNtaLWIYWsqHTDG61I6uYp9uMevzP384MLwxX3QtNbrFB19AobHrZjvk1f/MDCvKer9UqOtSFVNTr7anZkZdhQjEKlbCaX2a9avZkuT1stn5x2LbUi1DmHwmWkWn2EkMJW2+fznpB00DKmEvdZrYhD22yM+4lmR9o6ywJbZepZLaKgMBvOlLOg4ulKPAAftLEhBvf86Rubf6pG9bbim6ERFlh4YLFN4fvz4/b40UVv5dKQdNAynrzF0d9saIGwm0b6nuMdvle6Ljy4yH9tFTmXPJ7sYa7qeIqIXLS8tdw6PwWd/+7v1pwTF2QgynGc5sAS4HnXdZ/LXuYAs4FaQBXXdTPyee1NwLfAw67rvptj+evAY8DlruuuPlEbFIgSOXU7Y5OZtfEAMzfsZ+aGA2R6XNrUKMXbA5pQtuhpZsscLTn2/KSmbpttMxKVrmMzDx2dzeTJshlD9v9lWUKFStrsXmsn5X5emfo2FG7p59D63mOnmAbY+IdNo7ztTwsatboHrnnFHvvjGZj3Tu7nd3sO2j92et8rbqelasdFWeCsdC0rfFi948m9fsOvNvyu6RCb8e6TLjZzXJNBp9eenPavtxo9J9uWvKwYB9/fa//2Fi53XQtAhEbYFM5y6XFdeKmy7YddnoL/VbVC9x0e9z3HO4tQy7uh12v+a6uIiIjI8bjZsxhWannuJjvws+MFovyZnnAz4AJHKom6rus6jvM+MBboCEzL57Udsv8ee9TyccDjQH8sS0pEToHH43I4NSPf4XKv/v4XI2ZsASCyeDh3tq9OvxaVqFX2LA6BWvKZDQU7Ue0LTxZMfdayl1LjrKhr3/dObsplyB7SNsDqJN3yfd71oAICoVY3++NVrb0FiKIWWEZP+ca+u9LJMVYAvMvTuacQ3jrThpAVjbRhdkkHrNBnhcbW7nnv2DSyLe+22jaFSh07A86pKF4ZHlxqmUeFS5/60Km6PaHDcPjzNYheZSnDtU8w1fPJKlsfOMPaPA2utSlui0b69hHHObOZgeTC5zh2fB/aDvuy65yVb5T7OZVaQv1rLYgqIiIicqFyHKjS2t+t8Bt/BqKaAdtd1z1w1PJFOR7PLxDlrRabctTy5Oy/84y6icixktMzeW/6ZmZsOMDWA4mkZXq4+rLyPH1NPSqXLHQkiLFhbwIfztpKr8YVeLx7HWqULoxzprPYZGVYBkPZBpaNtGKcBaEAFrx//EDUgg+sTkZkCyhaCaLm24wTQyZZhtOaCbBpihXVLlHNZrTIGaT6/SkL+Nz6w6kXJa/Q2P4creVdNpPX2km+jvCBDTD+Vpsp7c7frZ5HVqYN+Zv8mA19q9jUhgUGhfpmPjtTQSGnNpPe0bo8ZdPtbpsNVdv5t3D70UIKw8BxNtPfJTSziJyEElWtdti+Nfb/cg1zPx4UCv1Hn/92iYiIiMhJ82cgqgIQncdy77KKeTzmtSH77/bAHzmWezOlIs+saSIFw+yNB3jqu9XsOpRCh9qlaVezKoGBDmPnbWHTpifwlAql8kO/4Djw78lriQgN4sW+DSlROEfGVGq8DV071Yh+yiH45lYLdOBYDaLdS62Idq2uMOVfVkspstmxr43ZDNNfgDo9LSDhODbka/QN8Pk1lo2UEG0FvlMPQ0YSbPwNbv3eXp+ebMWw2z50doqLe1VtZ7WVFn0CTQZbDamxN1tQaNB4X1HZwCCbbezjzrb++n1x4c3GFhAIN35mU8s2vcXfrTnWmQztk4tXiWqweSrsXW2B5DOZ9UZERERE/MKfgahwYH8ey1NzPJ6fMcC/gI8dx3kAWAO0Af4DZB7vtY7jDAOGAVSpUuXUWy1ykTucmsGPK/bwzZKdrNoVT80yhfnmnja0qp5dk8l1eSThLQqtW0pWrMODn8+kU+OazN18kOevvSx3EMp1YcJQ6xh2fsoKa59MltTBLTC2vw2xufplm21u/U8WhBowxop+z3wZlow8NhDlybIZ4ILCoM9bvs8rWx/u/APGD7GAz7XvWUALbBjX8jE2m1pQiAWhPJlW6PhschzLivpluM2EsWaCzcJ3y3eWyZFToZIwbCZkJEOxSme3HWdLRBmbfU7kQlGiGmSmwpYZlg11plmZIiIiInLe+TMQlYJviF1OYTkez5Pruvsdx+kNjAYmZy9OBZ4EngESjvPaj4GPwYqVn3qzRS5sSanpLN+wBadwGQqFBFK/QlHCgm340q5Dydz84Xz2xKdSr3wR/tW7AYNaVznyOACzXqHQuq9xa3UjcPNUMrbN5e+bkqlbrgiDWx8VvF33gwWhyjaAmf+12kc9/5f/cKmkGJjzpmUMhRSG2370TVXa5R+5n9v4Zlj5NXR/wTqbCz+G/WstG2r/WitSfXQ2RPHKcM+sYz+3RmeblW73UqjaBnYusOVnOxAF0Lg/TH0OVo6FxgOg+/P5Z20UKgmch6LsIpcK7/Daw7ugQV+/NkVERERETo8/A1HR2Ox4R6uQ/fee473Ydd25juPUAhoCRbGsqDTgLWDGWWynyEVjf0Iqv494nAEpX3NfxqNM9TSnRunCvD2gKeWLhTHk04UkpmUyftgVtKpe8tgaT8vHWEDp8kE4vd+Al6vwYsM4Dh8syZNX1yMoKxUSYy2DJy0BfvuHFQu+ewZMe95qNv012TKbanSy4VPFKkH8Llj4ISz53DKALh8Inf9hgaP8tLgTlo6CHx6wwuAph6BUTShe1YJUjW8++RVTtR3gWD2qqm2sUHnpOudmZr6wojBkIgQGQ2Tzs//+IgVZzjpv5Rvm+zQRERERuXD5MxC1DOjqOE6ZowqWt87x+HG5rusBVnn/7zhOHyAAmHI2GypyQVj0Cexagtv3PZbsTKBRZLFcmUw7DiZx26fzGZ/yC8FOFh+HvcuCK0bw+JIwhrw/lbpF0tiXXJKv7mpF86p5BGA2T4OfHrbsoT5v2xC2Sq0od3Ax4+/Jngb9u/ss06dqOxv+lhBthYEDg6HHi1CxGaz/ETZPgVVf22tKVLNAlOvCZddDp79DmTon/r4VGlvG0oZf7PN6/u/YGbJOVqGSNoxn+2zo8DfYuRDq9T699zoZVa44d+8tUpAVqww4gHtsoXIRERERuSj4MxA1ARtK9wDwHIBj6Rn3AvuA2dnLipFd2Nx13fj83sxxnMLAC8BuYNy5bLjIeZeVYTWTkmP4Y08Y9+zqQbtapRh5W0vCggNZuyee2z5bzBVZSynnHII+7xCw6GPaLnqYOWUb4qQvw011WXL99LyDUHtXwze3Qem6cPOXFoQCqNYeZr9iNZw8WVbzqHJrC0DtmAvN77Ai414Nb7A/Hg/sXwfbZsH2uVD3Gmh977F1kk7k+o+snlStrmdeC6Zae1j6uQ3rSzl0boblici5FRwGRStC4j4oU9ffrRERERGR0+C3QJTruosdxxkLPOM4Tkkss+kGbOa721zXzch+6vXA58AdwCjv6x3HmQEsATZiRVaGApWBnq7rJp2v7yFyru2NTyVt7c9UTY5hR2BVuh34gkdqXc7bm+HBscsZ2q4a94xeSkRYEC9XWQF7S9nQt7rXwMShBKUnQ+u7YeGHXJGxGGia+wPSk6zAd2gRGPytb2Y3sODNrJchar5NmZ6VbtlSZepZ8KpMvbwbHRBgw2bKN4Q2D5z+ly9Z3f6cDdXaw8IPYP779n9lLYlcnErWgPASF95MkyIiIiJyUvyZEQUWPNoO3ArcgwWVhriuO+YkXrsEC1JVAhKBmcCNruuuOSctFTmP9sanMnHZLiavimZ99GHeC/6IiIAiDMx8lqlFnuex+Fep3u0DHp26j6nr91GzTGHGDKxJxKdToNUwy2iKKAO3/eR7081TYdMf0HpY7g+b/h+bve72X6BYZO7HKrW0Wd+2/Qkbf4PKV9jsdGBD5y4mVdsCDqwaD+EloVReJepE5ILX6w3wZJz4eSIiIiJyQfJrIMp13TTg6ew/+T1nFDkyoXIsfwJ44ly1TcQfXNfl+xW7eeb7tSSmZdKsSnH+3aMSPecsZ3+dgfzYuzeFDteEz67mujl9aV2hBb8GdeX6gcMoseEb65w1HZL3m9fuAUs+g/RkCClky3YuhgXvW2Hwau2OfU1wGFRuBcu+hPQE6PTkufvy51qhkpahtXe1DcvTtO8iF6eTqTEnIiIiIhesAH83QKQgmf7XPtbuObbU2cHENJbMn8Hul5rxx7cfU79CEWYM78yk+9txa7HlBHrSqdDhNkpHhELFJvDwMrjyGSq4Bxh64H+UeK8ezHzJZmkr1yDvD6/dHTJTbeY4gMw0m5GuaCR0ey7/Rldrb0GosOIX/3Tp1Tra31VUH0pERERERMQf/D00T6RAcF2Xd6dv5o0pGwlw4Pa21bmvc03+WLeX0fN38Nfew3wd8iKVArbyQcjbeKq7BJRoZS9eOR5K17EZ6byKVoSOw6H947B7Caz7wWa9a/do/o2o2g6CC9nwvDo9YParELMBBk+EsKL5v65aB+AlaDIYgsPPyvrwm1pdYcEIqN7R3y0REREREREpkBzXdf3dBr9p0aKFu2TJEn83Qy5xHo/LCz+v4/O527mhaSSFQgP5akHUkccbVCjKg5U2c83qR0nt+iJh8dtgyUgIiYCAIEiNgyufscDTmRo3EPatgQFj4ePO0KgfXP/hCb5AFswfAU0GQeHSZ94Gf4vdasWORURERERE5JxwHGep67ot8npMGVEi51B8cgbDJ6xkyrp9DG1XnX/2qk9AgMN1TSL5Y90+ujcoR4vKRXA+HA6lahHW9l4IDLaMnR3z7E2CQqDF0LPToNrdYcMv8PUgK9h91X9P/JqAQGj38Nn5/AuBglAiIiIiIiJ+o0CUyFk0b3MME5btol75IlQoFs7/fvuLfYdT+VfvBtzRrhpOdoHsFtVK0qJaSfB4YNFHcOAv6P+VBaEALrvO/pxttbrb33FRcPOXVsBbRERERERE5DxRIErkNKVlZpGclkWJwiEA7I5L4b4xy0jJyGLSsl10CVhBk8JFuWvYYJpULZX7xYej4bf/g22zIOUQVGkD9Xqf+0YXr2yfVazyxV94XERERERERC46CkSJnIbEtEwGf7qQTfsSeOmGRlzTqAIPj1tOlsflj4euoPyf/yBszTjIAMa/DZcPgO7/tmFuAFOegY2/QcOboEYnqNsTsrOlzrk7fj0/nyMiIiIiIiJyFAWiRE5CUlomqRlZlIoIJS0zi3tHL2XN7njqlivCI1+v4KNZW1kXfZgPb6hGtV+GwI450OnvULYBrJkA89+DYpXgivtg/3pYPQHaPQLdnz//X+Z8BbxEREREREREjqJAlMgJpGd6GPDxAlbvjufySsUIDQ5k3/Z1/FF3EdVDE/mudDueWl2Bt2qu4uoZD0B6EtzwCTS+2d6gQV8Y0w+mvQD1esHMl2xGvHaP+PeLiYiIiIiIiJxnCkSJnMDb0zayenc8g1tXYdOeGG7Z9SK9Qxfg7AyG8BLcmDiZGwqF4OxOh2odoOcrUK6B7w0cB3q/ASOugPFDIHoldHxShcJFRERERESkwFEgSiQ/MZuI/emffLexF/1bNOE/1zeCVd/CpPlwxQOW0VS4NGyehvPXZKjZBRpcl/fQt+JVoOszVqA8tBi0uf/8fx8RERERERERP1MgSgRw96/n8E9Ps7r+Y+wLrU5KYjw9Fw6hVPJWHiocSp8+g+yJK8fZjHM9XoSAAFtWp4f9OZFWwyB6FVTvCOElzt2XEREREREREblAKRAlAmwa9yR1Ds2mYdQC3kh/gluCplAiYBubnCr0C5hJkJMOCTGwdQa0f9wXhDoVAYFw/Qdnv/EiIiIiIiIiFwkFoqRA8nhcAgJsCN2sP2fS6dBsFpboTZOstUxMfBHHk0lW56epXbUNfNEb1k6ClEPgeuDyAX5uvYiIiIiIiMjFSYEoKVBSM7J4+rs1/LRyD13rl6Vb/XKETn2FlIAwmg59hxDHYwXFi5QjsONwq/dUph4s/hSyMiGyOZSu7e+vISIiIiIiInJRUiBKLmmu67L9YDJhwQFkHD7AY99vYenuZHo2LM/8rQdZt3YF00Pnk9rsXsKLlLIX3fl77jdpeRf8Mtz+3fPV8/sFRERERERERC4hCkTJJe3JCav4dukuegYs5I3gD3iTEsR0fZ5m3XuRejCKQxM/wtkXTOHOj+T/Jo37w5RnISsNGt54/hovIiIiIiIicolRIEouWROX7uLbpTv5sNpsrt77EfuLXkb5gFSqzL0X1v2PsEPbqADQ4W9QpHz+bxRWFK58GlLioHCp89V8ERERERERkUuOAlFy6cjKgLQEKFSSrQcSeeaHNbxe+ieu3vs1NLyJsn1HgBMAiz6GzVOg2S1Qvy+UrnXi927zwLlvv4iIiIiIiMglToEoubi4rhUQP1pGCoy+HvauJm3ANzz4k4fugcu4MfFraHoLXPuu73VtH7Q/IiIiIiIiInJeBfi7ASInbedieL0ebPg19/KsTJgwFKIWQFgx+OpG6u+bzGtBH0D5xnDNa3kHr0RERERERETkvFIgSi4OWZkw+VFI3Avf3wfxu225xwM/PwYbfoGer/BjyzHsyCzJ6yEfEhzgwM1fQnCYf9suIiIiIiIiIoACUXKxWPQR7FsD3Z63WlCT7oa4nTC6Lyz7kvS2j/FzeB+G/76XtyLfwNPgOuj3OZSs7u+Wi4iIiIiIiEg21YiSC1/8bpjxX6jdA9o9wkGnBKWmPEzGW03IIpAPCj3MiJktyfQso3LJcF4Y3I6AiKv93WoREREREREROYoCUXJhSzxg2U+eTJK6vsSrP61jzMIy/CvwKlqFRzOq9ONEB0UyrHFR2tUqTfOqJQgLDvR3q0VEREREREQkDwpEyYVr0xSrB5WWwK72LzFk9E6iYpPp37Iy3bp+QYVi4bzk7zaKiIiIiIiIyElTIEouLGsmwarxEL0SEqKhbAN+avIhf5uSQakID18Pa0Or6iX93UoREREREREROQ0KRMmFI3arDcMrWhGqd8IT2ZxXD7Tig2m76VK3DG/c3IQShUP83UoREREREREROU0KRIn/LP8KytaHyOb2/xn/hYBguHMKKaFleHLiKn5auZtb21Tl2T6XERjg+Le9IiIiIiIiInJGFIgS/9g0BX54AEKKwB0/gxMIqydA+0eZstPhuR9nsTsuhf/rWY97OtbAcRSEEhEREREREbnYKRAl58fWWVCqFhSLhLREmPwYlKoNGSnw1U1QqiZuWFGe2NOFCVOXUKdcBOOHXUHrGqX83XIREREREREROUsUiJJz7+AW+PJaCCsGvd+CXYshfhcM/R3Ci8PIHhA1nzERdzBxfSJPXFWXYR1rEBwY4O+Wi4iIiIiIiMhZpECUnHvLvwInAErWgAl32LKWd0GV1gDEXj+OeRPf4X+HOvHewGb0alzBj40VERERERERkXNFgSg5t7IyYeU4qNUdBoyBWa9A1Hzo+iwAccnpDPwlk52pt/Px7S1oX7u0nxssIiIiIiIiIueKAlFybm2ZDgnR0PMVCAyGK58+8lBSWia3f76YbTFJfH5HS9rVUhBKRERERERE5FKmQJScW8tHQ6FSUOfqXItd1+X+MctYvTue9wc3UxBKREREREREpABQIErOrsT9MKoXlG8MTYfAhl+h1TAICsn1tMmropm18QDP9WnAVZeV91NjRUREREREROR8UiBKzq7Zr9oseYejYc0EW9Z0SK6npGZk8fKvf1G/QlFuaVPt/LdRRERERERERPxCgSg5ew5thyWfQ7NboNvzsHQUZKRAuQa5njZyzjZ2x6Xwar/GBAY4fmmqiIiIiIiIiJx/CkTJ2TPjJQgIhE5/h/Di0P7RIw9t3p9IdHwKqRke3p+xmR4NytG2pupCiYiIiIiIiBQkCkTJ2bFvLawaD+0ehqIVcz90OJVr3v6T9CwPAGHBATx1TX1/tFJERERERERE/EiBKDlzHg/89n8QWhTaPXrMw2MW7CDD4+HTW1tQMiKESsXDKVs0zA8NFRERERERERF/UiBKTl3UQshIgppX2v8XfgjbZkOft6FQyVxPTcvMYuyiKK6sW5ZuDcr5obEiIiIiIiIicqFQIEpOza6l8OW1kJkKbR+GxjfD1OegTk9odhsej8tPq/bQpkYpyhYN49fVe4lJTOe2ttX83XIRERERERER8TMFouTkxUXBuAEQUQ5qdoF571g2VGhRuPYdcBzGLtzBP79fQ8ViYYwa2oov5m+nRunCtK+lwuQiIiIiIiIiBZ0CUXJy0hJhbH/ITIPbJ0OZulD5Cpj2vA3JiyjLrkPJvPTLeppULs6euBSuGzGX5PQsnu3TgIAAx9/fQERERERERET8TIEoOTnLR8P+dTBkogWhAJoMtD+A67r8Y9JqXODdgU0JCHC44/NF7I1P5abmlfzXbhERERERERG5YCgQJSfmurDsS6jYDGp1y/MpYxdF8eemGF7oexmVSxYC4McH23M4JYMiYcHns7UiIiIiIiIicoEK8HcD5CKwa4llQzW/Lc+HZ/y1n2d/WEuH2qUZ3LrqkeVhwYGULRp2vlopIiIiIiIiIhc4BaLkxJaNguDC0PDGYx5asj2W+8YspV6FIrw/uJlqQYmIiIiIiIhIvhSIkuNLPQxrJkHDGyC0SK6HdhxMYuioxVQoFs6oO1ppCJ6IiIiIiIiIHJcCUXJ8ayZCRjI0vz3X4swsD4+NX4ELfDm0FaUjQv3SPBERERERERG5eKhYueTPdWHJSCh7GUQ2z/XQBzO3sCwqjrcHNDlSnFxERERERERE5HiUESX52/g77F0Nbe4Hx1f7adWuON6etok+l1ekb5NIPzZQRERERERERC4mCkRJ3lwXZr0MxatC4/5HFsclp/PQuOWUjgjlxb4N/dhAEREREREREbnYKBAleds8FfYsh47DIdCKkGdmeXhw7HKi41IZMbgZxQqpOLmIiIiIiIiInDzViJJjuS7MfBmKVYHGA44s/s8v65mzOYZXbmpM86ol/NhAEREREREREbkYKRAlPulJsOkPmylv9xLo/RYEhQCwYOtBPp+7naHtqnNzi8p+bqiIiIiIiIiIXIwUiBKTHAsfd4K4KChcBq64H5oMPvLwDyv2UCgkkCevruvHRoqIiIiIiIjIxUyBKLGheD88CIejYeB4qN0dAgKPPJyZ5eH3tXvpWr8cYcGBx3kjEREREREREZH8KRAlsPhT2PAzXPVfqHv1MQ8v3BZLbFI6vRqV90PjRERERERERORSoVnzCrr96+H3p6F2DxuOl4fJq6IpFBJI57plz3PjRERERERERORSokBUQbf8K/v7ug/AcY552Dss78p6ZTUsT0RERERERETOiAJRBd32P6FyKyhcOs+HfcPyKpznhomIiIiIiIjIpUaBqIIsJQ72roaq7fJ9yuRV0YQHa1ieiIiIiIiIiJw5BaIKsqgF4HqgWvs8Hx63KIqvF0dxTaMKhIdoWJ6IiIiIiIiInBnNmleQ7ZgDgSFQqcUxD300awsv/foXneqU4cXrGvqhcSIiIiIiIiJyqVEgqiDbPhciW0BweK7F4xZF8dKvf9GrcQXevLkJIUFKnBMRERERERGRM6cIQ0GVehiiVxwzLG97TBL//mkd7WuV5p0BTRWEEhEREREREZGzRlGGgmrnwuz6UL5C5ZlZHh77ZgXBgQ6v9mtMYIDjxwaKiIiIiIiIyKVGQ/MKqu1zICAYKrU6suiDmVtYHhXHOwObUqFY+HFeLCIiIiIiIiJy6pQRVVBtnwORzSCkEGDZUB/N3spVl5Xj2ssr+rlxIiIiIiIiInIpUiCqIEqNhz3Lc9WH+mtvAolpmfRqrCCUiIiIiIiIiJwbCkQVRFtmgJsFtbofWbR4eywALauV8FerREREREREROQSp0BUQbRpCoQVg0otjyxavD2WyOLhqg0lIiIiIiIiIueMAlEFjccDm6dAza4QaLXqXddl8fZDtKpe0s+NExEREREREZFLmQJRBc3eVZC4D2r3OLIoKjaZAwlptNCwPBERERERERE5hxSIKmg2TQEcqNXtyKLF2w8B0LKaMqJERERERERE5NxRIKqg2fQHRDaDiDJHFi3eFkvxQsHUKhPhx4aJiIiIiIiIyKVOgaiCJOkg7Fqca1gewOIdsbSoWoKAAMdPDRMRERERERGRgkCBqIJky3TAhdrdjyw6mJjG1gNJtNCwPBERERERERE5xxSIKkh2L4GQCKjQ9Mgi1YcSERERERERkfNFgaiCJCEailaEAN9mX7jtIGHBATSMLOrHhomIiIiIiIhIQaBAVEFyOBqKlM+1aP6Wg7SsVpLQoEA/NUpERERERERECgoFogqShL1QpOKR/x5MTOOvvQm0qVnKj40SERERERERkYLCr4Eox3FCHMd5wXGcKMdxUh3HWeU4zsCTfG244zhPOY6zznGcZMdx9jiO86PjOK3PdbsvSh6PDc3LkRG1YGssAG1qKBAlIiIiIiIiIueevzOiRgJPAT8ADwG7gbGO4ww+idd+A/wbmA08ArwHNAH+dByn5blp7kUsJRY8GVYjKtu8LTFEhAbRKLKYHxsmIiIiIiIiIgVFkL8+2HGc5sAQ4CXg854AACAASURBVHnXdZ/LXvYpFlh6zXGcb1zXzcjntTWA3sAbruv+Lcfy74G12e+7+Nx+g4vM4T32d46MqPlbDtK6ekmCAv0djxQRERERERGRgsCfEYibARcY4V3guq4LvA+UBzoe57XeKd6ij1ru/X/yWWrjpSNhr/2dXSMqOj6FrTFJqg8lIiIiIiIiIueNPwNRzYDtruseOGr5ohyP5+cvYB8w3HGc6xzHqeQ4TjPgS+AA8PFZb+3FLiF3RtT8LQcBaFuztL9aJCIiIiIiIiIFjD8DURU4NqOJHMsq5vEYAK7rpgI3AInAd8BOYClQG2jjuu62s9vUS8Dh7NWaHYiat+UgJQoFU698ET82SkREREREREQKEn8GosKBtDyWp+Z4/HjigGXAi8B1WMHyIsDPjuOUye9FjuMMcxxnieM4Sw4cODoZ6xKWEA2Fy0BgMGAZUVfUKEVAwP+3d+9xlp1lneh/T1X1LbcOCZEkJBDFCw7DeCHIKILoDOg43kBF0YCACpxhFAePqIPMoByGMw4ezqDgyIBmUOIt3hA53oGI1yBoBBFkSAikGwiQ7qTT3XXZ+z1/7FWhLKo7vbura69a9f1+PvuzutZae/dbeevtJL9+3mfVjAcGAAAA7BSzDKKOJdmzwfm9a65vqKquSPLnSX6ntfaC1tpvtdZenuRfJ3lQJk/i21Br7VWttatba1dfcskJ86rhuetgcv5lSZKP3nk8tx06lodfddGMBwUAAADsJLMMog5m4+13l3XHAyd573dm0rD8N9aebK29O8m7kzxqMwY4KGuCqHceOJwkeegV+2c5IgAAAGCHmWUQ9fYkD9xgG90j1lw/kdUAa36Dawvdi7XuPJhc0AVRt92ZquRzL7vgXt4EAAAAsHlmGURdn6SSPHv1RFVVkmdl8kS8G7pz+6vqwVW1tnznPd3xmrUfWFVXJ/mcTBqXs2plKTn6seT8SX73ztsO59Pve27O2yOvAwAAALbOzJKI1tqNVXVdkhdU1UVJbsrkSXiPSvIdrbXl7tbHJ/m5JE9Lcm137tokz03ysqr6F0luTHJVJqHWsSQv3ZrvYps48uHJsXti3jtvO5yr9YcCAAAAttisS2KenuSWJE9J8swk701yTWvtdSd7U2vtE1310wuSPDbJk5PcneRNSf5T1yuKVXd1QdQFl+fjRxZz4PDxPPT++kMBAAAAW2umQVRrbTHJ87vXie65Np+shFp7/sNZs62Pk7iz6/t+/qV514E7kyQPub/+UAAAAMDWmmWPKLbKakXU+Zfn726bPDHvIZeriAIAAAC2liBqJ7jrQDK/OznnorzrwOE84KJzsn/frlmPCgAAANhhBFE7wZ0HJ43Kq/LO2+7UHwoAAACYCUHUTnDXweT8y3L46HJu/cRR/aEAAACAmRBE7QRdEPWuA5P+UP9cfygAAABgBgRRO8FdH07OvyzvXA2ibM0DAAAAZkAQNXTH70yWjiTnX5qbP3Y0F527Oxedu3vWowIAAAB2IEHU0N152+S4/4ocPHwsl+3fO9vxAAAAADuWIGroDn1wctx/ZQ4eOp7L9u+b7XgAAACAHUsQNXSHuyDqwitz8PCxXH6hiigAAABgNgRRQ3f4g8ncQu7edXHuPL6iIgoAAACYGUHU0B3+UHLB/XPwrqUkUREFAAAAzIwgaugOfTDZf2UOHDqeJCqiAAAAgJkRRA3d4Q/d0x8qiafmAQAAADMzVRBVVa+tqn91tgbDJhutJHcdSPZfkQOHjqcqud8FgigAAABgNqatiPraJL9fVR+sqpdU1eeejUGxSe46kLRxsv+KHDx8LPc9b092LyiCAwAAAGZj2lTifkm+Jck7kjw3yTur6saq+vdVdfGmj44zc/hDk+P+K3Pw8PFcblseAAAAMENTBVGttaXW2vWtta9LcnmS5yQZJ3l5kgNV9ZtV9fiq2nUWxsq0Dn1wcuyCKI3KAQAAgFk67X1arbWPt9Z+qrX2iCQPTvLrmWzduz7Jwar6yar6rE0aJ6fj8CSIavvvn4OHjuWyC1VEAQAAALNzRg2DqurCqnpmkp/NZMve8SS/lOQNSZ6eyda9J5/xKDk9hz+YnHNx7hztzt1Lo1yuIgoAAACYoamDqKpaqKqvr6rrkxxM8tPd5zwryWWttW9vrT01yRVJ3pLkxZs4XqZx+EPdtrxjSaIiCgAAAJiphWlurqqfyqTy6eIkB5K8LMm1rbX3rr+3tXZHVb02yWs3Y6CchsMfSi7+zBw8dDxJ9IgCAAAAZmqqICqT7Xa/leTaJH/QWhvfy/1vTfK00xgXZ6q1SbPyB31FDnQVUZeriAIAAABmaNog6rLW2uFTvbm1dkuSW6b8PdgMx+5Ilu9O9l+Rg4eOZ36u8mnnC6IAAACA2Zm2R9Q5VfWoE12sqkdV1aVnOCY2Q/fEvOy/IgcPH8+nnb8n83M12zEBAAAAO9q0FVEvTXJVkkee4PqLk9yc5DvOYExshsMfmhy7ZuWX7VcNBQAAAMzWtBVRj07yOye5/v8lecxpj4bNc2i1IurKHDx8PJddqFE5AAAAMFvTBlGXJLn9JNc/nuR+pz8cNs3hDyYLe9POuTgHDh3L5SqiAAAAgBmbNoj6SJJ/cZLrn5fkY6c/HDbN3bcn531aDh9fyeLKOJfuVxEFAAAAzNa0QdQbknx3VT16/YWqekyS7+ruYdaW7k52n587ji4nSS46d9eMBwQAAADsdNM2K//RJP82yZuq6g+S/F13/qFJHpvktiT/efOGx2lbvCvZc14OHV1Kkly4b/eMBwQAAADsdFMFUa21j1bVFyX5v5M8Psnjukt3Jrk2yX9srX1kU0fI6Vk6kuzdn0PHJhVRF56jIgoAAACYrWkrotJa+2iSp1fVd2bSvDxJbm+ttU0dGWdm6e7kgvvn8NHVIEpFFAAAADBbUwdRq7rg6aObOBY20+KRZM/5ueOerXkqogAAAIDZOq0gqqq+OMnDklyYT2143lprLzrTgXGGlu5Kdp+XQ11F1AWCKAAAAGDGpgqiqmp/kt9O8sgklaR1x6z5dUsiiJql1iYVUbvPzeGjy7lg70Lm5+re3wcAAABwFq2vZro3L0ny8CRPSfKgTIKnr0zyOUl+Nsnbk9xvMwfIaVhZTNronqfm6Q8FAAAA9MG0QdTXJnl1a+11mTwpL0lGrbV/bK19d5Lbk/zEZg6Q07B0ZHLcfX4OHVvOfTwxDwAAAOiBaYOoS5L8Tffrpe54zprrb0jy1Wc6KM7Q4l2T4+5zc+jocvariAIAAAB6YNog6vYkFydJa+2uJEeTfOaa6+ckkXrM2mpF1OrWPI3KAQAAgB6Y9ql5b0/yiDVf/1GS51TV25LMJ/me7h5maenuyXH3eTl0bDkX2poHAAAA9MC0FVGvSTJXVXu7r5+XSRXUW5K8KcneJN+/ecPjtCxOKqLGu87L4WPLKqIAAACAXpiqIqq19vokr1/z9Xuq6jOTfHmScZI/ba3dsblDZGpLkx5Rd2dvWoseUQAAAEAvnHIQVVX7krw4yZtaa7+9er7rFfX6E76RrddtzTs83pMknpoHAAAA9MIpb81rrR1L8qwkn3b2hsOm6LbmHVqZBFF6RAEAAAB9MG2PqHckefDZGAibqNua9/HlSQC1f5+teQAAAMDsTRtE/VCSp1fV15+NwbBJFo8kc7tyaKmSqIgCAAAA+mGqZuVJXpDkjiS/XlUHk9yc5Ni6e1pr7Ss3Y3CcpqW7kz3n5dDR5STx1DwAAACgF6YNoj47SUtya/f1FZs7HDbF0pFk9/n3BFH7BVEAAABAD0wVRLXWrjpL42AzLd6V7D43h44t5fy9C1mYn3YHJgAAAMDmk1AMUbc17/DRZf2hAAAAgN6YqiKqqh5wKve11m6997s4a5aOJLvPyx1Hl3KhJ+YBAAAAPTFtj6hbMukRdW/mpx8Km2bxSHL+pTn0cRVRAAAAQH9MG0Q9PZ8aRM0n+fQkT0ny4SSv3IRxcSa6iqjDR5dz/wv3zXo0AAAAAEmmb1Z+7YmuVdV/TXJjknPPcEycqS6IOnRMRRQAAADQH5vWrLy1diTJzyX5/s36TE7T4pG03efl0NGl3OccPaIAAACAftjsp+YtJbn/Jn8m01hZTMbLWZzfl3FL9u9TEQUAAAD0w6YFUVX1eUmek+TvN+szOQ2LR5IkxzLpDXWhiigAAACgJ6bqEVVVN2fjp+ZdmGR/kiNJnnrmw+K0LU2CqCPZmyS5UEUUAAAA0BPTPjXvLfnUIKoluSPJ+5L8Ymvt0GYMjNPUBVF3jbsgSrNyAAAAoCemfWreU8/SONgs3da8w+M9SQRRAAAAQH9sdrNyZq2riDq8MukNtX+fHlEAAABAP0wVRFXVD1XVn53k+lur6v8882Fx2rog6hMrKqIAAACAfpm2IurbkvzFSa7/RZInn/5wOGPd1ryPL+/KeXsWsmte0RsAAADQD9OmFJ+R5B9Ocv093T3MSlcR9bGl3blg77S96AEAAADOnmmTiuUk9zvJ9UuTjE9/OJyxLog6NNqTfbvXP+AQAAAAYHamrYi6Mck1VbVv/YWqOjeTbXk3bsbAOE2LR5K5hRxZnsu+3fOzHg0AAADAPaYNol6S5EFJ/ryqvqWqHtK9vjXJn2WyLe8lmz1IprB0JNl9bo6tjLNvlyAKAAAA6I+ptua11t5UVU9J8ook1625VEkOJ3lqa+2PNnF8TGvp7mT3+Tm2PMp5e/SIAgAAAPpj6qSitXZdVb0+yeOSfGZ3+n1Jfr+1dmQzB8dpWLwr2XNeji2Ncsl5e2Y9GgAAAIB7nFbJTBc4/fomj4XNsHQk2X1ejh8d6REFAAAA9MpUPaKq6uuq6qdOcv0nq+rfnvmwOG2LXY+o5ZEeUQAAAECvTNus/AeSnH+S6+cmed7pD4cztnR3suf8HFsaZa8gCgAAAOiRaYOohyS58STX/7q7h1lZumuyNW95bGseAAAA0CvTBlF7kuy6l+vnnP5wOGOLRzLedU6WRuOcoyIKAAAA6JFpg6h3J/mak1z/miTvOf3hcMaWjmR54dwkUREFAAAA9Mq0QdT/TPLlVfXqqrp09WRVXVpVr0nyZUletZkDZAorS8loKcsLk6I0PaIAAACAPlmY5ubW2s9U1RckeUaSp1XVJ7pLFyWpJK9urf30Jo+RU7V0JEmyPNdVRAmiAAAAgB6ZKohKktbas6rquiTfnORB3en3JfnV1tqfbObgmFIXRC3O7Utiax4AAADQL1MHUUnSWrshyQ2bPBbO1NLRJMnx2ptERRQAAADQL9P2iKLPRktJkuNt8mBDPaIAAACAPpm6Iqqq/lmS5yR5WJIL86lhVmutPehT3sjZN1pOkiy2SQBlax4AAADQJ1NVRFXVFyd5W5JvSHIwyWckeX/36wcmuSu27M3OakXUuAuiVEQBAAAAPTLt1rwfS3Jbks9J8rTu3H9prT0yyWOSXJXkdZs1OKY0WkwiiAIAAAD6adog6ouSvKa1dijJeO1ndE/Me02SF23e8JhKtzXv2HgyrXt3awEGAAAA9Me0ScV8ko91vz7aHe+z5vrfJ3nomQ6K09RtzTs2nrT+UhEFAAAA9Mm0QdStmfSCSmvteJIPJvmSNdc/P8nhU/2wqtpdVS+qqlur6nhV3VRVTzqF9z21qtpJXv9zyu9rGLog6uhKVxEliAIAAAB6ZNqn5v1xJo3KX9B9/QtJnldV52dSLXVNkp+Z4vNek+TbkrwyyU1JnpDkuqqaa62drNfUDUmevMH5b07ydUl+d4oxDMdKF0SN5rJrfpxd87bmAQAAAP0xbRD140neVFV7WmuLSV6Y5KIk35JJz6jXJvnBU/mgqnpYJsHVj7bWXtide3UmIdNLq+pXWmvLG723tfb+TJ7Wt/4zn5fkjiS/Pd23NRBdRdSRlTnVUAAAAEDvTFUy01q7tbX2a10Ildbacmvt/2itXdRau29r7Ttba3ef4sc9MUlL8oo1n98yqY66NMmjpxlbVX1+Jv2pfrm1tjTNewdj9MmKKP2hAAAAgL6Z5d6tL0xyS2vt9nXn/2rN9Wk8pTu+9oxGtZ11T807MprPObsFUQAAAEC/TLs1bzNdluTgBudXz11+qh9UVfNJnpTkfa21P9+EsW1Pq1vzlueyd1fNeDAAAAAA/9QsK6L2JVnc4PzxNddP1eMy2c738/d2Y1U9o6reVlVvu/329cVY29xo8o/zrpXKPhVRAAAAQM/MMog6lmTPBuf3rrl+qp6cSb+pew2iWmuvaq1d3Vq7+pJLLpnit9gGuq15dy+XHlEAAABA78wyiDqYjbffXdYdD5zKh1TV+Um+IclbW2s3b9LYtqfRUjK3K8dWxoIoAAAAoHdmGUS9PckDq2p9WdIj1lw/Fd+UyTa+ndukfNVoOVnYk2NLo+y1NQ8AAADomVkGUdcnqSTPXj1RVZXkWUk+kuSG7tz+qnpwVe0/wec8JZO+Ur96doe7DYyWkvldOb6sIgoAAADon5kFUa21G5Ncl+QFVfXyqvquJL+T5FFJntdaW+5ufXySd3fHf6KqHpDky5L8Vmvt8NaMvMdWFpP53Tm2PBJEAQAAAL2zMOPf/+lJbsmkqumZSd6b5JrW2utO8f3fnklVlW15yWRr3vzuHFsaeWoeAAAA0DszDaJaa4tJnt+9TnTPtUmuPcG1lyR5ydkY27Y0WkrrKqL2qogCAAAAemaWPaLYbKOltPldSWJrHgAAANA7gqghGS1nXKtBlKkFAAAA+kVaMSSjxYznuiBKjygAAACgZwRRQzJazqiriNIjCgAAAOgbQdSQjJYymtMjCgAAAOgnQdSQjJayUrbmAQAAAP0kiBqS0XJWspAkOUcQBQAAAPSMIGpIVhaz3AVRekQBAAAAfSOIGpLR0j0VUXpEAQAAAH0jiBqS0XKWokcUAAAA0E+CqCEZLWUpkwBKRRQAAADQN4KoIRktZanpEQUAAAD0kyBqSEZLWWrzqUr2LJhaAAAAoF+kFUMyWspiW8i+XfOpqlmPBgAAAOCfEEQNxXiUtHGOd0EUAAAAQN8IooZitJQkOT6e1x8KAAAA6CVB1FCsLCZJjo/nsm+3IAoAAADoH0HUUIyWkyTHxvO25gEAAAC9JIgaim5r3rGRIAoAAADoJ0HUUHRB1NHxQvbamgcAAAD0kCBqKLqteUdX5rJvl2kFAAAA+kdiMRSjSbPyo6O5nLN7YcaDAQAAAPhUgqih6Lbm3T2ay149ogAAAIAeEkQNRbc17+4VzcoBAACAfhJEDUVXEXVkpbJvt2kFAAAA+kdiMRRdEHV8rCIKAAAA6CdB1FCsTIKopSzoEQUAAAD0kiBqKLqKqOUsZN9uQRQAAADQP4KooeialS9ll615AAAAQC8JooZiTUXUrnnTCgAAAPSPxGIoRotJkqW2kF3zNePBAAAAAHwqQdRQdFvzljOf+TnTCgAAAPSPxGIo1mzNW5hTEQUAAAD0jyBqKLogaim7Mi+IAgAAAHpIEDUUa7bmqYgCAAAA+kgQNRQrixnXQlrmMieIAgAAAHpIEDUUo6W0uV1JoiIKAAAA6CVB1FCMljPugig9ogAAAIA+EkQNxWgp4/ndSZKFOdMKAAAA9I/EYihGyxmXiigAAACgvwRRQzFavGdr3sK8IAoAAADoH0HUUIyWMp5bSKIiCgAAAOgnQdRQjJYzqtUeUYIoAAAAoH8EUUMxWsqo25o3V4IoAAAAoH8EUUMxWsqo9IgCAAAA+ksQNRQrSxmVHlEAAABAfwmihmJtRdScaQUAAAD6R2IxFKPle3pEqYgCAAAA+kgQNRSjpazcUxEliAIAAAD6RxA1FKOljKJHFAAAANBfgqihGC1lpWtWriIKAAAA6CNB1FCMlrISPaIAAACA/hJEDcVoKcu1K3OVVAmiAAAAgP4RRA3FaDkrtZCFOVMKAAAA9JPUYihWFrOSBdvyAAAAgN4SRA3BeJS0UZazS6NyAAAAoLcEUUMwWk6SrGQ+8/OCKAAAAKCfBFFDMFpKkiyViigAAACgvwRRQ9BVRC03PaIAAACA/hJEDcFoMUmylIXMlyAKAAAA6CdB1BB0W/OWs6BHFAAAANBbgqgh6LbmLWVXFuZMKQAAANBPUoshWK2IavN6RAEAAAC9JYgagtWn5mXeU/MAAACA3hJEDcFKF0R5ah4AAADQY4KoIegqohazoCIKAAAA6C1B1BCMVEQBAAAA/SeIGoLuqXmLY0EUAAAA0F+CqCFY3ZrnqXkAAABAjwmihuCep+YtZGHOlAIAAAD9JLUYgi6IOq4iCgAAAOgxQdQQrG7NG897ah4AAADQW4KoIeialR/XrBwAAADoMUHUEKzZmrcwL4gCAAAA+kkQNQQri0kmW/PmNSsHAAAAekpqMQT3bM2bj4IoAAAAoK8EUUMwWkpqPsttTkUUAAAA0FtSiyEYLSXzuzMaN0/NAwAAAHpLEDUEXRC1Mm6ZtzcPAAAA6ClB1BCMlpL5XRmNxyqiAAAAgN4SRA3B2oooQRQAAADQU4KoIRgtJwt6RAEAAAD9Jogagn9SEWVKAQAAgH6SWgzByiefmjdvRgEAAICeWpj1ANgE+69IW9iT0QdURAEAAAD9NdPUoqp2V9WLqurWqjpeVTdV1ZOmeP9FVfXfq+oDVbVYVbdV1a9V1QVnc9y989U/nvE3/myS6BEFAAAA9NasK6Jek+TbkrwyyU1JnpDkuqqaa6297mRvrKrLkrw1yd4kr07ygSSXJHlkknOS3HkWx907K+NxknhqHgAAANBbMwuiquphSa5J8qOttRd2516d5IYkL62qX2mtLZ/kI/5Hkvkkn99au/1sj7fvRuOWREUUAAAA0F+z3Jr3xCQtyStWT7TWWibVUZcmefSJ3lhVn5Xk65L8t9ba7VW1p6r2nOXx9tpKF0SpiAIAAAD6apZB1BcmuWWDaqa/WnP9RB7XHQ9U1e8lOZbkWFX9SVV9/iaPc1sYjVREAQAAAP02yyDqsiQHNzi/eu7yk7z3s7rjqzL5Hp6U5HuSfHaSN1XVlZs1yO3inoqoeU/NAwAAAPppls3K9yX56Abnj6+5fiLndcfbk3xVa22UJFX1tiR/keQ/JHnuRm+sqmckeUaSPOABD5h+1D212iNqvlREAQAAAP00y/KZY0k26uu0d831k703SX5pNYRKktbaXyZ5X5IvPdEbW2uvaq1d3Vq7+pJLLplyyP21+tQ8W/MAAACAvpplEHUwG2+/u6w7HjjJe1evfWSDax9Jcp8zGNe21OVQmpUDAAAAvTXLIOrtSR5YVevLkh6x5vqJ/HV3vGKDa/fPZMvejnJPRdS8IAoAAADop1kGUdcnqSTPXj1RVZXkWZlUNd3QndtfVQ+uqv1r3vvmJB9Ock1V7Vvz/scmuSrJ753twffNPT2iVEQBAAAAPTWzZuWttRur6rokL6iqi5LclOQJSR6V5Dtaa8vdrY9P8nNJnpbk2u69S1X13CTXJXlrVf2vJJck+b4kNyf571v5vfTB6lPz9IgCAAAA+mqWT81LkqcnuSXJU5I8M8l7k1zTWnvdvb2xtfaLVXU8yfOT/HiSu5P8ZpIfbK0dOmsj7qlPVkTNssgNAAAA4MRmGkS11hYzCZKef5J7rk1XCbXBtd9I8htnY2zbjYooAAAAoO+UzwzEqGtWPieIAgAAAHpKEDUQKyMVUQAAAEC/CaIGYtQ8NQ8AAADoN0HUQIz0iAIAAAB6ThA1ECtjFVEAAABAvwmiBmJ0T48oUwoAAAD0k9RiIFREAQAAAH0niBqIe3pEzQuiAAAAgH4SRA3EynicJJkrQRQAAADQT4KogfDUPAAAAKDvBFEDMdIjCgAAAOg5QdRA6BEFAAAA9J0gaiA8NQ8AAADoO0HUQHyyR5QpBQAAAPpJajEQKqIAAACAvhNEDcRoPE7iqXkAAABAfwmiBkJFFAAAANB3gqiBGI0EUQAAAEC/CaIGYtS6IKoEUQAAAEA/CaIGYjRumatkTkUUAAAA0FOCqIFYGbcszJlOAAAAoL8kFwMxGjf9oQAAAIBeE0QNxMqoZUEQBQAAAPSYIGogRuNx5ucFUQAAAEB/CaIGYmXcPDEPAAAA6DVB1EDoEQUAAAD0nSBqIEZjPaIAAACAfhNEDcRo3PSIAgAAAHpNEDUQK+OWhTnTCQAAAPSX5GIg9IgCAAAA+k4QNRAr47EeUQAAAECvCaIGYjRumStBFAAAANBfgqiBWBm3LGhWDgAAAPSYIGog9IgCAAAA+k4QNRCjcdMjCgAAAOg1QdRArKiIAgAAAHpOEDUQk4oo0wkAAAD0l+RiIFREAQAAAH0niBqI0XisRxQAAADQa4KogVgZtcwJogAAAIAeE0QNhKfmAQAAAH0niBqIUdMjCgAAAOg3QdRAqIgCAAAA+k4QNRAro5b5OdMJAAAA9JfkYiBURAEAAAB9J4gaiJVxy/y8IAoAAADoL0HUQIzGYxVRAAAAQK8JogZiZdwyV4IoAAAAoL8EUQOhRxQAAADQd4KogRjpEQUAAAD0nCBqIFREAQAAAH0niBqA1trkqXlzphMAAADoL8nFAIzb5KgiCgAAAOgzQdQArIzHSZJ5QRQAAADQY4KoARh1JVEqogAAAIA+E0QNwEoXRKmIAgAAAPpMEDUAo5EgCgAAAOg/QdQAjJqteQAAAED/CaIGYHTP1jzTCQAAAPSX5GIAVjQrBwAAALYBQdQA6BEFAAAAbAeCqAFYGY+TJAvzgigAAACgvwRRA/DJHlGCKAAAAKC/BFEDsNojar4EUQAAAEB/CaIGQEUUAAAAsB0IogZgNYjSIwoAAADoM0HUANyzNW/OdAIAAAD9JbkYgHsqomzNAwAAAHpMEDUAK+NxEj2iAAAAgH4TRA2AiigAAABgOxBEDcCKp+YBAAAA24AgagBGI0EUAAAA0H+CqAFQEQUAAABsB4KoARi31R5RgvZLBAAAEfZJREFUphMAAADoL8nFAKiIAgAAALYDQdQAjMbjJJ6aBwAAAPSbIGoAVjQrBwAAALYBQdQAjLqteQvzgigAAACgvwRRA6BHFAAAALAdCKIGYLUiar4EUQAAAEB/CaIGYLUiamHOdAIAAAD9JbkYgPFqRZQeUQAAAECPCaIG4JMVUYIoAAAAoL8EUQMwGo+TaFYOAAAA9JsgagBWNCsHAAAAtoGZBlFVtbuqXlRVt1bV8aq6qaqedIrvbSd4vfpsj7tvRuOWuUrmVEQBAAAAPbYw49//NUm+Lckrk9yU5AlJrququdba607h/W/uPmOt923qCLeBlXHzxDwAAACg92YWRFXVw5Jck+RHW2sv7M69OskNSV5aVb/SWlu+l4/53621Xzi7I+2/0bhFDgUAAAD03SzjiycmaUlesXqitdYyqY66NMmjT+VDqmpPVZ1zVka4TayMVEQBAAAA/TfL9OILk9zSWrt93fm/WnP93nxrkqNJ7q6q91fV92zmALeLcWuemAcAAAD03ix7RF2W5OAG51fPXX4v7/+LJL+c5P1J7pfkaUleXlVXttaet2mj3AZWxuMsCKIAAACAnptlELUvyUc3OH98zfUTaq198dqvq+o1SX4vyXOr6qdbazdv9L6qekaSZyTJAx7wgGnH3EujsYooAAAAoP9muTXvWJI9G5zfu+b6KWutjZP8RJL5JF9xkvte1Vq7urV29SWXXDLNb9Fbkx5RgigAAACg32YZRB3MxtvvLuuOB07jM2/tjhef1oi2qdG4ZX5eEAUAAAD02yyDqLcneWBVrS9LesSa69N6UHdc3wB90FbGnpoHAAAA9N8s04vrk1SSZ6+eqKpK8qwkH0lyQ3duf1U9uKr2r7nvU/bUVdXuJD+cZDnJH5zdoffLaNxiZx4AAADQdzNrVt5au7Gqrkvygqq6KMlNSZ6Q5FFJvqO1ttzd+vgkP5fJU/Gu7c49u6qekOT1mWzHuyTJtyf53CQ/0lr70JZ9Iz0weWqeiigAAACg32b51LwkeXqSW5I8Jckzk7w3yTWttdfdy/v+NMkXd++/OMliknckeUFr7dfO2mh7ajSOp+YBAAAAvTfTIKq1tpjk+d3rRPdcm09WQq2e+4PssO13J3O/C/Zkl2blAAAAQM/NuiKKTfDixz901kMAAAAAuFcaCwEAAACwJQRRAAAAAGwJQRQAAAAAW0IQBQAAAMCWEEQBAAAAsCUEUQAAAABsCUEUAAAAAFtCEAUAAADAlhBEAQAAALAlBFEAAAAAbAlBFAAAAABbQhAFAAAAwJYQRAEAAACwJQRRAAAAAGwJQRQAAAAAW0IQBQAAAMCWEEQBAAAAsCUEUQAAAABsCUEUAAAAAFtCEAUAAADAlhBEAQAAALAlBFEAAAAAbAlBFAAAAABbolprsx7DzFTV7Uk+MOtxbJL7JvnYrAfBTJj7ncvc71zmfmcz/zuXud+5zP3OZe53ru0+9w9srV2y0YUdHUQNSVW9rbV29azHwdYz9zuXud+5zP3OZv53LnO/c5n7ncvc71xDnntb8wAAAADYEoIoAAAAALaEIGo4XjXrATAz5n7nMvc7l7nf2cz/zmXudy5zv3OZ+51rsHOvRxQAAAAAW0JFFAAAAABbQhAFAAAAwJYQRG1jVbW7ql5UVbdW1fGquqmqnjTrcbF5quoxVdVO8Lpm3b2XVtUvVNXHq+pIVf1xVT1sVmPn1FXVeVX1o1X1xqq6vZvfF57g3guq6qeq6sNVdayq/qKqHnuCez+7ql5fVXd2r9+qqged1W+GqZzq3FfVU0/yZ8GXbnC/ue+5qnp4Vb28qv6u+zP7QFW9oao+5THN1v2wnOrcW/fDU1WfW1W/XFX/u6rurqo7quovq+opVVXr7rXuB+RU59663xmq6lFr5vWKddd2xNpfmPUAOCOvSfJtSV6Z5KYkT0hyXVXNtdZeN9ORsdl+OsmfrTv3p6u/qKpzk7wpyf2S/ESSw0meneRNVfVFrbV/2KqBclrum+Q/JbktyduTPG6jm7r/UPntJF+U5P9JcmuSpyV5Y1X969baW9bce3mSP0mymOSFSSrJf0hyQ1V9fmvt9rP23TCNU5r7NV6U5L3rzr1n7Rfmftv4wSSPSnJ9kpcnuU+SZyb5y6r62tbaGxPrfqBOae7XsO6H48okFyb5hSQfSrInkz/3/1eSf57keYl1P1CnNPdrWPcDVVULSV6R5O4k5667tnPWfmvNaxu+kjwsSUvywjXnKpMfxoNJds16jF6bMs+P6eb5mnu57/u7+758zblLktyR5PpZfx9e9zrPe5Jc3v36ivVre81939hde+qac3uTvC/J29bd+5NJlpJ89ppzD06ykuSls/6evaae+6d21770FD7T3G+DV5IvSbJ73bmLk3wkydvXnLPuB/aaYu6t+x3yyuR/PI8l2dN9bd3vkNcGc2/dD/yVSVj00SQv6+b6ijXXdszatzVv+3piJj+kr1g90SY/fa9McmmSR89oXJwlNdnCs+sEl5+Y5F2ttTetnmiTFPxXknxNVZ2zFWPk9LTWFltrB07h1icmOZTJ36atvvd4JtWRD1tXivvNSX6/tfbeNff+Q5I/SvItmzJwztgUc3+Pqjq/+9u0EzH320Br7c9aa0vrzn08yZuT/LM1p637gZli7u9h3Q/eBzL5n8293dfW/c6xfu7vYd0PT1Vdlkn10n/MZAfLejtm7Quitq8vTHJL+9SSu79ac53heGWSu5IsdvvJ79knXFVzST4vn5z7tf4qk4qLh2zJKDnbvjDJO1prK+vO/5N1X1X3z2Sb5ol+Jq6oqkvO2ig5m96Y5M4kx6rqj2pdHzhzPwiXJ/n4mq+t+51j/dyvsu4HpqrOqar7VtWnV9XTM9l6c2NrbfV/TK37gTqFuV9l3Q/TS5P8Y5KfPcH1HbP2BVHb12WZbMFbb/Xc5Vs4Fs6e5SS/keS5Sb4uky14lyf53ar62u6eizIJm/w8DN+prvvL1p0/2b1sD0eTvDbJ9yb5hkz+Nu0LkvzJuv84NffbWFU9Kskjk/zSmtPW/Q5wgrm37ofrx5LcnuT9mVQ6/Hkm1Q2rrPvhure5t+4Hqqq+LMmTknxva218gtt2zNrXrHz72pfJ3tL1jq+5zjbXWvvTrGlKniRV9dok707y/2ayr3x1rhc3+Ag/D8OyL6c2z34mBqa19iuZbLVd9VtV9atJ/jbJf0vyFd15c79NdeX6v5hJY9IfW3PJuh+4E829dT9oP5PkdzPp5/mVmfQIPG/Ndet+uE4699b9MK1pUP661tr6B1CttWPWvoqo7etYJlUw6+1dc50B6vpI/GySz+j2Ca/OtZ+H4TvVde9nYgfoegL8VpJHVdXqXJv7baiq9meyDeO8JF+7bouGdT9g9zL3n8K6H4bW2j+21v6wtfaLrbWnZrKV5oaqum93i3U/UKcw9xu9x7rf/p6T5IGZPDX1ZHbM2hdEbV8Hs3G53WqZ3lTNb9l2bu2OFyf5RCZpuJ+H4TvVdX+yklw/E8NyaybVzfu7r839NtM9TOINST4nyde01v5u3S3W/UCdwtyfiHU/PL+USauFx3dfW/c7x/q5PxHrfpvq/sLhP2dSSLC7qq6qqquSXNjdckVVXdH9esesfUHU9vX2JA/coAnZI9ZcZ7hWn5hwe7fH+G+TPHyD+x6RSUj191s1MM6qtyf5/A2eoLK67t+RJK212zLZunuin4kPbfCgA7anB2XSS+5QYu63m6raneTXk/zLJN/cWnvrBrdZ9wN0inN/Itb98KxuoblPd7Tud471c38i1v32dZ8k52fS9+vmNa/ndNf/PMnqvwN2zNoXRG1f1yepJM9ePVFVleRZST6S5IYZjYtNVFWftsG5K5N8Z5J/aK3d3J2+PslDquoxa+67JJPmh29srd29BcPl7Ls+k789uWb1RFXtTfL0TJ6w8b519z6uqj5rzb0PzqS3wK9uzXDZLCf4s+ALM3mIwR+texS8ud8Gqmo+yXVJHpvkKa213znBrdb9wJzq3Fv3w7PRnHae1R1v7I7W/cCc6txb94P00Uwq3ta/frm7/l1JntH9eses/WqtzXoMnKaqel2Sb82k8dlNSZ6Q5N8k+Y7W2mtnOTY2R1X9cSYVTX+aScD4oEz+oDo3yVe11t7U3Xdekr/OpPHhS5McziSkvDLJI1prKqJ6rqr+fSb/4rkgyQ8keVOSP+4u/3xr7QNVNZfkLUmuTvITST6Y5KmZ/G3IY1d/HrrPu38mf2tyPMnLMgmun5vJX0B8QWvtI1vwbXEKTnHu35fkb5K8LZPtuA9J8t1JlpJ8ydo1bu63h6p6WZLvS/IHmTwhab3faK3dbd0PzxRzb90PTFX9RibbsN6SyVarizMJGL4kya+11r6pu8+6H5gp5t663yGq6oWZbNm7srX2oe7czln7rTWvbfrKpDnZizP5AV1M8ndJvn3W4/La1Dn+3kzKNT+WSTnuRzNJv79gg3svz+RvWD+R5O5M/mf26ll/D16nPNe3JGkneD1mzX37k7wyk2DyWCZNLr/yBJ/5OZn0H7mze70+yWfO+nv1mn7uk7wok3LtO7o/C25Lcm2SB5n77flK8uaTzHtLctWae637Ab1Ode6t++G9knxLJk9MO5BJsHBn9995/y7J/Lp7rfsBvU517q37nfNK8sLuz/wr1p3fEWtfRRQAAAAAW0KPKAAAAAC2hCAKAAAAgC0hiAIAAABgSwiiAAAAANgSgigAAAAAtoQgCgAAAIAtIYgCAAAAYEsIogAAdoiquqWq/nDW4wAAdi5BFAAAAABbQhAFAAAAwJYQRAEAAACwJQRRAACbqKruV1U/U1UHqmqpqt5XVT9cVXPd9auqqlXVj1TVM7vrx6vqHVX1uA0+78qq+oWqur2772+r6qkb3Ffd5/11VR2tqjuq6q1V9fUb3PvwqvrTqjpWVR+squeelX8YAADrVGtt1mMAABiEqrpvkhuT7E3yqiQHkjwyyZOT/Exr7VlVdVWSm5P8bZL7JXllkuNJnpnkAUm+orX21jWf944kFyf5ySS3JXli95k/0Fp76Zrf+390n/HmJG9Ispzk4Unuaq39u+6eW5IsJbkgyc8neX+Sb0nyZUm+qrX2e5v+DwUAYA1BFADAJqmqn0nyjUke2lo7uOb8f0nyQ0kenEkQdHOSlSQPaa29t7vnkiT/mOTdrbUv7s69NMn3Z01IVFW7krwlyRckuaK19vGqenR37tokT29r/gOvqmr16y6IemCSf9Na+93u3J4ktya5obX2zWfjnwsAwCpb8wAANkFVVZJvTvLGJMtVdd/VV5LfS1JJvnzNW964GkIlSWvt9iSvS/Ivu/ckydckeefaSqXW2nKSl2VSdfWvutOrAdLz27q/ZVz/dZKbV0Oo7vpikr9I8hmn8W0DAExFEAUAsDkuSXKfTLbh3b7u9ebunk9bc/97NviM1XNXrTm+e4P7/r47fnp3/Mwkn2itHTiFcX5gg3N3JLnoFN4LAHBGFmY9AACAgVj9C75fTvLqE9zz/i0ay8mMTnC+tnQUAMCOJIgCANgctye5M8nu1tofnuimrll5knzOBpdXz92y5vjgDe773O54c3d8X5KvqqrLT7EqCgBgJmzNAwDYBK21UZJfTfJ1VfXw9der6vyuMfiqr66qz15z/ZIk357kL1trH+tO/3aSh1bVY9fct5Dk+zJ50t5q4PWr3fHFXa+qtb+vSicAoDdURAEAbJ4fTvKYJH9SVT+b5KYk5yV5SJJvSvLQNfe+K8lbquoVSRaTPDPJuUmet+ae/5rkW5P8ZlX9ZJLbMmlM/sgkP9Ba+0SStNZuqKpXJ/muJFdV1Ru6z3xYkqNJnn1WvlsAgCkJogAANklr7faqekSSH0ny9ZkEQ4eS/GOSH0vy4SSXdrdfn8l2vh9IcmUmTcm/trV2w5rP+1hVPTLJS7rPOj+ThuZPb6393Lrf/hlJ/qY7vjiTAOpdSX58879TAIDTU5/6RF8AAM6WrkfUzUle0Fr7v2Y7GgCAraVHFAAAAABbQhAFAAAAwJYQRAEAAACwJfSIAgAAAGBLqIgCAAAAYEsIogAAAADYEoIoAAAAALaEIAoAAACALSGIAgAAAGBLCKIAAAAA2BL/P61dcEahdUshAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e50JgKzsFPAw",
        "colab_type": "code",
        "outputId": "deb1ff51-5e77-4615-e921-20a9f98f1ec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [0.],\n",
              "       [2.],\n",
              "       ...,\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [2.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSRFpff77opA",
        "colab_type": "code",
        "outputId": "7a7fabfb-8df0-4726-a9b9-ac1fcf7837c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from sklearn.datasets import make_circles\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# predict probabilities for test set\n",
        "yhat_probs = cnn_model.predict(X_test, verbose=0)\n",
        "\n",
        "yhat_classes = yhat_probs.argmax(axis=-1)\n",
        "\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(y_test, yhat_classes)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, yhat_classes, average = 'macro')\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test, yhat_classes, average = 'macro')\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, yhat_classes, average = 'macro')\n",
        "print('F1 score: %f' % f1)\n",
        " \n",
        "# kappa\n",
        "kappa = cohen_kappa_score(y_test, yhat_classes)\n",
        "print('Cohens kappa: %f' % kappa)\n",
        "\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(y_test, yhat_probs, multi_class= 'ovr')\n",
        "print('ROC AUC: %f' % auc)\n",
        "\n",
        "matrix = multilabel_confusion_matrix(y_test, yhat_classes, labels = [0,1,2,3,4])\n",
        "print(matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.913667\n",
            "Precision: 0.913667\n",
            "Recall: 0.913667\n",
            "F1 score: 0.913667\n",
            "Cohens kappa: 0.892076\n",
            "ROC AUC: 0.992314\n",
            "[[[4764   46]\n",
            "  [  39 1151]]\n",
            "\n",
            " [[4669  101]\n",
            "  [ 142 1088]]\n",
            "\n",
            " [[4678  140]\n",
            "  [ 157 1025]]\n",
            "\n",
            " [[4681  144]\n",
            "  [ 132 1043]]\n",
            "\n",
            " [[4690   87]\n",
            "  [  48 1175]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1H0xFWFoncV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_fea = [str(i) for i in range(0,784)]\n",
        "X_test_t = pd.read_csv('testX.csv', usecols=test_fea)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDCGSD8dp0CE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_t =np.array(X_test_t, dtype ='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CFf6xYWqtjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_t = X_test_t.reshape(X_test_t.shape[0],*(28,28,1))\n",
        "X_test_t = X_test_t/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZTYsWcfNxs-",
        "colab_type": "code",
        "outputId": "2a84aed6-25df-4614-f5f1-8602ea3ed98f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test_t.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvS91KdXOC3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_test = cnn_model.predict_classes(X_test_t)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQxu4xc6ORU7",
        "colab_type": "code",
        "outputId": "50694781-3dc5-4aea-cc5a-9d5156611236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 4, 0, ..., 4, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AbCHUFbOY3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id = [i for i in range(0,10000)]\n",
        "frame = pd.DataFrame(id, columns=['Id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJT4cG6NY4AT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frame['Label'] = pred_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM8mUK5hY-dC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frame.to_csv(r'submission_model6_full_2.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo9IQC5fZMs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Mk7cg3ZaiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J8m_EQuZfAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F21GZ4F3Z7uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBAkVAsdbU5o",
        "colab_type": "code",
        "outputId": "9c4824a9-b2dc-4d26-e5f9-67ec3acf4fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!kaggle competitions submit -c ece657a-w20-asg3-part2 -f submission_model6_full_2.csv -m \"Submission Model 6 - Rishi2 - Updated - full train - 2\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 67.3k/67.3k [00:02<00:00, 28.5kB/s]\n",
            "Successfully submitted to ECE 657A Assignment 3 Part 2"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQBZUOF12I3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRhaXgdi5K6C",
        "colab_type": "code",
        "outputId": "0692c1ba-4229-4914-f3e1-07953a2932e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "#code to make a submission\n",
        "test_fea = [str(i) for i in range(0,784)]\n",
        "X_test_t = pd.read_csv('testX.csv', usecols=test_fea)\n",
        "X_test_t =np.array(X_test_t, dtype ='float32')\n",
        "X_test_t = X_test_t.reshape(X_test_t.shape[0],*(28,28,1))\n",
        "X_test_t = X_test_t/255.0\n",
        "X_test_t.shape\n",
        "pred_test = cnn_model.predict_classes(X_test_t)\n",
        "pred_test\n",
        "id = [i for i in range(0,10000)]\n",
        "frame = pd.DataFrame(id, columns=['Id'])\n",
        "frame['Label'] = pred_test\n",
        "frame\n",
        "frame.to_csv(r'submission.csv', index = False)\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions submit -c ece657a-w20-asg3-part2 -f submission.csv -m \"more dropout Submission\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-32-a5d79d4e1f50>:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 67.3k/67.3k [00:02<00:00, 25.8kB/s]\n",
            "Successfully submitted to ECE 657A Assignment 3 Part 2"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0BxTmOx47Fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout,BatchNormalization, Activation, add, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam,SGD,RMSprop\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKh6un4B1GLR",
        "colab_type": "code",
        "outputId": "546cf29e-d993-43c2-ee47-eb38f527e33b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "#2048 with 0.4 and 100, 500 epoch\n",
        "\n",
        "image_rows = 28\n",
        "\n",
        "image_cols = 28\n",
        "\n",
        "batch_size = 512\n",
        "image_shape = (image_rows,image_cols,1)\n",
        "cnn_model40 = Sequential([\n",
        "    Conv2D(filters=32,kernel_size=5,activation='relu',padding='same',input_shape = image_shape),\n",
        "    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n",
        "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same'),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Conv2D(filters=64,kernel_size=1,activation='relu',padding='same'),\n",
        "    Flatten(), # 1flatten out the layers\n",
        "    Dense(1024,activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(32,activation='relu'),\n",
        "    Dense(5,activation = 'softmax')\n",
        "])\n",
        "cnn_model40.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0001),metrics =['accuracy'])\n",
        "history = cnn_model40.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=2048,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_data=(X_test,y_test)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.4251 - accuracy: 0.3825 - val_loss: 1.2222 - val_accuracy: 0.5133\n",
            "Epoch 2/500\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 1.1060 - accuracy: 0.5352 - val_loss: 0.9673 - val_accuracy: 0.5628\n",
            "Epoch 3/500\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.9091 - accuracy: 0.6059 - val_loss: 0.8139 - val_accuracy: 0.6555\n",
            "Epoch 4/500\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.7860 - accuracy: 0.6684 - val_loss: 0.7169 - val_accuracy: 0.7020\n",
            "Epoch 5/500\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 0.7096 - accuracy: 0.7050 - val_loss: 0.6508 - val_accuracy: 0.7355\n",
            "Epoch 6/500\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.6476 - accuracy: 0.7334 - val_loss: 0.6021 - val_accuracy: 0.7577\n",
            "Epoch 7/500\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.6038 - accuracy: 0.7547 - val_loss: 0.5580 - val_accuracy: 0.7775\n",
            "Epoch 8/500\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.5647 - accuracy: 0.7711 - val_loss: 0.5270 - val_accuracy: 0.7902\n",
            "Epoch 9/500\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 0.5354 - accuracy: 0.7877 - val_loss: 0.5082 - val_accuracy: 0.7920\n",
            "Epoch 10/500\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 0.5160 - accuracy: 0.7925 - val_loss: 0.4838 - val_accuracy: 0.8083\n",
            "Epoch 11/500\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 0.4948 - accuracy: 0.8029 - val_loss: 0.4668 - val_accuracy: 0.8162\n",
            "Epoch 12/500\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.4798 - accuracy: 0.8109 - val_loss: 0.4583 - val_accuracy: 0.8192\n",
            "Epoch 13/500\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 0.4663 - accuracy: 0.8161 - val_loss: 0.4444 - val_accuracy: 0.8253\n",
            "Epoch 14/500\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 0.4534 - accuracy: 0.8211 - val_loss: 0.4367 - val_accuracy: 0.8270\n",
            "Epoch 15/500\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.4441 - accuracy: 0.8276 - val_loss: 0.4231 - val_accuracy: 0.8337\n",
            "Epoch 16/500\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.4331 - accuracy: 0.8310 - val_loss: 0.4154 - val_accuracy: 0.8340\n",
            "Epoch 17/500\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 0.4227 - accuracy: 0.8352 - val_loss: 0.4072 - val_accuracy: 0.8373\n",
            "Epoch 18/500\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.4176 - accuracy: 0.8362 - val_loss: 0.4015 - val_accuracy: 0.8388\n",
            "Epoch 19/500\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.4101 - accuracy: 0.8389 - val_loss: 0.3947 - val_accuracy: 0.8428\n",
            "Epoch 20/500\n",
            " 3/27 [==>...........................] - ETA: 0s - loss: 0.3996 - accuracy: 0.8452"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "canyFpzC2lrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "ad0e68ad-c82b-431d-9594-a849eab587a3"
      },
      "source": [
        "#code to make a submission\n",
        "test_fea = [str(i) for i in range(0,784)]\n",
        "X_test_t = pd.read_csv('testX.csv', usecols=test_fea)\n",
        "X_test_t =np.array(X_test_t, dtype ='float32')\n",
        "X_test_t = X_test_t.reshape(X_test_t.shape[0],*(28,28,1))\n",
        "X_test_t = X_test_t/255.0\n",
        "X_test_t.shape\n",
        "pred_test = cnn_model40.predict_classes(X_test_t)\n",
        "pred_test\n",
        "id = [i for i in range(0,10000)]\n",
        "frame = pd.DataFrame(id, columns=['Id'])\n",
        "frame['Label'] = pred_test\n",
        "frame\n",
        "frame.to_csv(r'submission.csv', index = False)\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions submit -c ece657a-w20-asg3-part2 -f submission.csv -m \"more dropout Submission\"\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-735600e3d473>:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 67.3k/67.3k [00:06<00:00, 10.4kB/s]\n",
            "Successfully submitted to ECE 657A Assignment 3 Part 2"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "be5efbbc-5ccf-4cfb-cd00-a8c5f75db9d6",
        "id": "vSqKetUg2nA7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#sigmoid\n",
        "image_rows = 28\n",
        "image_cols = 28\n",
        "batch_size = 512\n",
        "image_shape = (image_rows,image_cols,1)\n",
        "cnn_modelsi = Sequential([\n",
        "    Conv2D(filters=32,kernel_size=5,activation='sigmoid',padding='same',input_shape = image_shape),\n",
        "    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n",
        "    Conv2D(filters=64,kernel_size=3,activation='sigmoid',padding='same'),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Conv2D(filters=128,kernel_size=1,activation='sigmoid',padding='same'),\n",
        "    Dropout(0.2),\n",
        "    Flatten(), # 1flatten out the layers\n",
        "    Dense(1024,activation='sigmoid'),\n",
        "    Dropout(0.25),\n",
        "    Dense(32,activation='sigmoid'),\n",
        "    Dense(5,activation = 'softmax')\n",
        "])\n",
        "cnn_modelsi.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0001),metrics =['accuracy'])\n",
        "history = cnn_modelsi.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=1024,\n",
        "    epochs=400,\n",
        "    verbose=1,\n",
        "    validation_data=(X_test,y_test)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 1.6412 - accuracy: 0.1986 - val_loss: 1.6115 - val_accuracy: 0.1970\n",
            "Epoch 2/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.6112 - accuracy: 0.2017 - val_loss: 1.6099 - val_accuracy: 0.1958\n",
            "Epoch 3/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.6115 - accuracy: 0.2002 - val_loss: 1.6111 - val_accuracy: 0.1970\n",
            "Epoch 4/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.6113 - accuracy: 0.1998 - val_loss: 1.6097 - val_accuracy: 0.2038\n",
            "Epoch 5/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.6106 - accuracy: 0.1983 - val_loss: 1.6100 - val_accuracy: 0.1970\n",
            "Epoch 6/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.6104 - accuracy: 0.2015 - val_loss: 1.6100 - val_accuracy: 0.1958\n",
            "Epoch 7/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.6100 - accuracy: 0.1989 - val_loss: 1.6094 - val_accuracy: 0.1958\n",
            "Epoch 8/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.6098 - accuracy: 0.2026 - val_loss: 1.6092 - val_accuracy: 0.2038\n",
            "Epoch 9/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.6096 - accuracy: 0.2043 - val_loss: 1.6083 - val_accuracy: 0.2038\n",
            "Epoch 10/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.6064 - accuracy: 0.2225 - val_loss: 1.6013 - val_accuracy: 0.1983\n",
            "Epoch 11/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.5488 - accuracy: 0.3140 - val_loss: 1.4357 - val_accuracy: 0.3842\n",
            "Epoch 12/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.3450 - accuracy: 0.4141 - val_loss: 1.2644 - val_accuracy: 0.4593\n",
            "Epoch 13/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.2180 - accuracy: 0.4742 - val_loss: 1.1701 - val_accuracy: 0.5207\n",
            "Epoch 14/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.1416 - accuracy: 0.5269 - val_loss: 1.1066 - val_accuracy: 0.5498\n",
            "Epoch 15/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.0790 - accuracy: 0.5678 - val_loss: 1.0403 - val_accuracy: 0.5980\n",
            "Epoch 16/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.0205 - accuracy: 0.6011 - val_loss: 0.9879 - val_accuracy: 0.6225\n",
            "Epoch 17/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.9718 - accuracy: 0.6259 - val_loss: 0.9456 - val_accuracy: 0.6393\n",
            "Epoch 18/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.9349 - accuracy: 0.6397 - val_loss: 0.9146 - val_accuracy: 0.6550\n",
            "Epoch 19/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.9038 - accuracy: 0.6550 - val_loss: 0.8833 - val_accuracy: 0.6728\n",
            "Epoch 20/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.8765 - accuracy: 0.6646 - val_loss: 0.8615 - val_accuracy: 0.6717\n",
            "Epoch 21/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.8508 - accuracy: 0.6762 - val_loss: 0.8315 - val_accuracy: 0.6893\n",
            "Epoch 22/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.8270 - accuracy: 0.6833 - val_loss: 0.8058 - val_accuracy: 0.7018\n",
            "Epoch 23/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.8034 - accuracy: 0.6923 - val_loss: 0.7806 - val_accuracy: 0.7032\n",
            "Epoch 24/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.7815 - accuracy: 0.7020 - val_loss: 0.7603 - val_accuracy: 0.7137\n",
            "Epoch 25/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.7624 - accuracy: 0.7095 - val_loss: 0.7416 - val_accuracy: 0.7250\n",
            "Epoch 26/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.7418 - accuracy: 0.7203 - val_loss: 0.7216 - val_accuracy: 0.7317\n",
            "Epoch 27/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.7268 - accuracy: 0.7238 - val_loss: 0.7140 - val_accuracy: 0.7358\n",
            "Epoch 28/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.7136 - accuracy: 0.7314 - val_loss: 0.6928 - val_accuracy: 0.7452\n",
            "Epoch 29/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6990 - accuracy: 0.7380 - val_loss: 0.6765 - val_accuracy: 0.7532\n",
            "Epoch 30/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6846 - accuracy: 0.7440 - val_loss: 0.6637 - val_accuracy: 0.7580\n",
            "Epoch 31/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6720 - accuracy: 0.7515 - val_loss: 0.6522 - val_accuracy: 0.7600\n",
            "Epoch 32/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6614 - accuracy: 0.7561 - val_loss: 0.6403 - val_accuracy: 0.7667\n",
            "Epoch 33/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6509 - accuracy: 0.7606 - val_loss: 0.6286 - val_accuracy: 0.7733\n",
            "Epoch 34/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6420 - accuracy: 0.7633 - val_loss: 0.6194 - val_accuracy: 0.7767\n",
            "Epoch 35/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6310 - accuracy: 0.7690 - val_loss: 0.6069 - val_accuracy: 0.7808\n",
            "Epoch 36/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6208 - accuracy: 0.7720 - val_loss: 0.5986 - val_accuracy: 0.7842\n",
            "Epoch 37/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6096 - accuracy: 0.7784 - val_loss: 0.5856 - val_accuracy: 0.7915\n",
            "Epoch 38/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6000 - accuracy: 0.7825 - val_loss: 0.5772 - val_accuracy: 0.7963\n",
            "Epoch 39/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5915 - accuracy: 0.7860 - val_loss: 0.5680 - val_accuracy: 0.8007\n",
            "Epoch 40/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5838 - accuracy: 0.7886 - val_loss: 0.5580 - val_accuracy: 0.8052\n",
            "Epoch 41/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5754 - accuracy: 0.7924 - val_loss: 0.5502 - val_accuracy: 0.8062\n",
            "Epoch 42/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5667 - accuracy: 0.7949 - val_loss: 0.5448 - val_accuracy: 0.8060\n",
            "Epoch 43/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5601 - accuracy: 0.7987 - val_loss: 0.5365 - val_accuracy: 0.8125\n",
            "Epoch 44/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5555 - accuracy: 0.8000 - val_loss: 0.5340 - val_accuracy: 0.8118\n",
            "Epoch 45/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5489 - accuracy: 0.8018 - val_loss: 0.5248 - val_accuracy: 0.8143\n",
            "Epoch 46/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5430 - accuracy: 0.8053 - val_loss: 0.5204 - val_accuracy: 0.8170\n",
            "Epoch 47/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5363 - accuracy: 0.8076 - val_loss: 0.5103 - val_accuracy: 0.8228\n",
            "Epoch 48/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5274 - accuracy: 0.8127 - val_loss: 0.5067 - val_accuracy: 0.8215\n",
            "Epoch 49/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5273 - accuracy: 0.8103 - val_loss: 0.4985 - val_accuracy: 0.8257\n",
            "Epoch 50/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5199 - accuracy: 0.8143 - val_loss: 0.4962 - val_accuracy: 0.8245\n",
            "Epoch 51/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5155 - accuracy: 0.8152 - val_loss: 0.4900 - val_accuracy: 0.8293\n",
            "Epoch 52/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5104 - accuracy: 0.8174 - val_loss: 0.4834 - val_accuracy: 0.8317\n",
            "Epoch 53/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5056 - accuracy: 0.8195 - val_loss: 0.4882 - val_accuracy: 0.8295\n",
            "Epoch 54/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5022 - accuracy: 0.8191 - val_loss: 0.4785 - val_accuracy: 0.8338\n",
            "Epoch 55/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4968 - accuracy: 0.8226 - val_loss: 0.4708 - val_accuracy: 0.8365\n",
            "Epoch 56/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4935 - accuracy: 0.8234 - val_loss: 0.4671 - val_accuracy: 0.8363\n",
            "Epoch 57/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4872 - accuracy: 0.8260 - val_loss: 0.4625 - val_accuracy: 0.8392\n",
            "Epoch 58/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4842 - accuracy: 0.8277 - val_loss: 0.4607 - val_accuracy: 0.8423\n",
            "Epoch 59/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4820 - accuracy: 0.8288 - val_loss: 0.4552 - val_accuracy: 0.8412\n",
            "Epoch 60/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4780 - accuracy: 0.8296 - val_loss: 0.4514 - val_accuracy: 0.8457\n",
            "Epoch 61/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4742 - accuracy: 0.8300 - val_loss: 0.4500 - val_accuracy: 0.8412\n",
            "Epoch 62/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4714 - accuracy: 0.8315 - val_loss: 0.4462 - val_accuracy: 0.8440\n",
            "Epoch 63/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4682 - accuracy: 0.8324 - val_loss: 0.4432 - val_accuracy: 0.8448\n",
            "Epoch 64/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4631 - accuracy: 0.8340 - val_loss: 0.4394 - val_accuracy: 0.8485\n",
            "Epoch 65/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4598 - accuracy: 0.8352 - val_loss: 0.4350 - val_accuracy: 0.8510\n",
            "Epoch 66/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4577 - accuracy: 0.8352 - val_loss: 0.4355 - val_accuracy: 0.8463\n",
            "Epoch 67/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4552 - accuracy: 0.8354 - val_loss: 0.4294 - val_accuracy: 0.8508\n",
            "Epoch 68/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4541 - accuracy: 0.8367 - val_loss: 0.4302 - val_accuracy: 0.8513\n",
            "Epoch 69/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4507 - accuracy: 0.8376 - val_loss: 0.4241 - val_accuracy: 0.8532\n",
            "Epoch 70/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4469 - accuracy: 0.8389 - val_loss: 0.4224 - val_accuracy: 0.8530\n",
            "Epoch 71/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4445 - accuracy: 0.8399 - val_loss: 0.4204 - val_accuracy: 0.8542\n",
            "Epoch 72/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4408 - accuracy: 0.8411 - val_loss: 0.4197 - val_accuracy: 0.8518\n",
            "Epoch 73/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4384 - accuracy: 0.8426 - val_loss: 0.4139 - val_accuracy: 0.8563\n",
            "Epoch 74/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4371 - accuracy: 0.8427 - val_loss: 0.4118 - val_accuracy: 0.8567\n",
            "Epoch 75/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4349 - accuracy: 0.8429 - val_loss: 0.4076 - val_accuracy: 0.8577\n",
            "Epoch 76/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4325 - accuracy: 0.8439 - val_loss: 0.4057 - val_accuracy: 0.8590\n",
            "Epoch 77/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4306 - accuracy: 0.8442 - val_loss: 0.4056 - val_accuracy: 0.8580\n",
            "Epoch 78/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4280 - accuracy: 0.8453 - val_loss: 0.4003 - val_accuracy: 0.8622\n",
            "Epoch 79/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4266 - accuracy: 0.8456 - val_loss: 0.4026 - val_accuracy: 0.8605\n",
            "Epoch 80/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4258 - accuracy: 0.8444 - val_loss: 0.4024 - val_accuracy: 0.8583\n",
            "Epoch 81/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4221 - accuracy: 0.8471 - val_loss: 0.3967 - val_accuracy: 0.8610\n",
            "Epoch 82/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4213 - accuracy: 0.8471 - val_loss: 0.3940 - val_accuracy: 0.8622\n",
            "Epoch 83/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4161 - accuracy: 0.8485 - val_loss: 0.3921 - val_accuracy: 0.8648\n",
            "Epoch 84/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4140 - accuracy: 0.8498 - val_loss: 0.3892 - val_accuracy: 0.8662\n",
            "Epoch 85/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4126 - accuracy: 0.8506 - val_loss: 0.3892 - val_accuracy: 0.8645\n",
            "Epoch 86/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4110 - accuracy: 0.8516 - val_loss: 0.3867 - val_accuracy: 0.8622\n",
            "Epoch 87/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4091 - accuracy: 0.8528 - val_loss: 0.3865 - val_accuracy: 0.8632\n",
            "Epoch 88/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4100 - accuracy: 0.8504 - val_loss: 0.3849 - val_accuracy: 0.8662\n",
            "Epoch 89/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4043 - accuracy: 0.8543 - val_loss: 0.3836 - val_accuracy: 0.8653\n",
            "Epoch 90/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4043 - accuracy: 0.8532 - val_loss: 0.3798 - val_accuracy: 0.8670\n",
            "Epoch 91/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4020 - accuracy: 0.8541 - val_loss: 0.3773 - val_accuracy: 0.8678\n",
            "Epoch 92/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3999 - accuracy: 0.8539 - val_loss: 0.3751 - val_accuracy: 0.8685\n",
            "Epoch 93/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3984 - accuracy: 0.8559 - val_loss: 0.3742 - val_accuracy: 0.8670\n",
            "Epoch 94/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3965 - accuracy: 0.8559 - val_loss: 0.3760 - val_accuracy: 0.8660\n",
            "Epoch 95/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3979 - accuracy: 0.8539 - val_loss: 0.3719 - val_accuracy: 0.8682\n",
            "Epoch 96/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3956 - accuracy: 0.8563 - val_loss: 0.3702 - val_accuracy: 0.8647\n",
            "Epoch 97/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3930 - accuracy: 0.8567 - val_loss: 0.3695 - val_accuracy: 0.8710\n",
            "Epoch 98/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3914 - accuracy: 0.8570 - val_loss: 0.3675 - val_accuracy: 0.8680\n",
            "Epoch 99/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3901 - accuracy: 0.8581 - val_loss: 0.3654 - val_accuracy: 0.8685\n",
            "Epoch 100/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3871 - accuracy: 0.8590 - val_loss: 0.3646 - val_accuracy: 0.8697\n",
            "Epoch 101/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3853 - accuracy: 0.8590 - val_loss: 0.3656 - val_accuracy: 0.8678\n",
            "Epoch 102/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3838 - accuracy: 0.8593 - val_loss: 0.3631 - val_accuracy: 0.8713\n",
            "Epoch 103/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3836 - accuracy: 0.8596 - val_loss: 0.3611 - val_accuracy: 0.8718\n",
            "Epoch 104/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3817 - accuracy: 0.8599 - val_loss: 0.3626 - val_accuracy: 0.8670\n",
            "Epoch 105/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3817 - accuracy: 0.8604 - val_loss: 0.3568 - val_accuracy: 0.8732\n",
            "Epoch 106/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3798 - accuracy: 0.8600 - val_loss: 0.3546 - val_accuracy: 0.8733\n",
            "Epoch 107/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3771 - accuracy: 0.8614 - val_loss: 0.3544 - val_accuracy: 0.8725\n",
            "Epoch 108/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3784 - accuracy: 0.8606 - val_loss: 0.3535 - val_accuracy: 0.8710\n",
            "Epoch 109/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3763 - accuracy: 0.8623 - val_loss: 0.3562 - val_accuracy: 0.8702\n",
            "Epoch 110/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3737 - accuracy: 0.8632 - val_loss: 0.3494 - val_accuracy: 0.8725\n",
            "Epoch 111/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3736 - accuracy: 0.8624 - val_loss: 0.3506 - val_accuracy: 0.8750\n",
            "Epoch 112/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3728 - accuracy: 0.8623 - val_loss: 0.3491 - val_accuracy: 0.8747\n",
            "Epoch 113/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3708 - accuracy: 0.8628 - val_loss: 0.3474 - val_accuracy: 0.8748\n",
            "Epoch 114/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3699 - accuracy: 0.8629 - val_loss: 0.3489 - val_accuracy: 0.8733\n",
            "Epoch 115/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3684 - accuracy: 0.8634 - val_loss: 0.3503 - val_accuracy: 0.8743\n",
            "Epoch 116/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3694 - accuracy: 0.8644 - val_loss: 0.3451 - val_accuracy: 0.8740\n",
            "Epoch 117/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3663 - accuracy: 0.8653 - val_loss: 0.3424 - val_accuracy: 0.8770\n",
            "Epoch 118/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3647 - accuracy: 0.8651 - val_loss: 0.3441 - val_accuracy: 0.8748\n",
            "Epoch 119/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3632 - accuracy: 0.8648 - val_loss: 0.3423 - val_accuracy: 0.8745\n",
            "Epoch 120/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3635 - accuracy: 0.8657 - val_loss: 0.3410 - val_accuracy: 0.8753\n",
            "Epoch 121/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3649 - accuracy: 0.8652 - val_loss: 0.3403 - val_accuracy: 0.8767\n",
            "Epoch 122/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3607 - accuracy: 0.8661 - val_loss: 0.3419 - val_accuracy: 0.8770\n",
            "Epoch 123/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3608 - accuracy: 0.8653 - val_loss: 0.3369 - val_accuracy: 0.8752\n",
            "Epoch 124/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3592 - accuracy: 0.8674 - val_loss: 0.3366 - val_accuracy: 0.8783\n",
            "Epoch 125/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3582 - accuracy: 0.8661 - val_loss: 0.3378 - val_accuracy: 0.8788\n",
            "Epoch 126/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3568 - accuracy: 0.8680 - val_loss: 0.3352 - val_accuracy: 0.8752\n",
            "Epoch 127/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3581 - accuracy: 0.8674 - val_loss: 0.3422 - val_accuracy: 0.8697\n",
            "Epoch 128/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3571 - accuracy: 0.8665 - val_loss: 0.3340 - val_accuracy: 0.8755\n",
            "Epoch 129/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3544 - accuracy: 0.8689 - val_loss: 0.3322 - val_accuracy: 0.8802\n",
            "Epoch 130/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3518 - accuracy: 0.8692 - val_loss: 0.3306 - val_accuracy: 0.8800\n",
            "Epoch 131/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3548 - accuracy: 0.8670 - val_loss: 0.3315 - val_accuracy: 0.8768\n",
            "Epoch 132/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3524 - accuracy: 0.8685 - val_loss: 0.3306 - val_accuracy: 0.8782\n",
            "Epoch 133/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3499 - accuracy: 0.8703 - val_loss: 0.3301 - val_accuracy: 0.8780\n",
            "Epoch 134/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3504 - accuracy: 0.8689 - val_loss: 0.3292 - val_accuracy: 0.8763\n",
            "Epoch 135/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3488 - accuracy: 0.8702 - val_loss: 0.3257 - val_accuracy: 0.8800\n",
            "Epoch 136/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3486 - accuracy: 0.8704 - val_loss: 0.3258 - val_accuracy: 0.8787\n",
            "Epoch 137/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3486 - accuracy: 0.8692 - val_loss: 0.3293 - val_accuracy: 0.8778\n",
            "Epoch 138/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3467 - accuracy: 0.8703 - val_loss: 0.3271 - val_accuracy: 0.8795\n",
            "Epoch 139/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3460 - accuracy: 0.8710 - val_loss: 0.3265 - val_accuracy: 0.8775\n",
            "Epoch 140/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3446 - accuracy: 0.8716 - val_loss: 0.3237 - val_accuracy: 0.8805\n",
            "Epoch 141/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3450 - accuracy: 0.8715 - val_loss: 0.3275 - val_accuracy: 0.8795\n",
            "Epoch 142/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3429 - accuracy: 0.8712 - val_loss: 0.3228 - val_accuracy: 0.8800\n",
            "Epoch 143/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3431 - accuracy: 0.8706 - val_loss: 0.3233 - val_accuracy: 0.8798\n",
            "Epoch 144/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3452 - accuracy: 0.8704 - val_loss: 0.3215 - val_accuracy: 0.8837\n",
            "Epoch 145/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3419 - accuracy: 0.8714 - val_loss: 0.3213 - val_accuracy: 0.8800\n",
            "Epoch 146/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3403 - accuracy: 0.8736 - val_loss: 0.3210 - val_accuracy: 0.8802\n",
            "Epoch 147/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3398 - accuracy: 0.8726 - val_loss: 0.3219 - val_accuracy: 0.8787\n",
            "Epoch 148/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3378 - accuracy: 0.8742 - val_loss: 0.3177 - val_accuracy: 0.8792\n",
            "Epoch 149/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3388 - accuracy: 0.8724 - val_loss: 0.3183 - val_accuracy: 0.8832\n",
            "Epoch 150/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3360 - accuracy: 0.8740 - val_loss: 0.3163 - val_accuracy: 0.8835\n",
            "Epoch 151/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3383 - accuracy: 0.8717 - val_loss: 0.3176 - val_accuracy: 0.8842\n",
            "Epoch 152/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3357 - accuracy: 0.8731 - val_loss: 0.3159 - val_accuracy: 0.8818\n",
            "Epoch 153/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3370 - accuracy: 0.8727 - val_loss: 0.3156 - val_accuracy: 0.8857\n",
            "Epoch 154/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3335 - accuracy: 0.8752 - val_loss: 0.3170 - val_accuracy: 0.8828\n",
            "Epoch 155/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3345 - accuracy: 0.8742 - val_loss: 0.3139 - val_accuracy: 0.8798\n",
            "Epoch 156/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3345 - accuracy: 0.8739 - val_loss: 0.3143 - val_accuracy: 0.8837\n",
            "Epoch 157/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3333 - accuracy: 0.8733 - val_loss: 0.3135 - val_accuracy: 0.8842\n",
            "Epoch 158/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3318 - accuracy: 0.8750 - val_loss: 0.3140 - val_accuracy: 0.8832\n",
            "Epoch 159/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3297 - accuracy: 0.8765 - val_loss: 0.3122 - val_accuracy: 0.8835\n",
            "Epoch 160/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3312 - accuracy: 0.8755 - val_loss: 0.3135 - val_accuracy: 0.8857\n",
            "Epoch 161/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3327 - accuracy: 0.8733 - val_loss: 0.3140 - val_accuracy: 0.8817\n",
            "Epoch 162/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3284 - accuracy: 0.8767 - val_loss: 0.3117 - val_accuracy: 0.8823\n",
            "Epoch 163/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3291 - accuracy: 0.8768 - val_loss: 0.3083 - val_accuracy: 0.8865\n",
            "Epoch 164/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3259 - accuracy: 0.8769 - val_loss: 0.3097 - val_accuracy: 0.8852\n",
            "Epoch 165/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3272 - accuracy: 0.8762 - val_loss: 0.3131 - val_accuracy: 0.8860\n",
            "Epoch 166/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3288 - accuracy: 0.8748 - val_loss: 0.3094 - val_accuracy: 0.8832\n",
            "Epoch 167/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3241 - accuracy: 0.8771 - val_loss: 0.3083 - val_accuracy: 0.8867\n",
            "Epoch 168/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3266 - accuracy: 0.8763 - val_loss: 0.3083 - val_accuracy: 0.8850\n",
            "Epoch 169/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3268 - accuracy: 0.8765 - val_loss: 0.3065 - val_accuracy: 0.8855\n",
            "Epoch 170/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3249 - accuracy: 0.8768 - val_loss: 0.3051 - val_accuracy: 0.8853\n",
            "Epoch 171/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3232 - accuracy: 0.8775 - val_loss: 0.3058 - val_accuracy: 0.8867\n",
            "Epoch 172/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3237 - accuracy: 0.8773 - val_loss: 0.3040 - val_accuracy: 0.8883\n",
            "Epoch 173/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3230 - accuracy: 0.8769 - val_loss: 0.3060 - val_accuracy: 0.8868\n",
            "Epoch 174/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3214 - accuracy: 0.8776 - val_loss: 0.3029 - val_accuracy: 0.8882\n",
            "Epoch 175/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3206 - accuracy: 0.8776 - val_loss: 0.3023 - val_accuracy: 0.8855\n",
            "Epoch 176/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3224 - accuracy: 0.8777 - val_loss: 0.3030 - val_accuracy: 0.8848\n",
            "Epoch 177/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3208 - accuracy: 0.8786 - val_loss: 0.3061 - val_accuracy: 0.8848\n",
            "Epoch 178/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3190 - accuracy: 0.8780 - val_loss: 0.3030 - val_accuracy: 0.8873\n",
            "Epoch 179/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3189 - accuracy: 0.8793 - val_loss: 0.3021 - val_accuracy: 0.8860\n",
            "Epoch 180/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3177 - accuracy: 0.8799 - val_loss: 0.3040 - val_accuracy: 0.8830\n",
            "Epoch 181/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3185 - accuracy: 0.8787 - val_loss: 0.3002 - val_accuracy: 0.8862\n",
            "Epoch 182/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3195 - accuracy: 0.8787 - val_loss: 0.2989 - val_accuracy: 0.8878\n",
            "Epoch 183/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3177 - accuracy: 0.8790 - val_loss: 0.3003 - val_accuracy: 0.8878\n",
            "Epoch 184/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3158 - accuracy: 0.8796 - val_loss: 0.2997 - val_accuracy: 0.8888\n",
            "Epoch 185/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3147 - accuracy: 0.8816 - val_loss: 0.3017 - val_accuracy: 0.8858\n",
            "Epoch 186/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3146 - accuracy: 0.8811 - val_loss: 0.3005 - val_accuracy: 0.8878\n",
            "Epoch 187/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3131 - accuracy: 0.8801 - val_loss: 0.2966 - val_accuracy: 0.8902\n",
            "Epoch 188/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3133 - accuracy: 0.8807 - val_loss: 0.2982 - val_accuracy: 0.8883\n",
            "Epoch 189/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3137 - accuracy: 0.8802 - val_loss: 0.3078 - val_accuracy: 0.8837\n",
            "Epoch 190/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3150 - accuracy: 0.8796 - val_loss: 0.3001 - val_accuracy: 0.8875\n",
            "Epoch 191/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3106 - accuracy: 0.8825 - val_loss: 0.2974 - val_accuracy: 0.8877\n",
            "Epoch 192/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3126 - accuracy: 0.8812 - val_loss: 0.2972 - val_accuracy: 0.8890\n",
            "Epoch 193/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3104 - accuracy: 0.8822 - val_loss: 0.2970 - val_accuracy: 0.8855\n",
            "Epoch 194/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3144 - accuracy: 0.8788 - val_loss: 0.2944 - val_accuracy: 0.8883\n",
            "Epoch 195/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3094 - accuracy: 0.8821 - val_loss: 0.2929 - val_accuracy: 0.8877\n",
            "Epoch 196/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3111 - accuracy: 0.8809 - val_loss: 0.2947 - val_accuracy: 0.8880\n",
            "Epoch 197/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3074 - accuracy: 0.8833 - val_loss: 0.2942 - val_accuracy: 0.8908\n",
            "Epoch 198/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3090 - accuracy: 0.8825 - val_loss: 0.2928 - val_accuracy: 0.8907\n",
            "Epoch 199/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3087 - accuracy: 0.8824 - val_loss: 0.2944 - val_accuracy: 0.8887\n",
            "Epoch 200/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3077 - accuracy: 0.8825 - val_loss: 0.2942 - val_accuracy: 0.8873\n",
            "Epoch 201/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3079 - accuracy: 0.8833 - val_loss: 0.2920 - val_accuracy: 0.8897\n",
            "Epoch 202/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3074 - accuracy: 0.8820 - val_loss: 0.2924 - val_accuracy: 0.8915\n",
            "Epoch 203/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3054 - accuracy: 0.8829 - val_loss: 0.2910 - val_accuracy: 0.8927\n",
            "Epoch 204/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3035 - accuracy: 0.8846 - val_loss: 0.2898 - val_accuracy: 0.8912\n",
            "Epoch 205/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3039 - accuracy: 0.8846 - val_loss: 0.2895 - val_accuracy: 0.8908\n",
            "Epoch 206/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3063 - accuracy: 0.8822 - val_loss: 0.2921 - val_accuracy: 0.8898\n",
            "Epoch 207/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3059 - accuracy: 0.8841 - val_loss: 0.2928 - val_accuracy: 0.8883\n",
            "Epoch 208/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3036 - accuracy: 0.8829 - val_loss: 0.2939 - val_accuracy: 0.8910\n",
            "Epoch 209/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3033 - accuracy: 0.8833 - val_loss: 0.2925 - val_accuracy: 0.8907\n",
            "Epoch 210/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3025 - accuracy: 0.8839 - val_loss: 0.2900 - val_accuracy: 0.8908\n",
            "Epoch 211/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3039 - accuracy: 0.8834 - val_loss: 0.2895 - val_accuracy: 0.8927\n",
            "Epoch 212/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3031 - accuracy: 0.8836 - val_loss: 0.2871 - val_accuracy: 0.8925\n",
            "Epoch 213/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3009 - accuracy: 0.8838 - val_loss: 0.2877 - val_accuracy: 0.8902\n",
            "Epoch 214/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3036 - accuracy: 0.8841 - val_loss: 0.2868 - val_accuracy: 0.8928\n",
            "Epoch 215/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3010 - accuracy: 0.8841 - val_loss: 0.2855 - val_accuracy: 0.8918\n",
            "Epoch 216/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2985 - accuracy: 0.8857 - val_loss: 0.2860 - val_accuracy: 0.8908\n",
            "Epoch 217/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2991 - accuracy: 0.8852 - val_loss: 0.2853 - val_accuracy: 0.8907\n",
            "Epoch 218/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2999 - accuracy: 0.8845 - val_loss: 0.2851 - val_accuracy: 0.8915\n",
            "Epoch 219/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2987 - accuracy: 0.8855 - val_loss: 0.2848 - val_accuracy: 0.8932\n",
            "Epoch 220/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2970 - accuracy: 0.8857 - val_loss: 0.2845 - val_accuracy: 0.8902\n",
            "Epoch 221/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2981 - accuracy: 0.8863 - val_loss: 0.2877 - val_accuracy: 0.8915\n",
            "Epoch 222/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2983 - accuracy: 0.8859 - val_loss: 0.2858 - val_accuracy: 0.8920\n",
            "Epoch 223/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2960 - accuracy: 0.8862 - val_loss: 0.2844 - val_accuracy: 0.8918\n",
            "Epoch 224/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2981 - accuracy: 0.8851 - val_loss: 0.2842 - val_accuracy: 0.8918\n",
            "Epoch 225/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2987 - accuracy: 0.8860 - val_loss: 0.2864 - val_accuracy: 0.8912\n",
            "Epoch 226/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2955 - accuracy: 0.8871 - val_loss: 0.2860 - val_accuracy: 0.8903\n",
            "Epoch 227/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2965 - accuracy: 0.8867 - val_loss: 0.2841 - val_accuracy: 0.8928\n",
            "Epoch 228/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2940 - accuracy: 0.8869 - val_loss: 0.2819 - val_accuracy: 0.8938\n",
            "Epoch 229/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2955 - accuracy: 0.8873 - val_loss: 0.2839 - val_accuracy: 0.8920\n",
            "Epoch 230/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2958 - accuracy: 0.8862 - val_loss: 0.2839 - val_accuracy: 0.8922\n",
            "Epoch 231/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2951 - accuracy: 0.8864 - val_loss: 0.2835 - val_accuracy: 0.8907\n",
            "Epoch 232/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2927 - accuracy: 0.8881 - val_loss: 0.2820 - val_accuracy: 0.8932\n",
            "Epoch 233/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2922 - accuracy: 0.8861 - val_loss: 0.2812 - val_accuracy: 0.8957\n",
            "Epoch 234/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2916 - accuracy: 0.8894 - val_loss: 0.2810 - val_accuracy: 0.8942\n",
            "Epoch 235/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2918 - accuracy: 0.8881 - val_loss: 0.2838 - val_accuracy: 0.8897\n",
            "Epoch 236/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2908 - accuracy: 0.8886 - val_loss: 0.2810 - val_accuracy: 0.8940\n",
            "Epoch 237/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2899 - accuracy: 0.8877 - val_loss: 0.2810 - val_accuracy: 0.8910\n",
            "Epoch 238/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2921 - accuracy: 0.8864 - val_loss: 0.2827 - val_accuracy: 0.8923\n",
            "Epoch 239/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2900 - accuracy: 0.8887 - val_loss: 0.2805 - val_accuracy: 0.8948\n",
            "Epoch 240/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2900 - accuracy: 0.8884 - val_loss: 0.2781 - val_accuracy: 0.8942\n",
            "Epoch 241/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2896 - accuracy: 0.8886 - val_loss: 0.2771 - val_accuracy: 0.8977\n",
            "Epoch 242/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2892 - accuracy: 0.8889 - val_loss: 0.2797 - val_accuracy: 0.8923\n",
            "Epoch 243/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2899 - accuracy: 0.8881 - val_loss: 0.2781 - val_accuracy: 0.8953\n",
            "Epoch 244/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2877 - accuracy: 0.8895 - val_loss: 0.2775 - val_accuracy: 0.8933\n",
            "Epoch 245/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2903 - accuracy: 0.8874 - val_loss: 0.2779 - val_accuracy: 0.8947\n",
            "Epoch 246/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2892 - accuracy: 0.8887 - val_loss: 0.2797 - val_accuracy: 0.8938\n",
            "Epoch 247/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2864 - accuracy: 0.8880 - val_loss: 0.2808 - val_accuracy: 0.8905\n",
            "Epoch 248/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2865 - accuracy: 0.8891 - val_loss: 0.2762 - val_accuracy: 0.8957\n",
            "Epoch 249/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2849 - accuracy: 0.8900 - val_loss: 0.2750 - val_accuracy: 0.8940\n",
            "Epoch 250/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2859 - accuracy: 0.8887 - val_loss: 0.2766 - val_accuracy: 0.8938\n",
            "Epoch 251/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2876 - accuracy: 0.8887 - val_loss: 0.2776 - val_accuracy: 0.8930\n",
            "Epoch 252/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2877 - accuracy: 0.8894 - val_loss: 0.2786 - val_accuracy: 0.8958\n",
            "Epoch 253/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2842 - accuracy: 0.8898 - val_loss: 0.2768 - val_accuracy: 0.8965\n",
            "Epoch 254/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2855 - accuracy: 0.8895 - val_loss: 0.2747 - val_accuracy: 0.8967\n",
            "Epoch 255/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2844 - accuracy: 0.8892 - val_loss: 0.2762 - val_accuracy: 0.8932\n",
            "Epoch 256/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2825 - accuracy: 0.8899 - val_loss: 0.2739 - val_accuracy: 0.8960\n",
            "Epoch 257/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2841 - accuracy: 0.8909 - val_loss: 0.2813 - val_accuracy: 0.8898\n",
            "Epoch 258/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2832 - accuracy: 0.8902 - val_loss: 0.2753 - val_accuracy: 0.8962\n",
            "Epoch 259/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2840 - accuracy: 0.8897 - val_loss: 0.2741 - val_accuracy: 0.8960\n",
            "Epoch 260/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2835 - accuracy: 0.8893 - val_loss: 0.2751 - val_accuracy: 0.8975\n",
            "Epoch 261/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2839 - accuracy: 0.8897 - val_loss: 0.2742 - val_accuracy: 0.8973\n",
            "Epoch 262/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2814 - accuracy: 0.8915 - val_loss: 0.2736 - val_accuracy: 0.8962\n",
            "Epoch 263/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2834 - accuracy: 0.8900 - val_loss: 0.2738 - val_accuracy: 0.8958\n",
            "Epoch 264/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2821 - accuracy: 0.8912 - val_loss: 0.2797 - val_accuracy: 0.8905\n",
            "Epoch 265/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2831 - accuracy: 0.8910 - val_loss: 0.2726 - val_accuracy: 0.8960\n",
            "Epoch 266/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2807 - accuracy: 0.8911 - val_loss: 0.2760 - val_accuracy: 0.8958\n",
            "Epoch 267/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2820 - accuracy: 0.8906 - val_loss: 0.2750 - val_accuracy: 0.8942\n",
            "Epoch 268/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2800 - accuracy: 0.8913 - val_loss: 0.2715 - val_accuracy: 0.8962\n",
            "Epoch 269/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2797 - accuracy: 0.8914 - val_loss: 0.2720 - val_accuracy: 0.8945\n",
            "Epoch 270/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2801 - accuracy: 0.8923 - val_loss: 0.2713 - val_accuracy: 0.8978\n",
            "Epoch 271/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2794 - accuracy: 0.8929 - val_loss: 0.2740 - val_accuracy: 0.8947\n",
            "Epoch 272/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2791 - accuracy: 0.8914 - val_loss: 0.2718 - val_accuracy: 0.8957\n",
            "Epoch 273/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2795 - accuracy: 0.8917 - val_loss: 0.2703 - val_accuracy: 0.8980\n",
            "Epoch 274/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2772 - accuracy: 0.8914 - val_loss: 0.2731 - val_accuracy: 0.8963\n",
            "Epoch 275/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2772 - accuracy: 0.8921 - val_loss: 0.2717 - val_accuracy: 0.8968\n",
            "Epoch 276/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2778 - accuracy: 0.8919 - val_loss: 0.2700 - val_accuracy: 0.8980\n",
            "Epoch 277/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2775 - accuracy: 0.8919 - val_loss: 0.2713 - val_accuracy: 0.8968\n",
            "Epoch 278/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2787 - accuracy: 0.8918 - val_loss: 0.2703 - val_accuracy: 0.8975\n",
            "Epoch 279/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2776 - accuracy: 0.8921 - val_loss: 0.2680 - val_accuracy: 0.8983\n",
            "Epoch 280/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2752 - accuracy: 0.8930 - val_loss: 0.2687 - val_accuracy: 0.8970\n",
            "Epoch 281/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2759 - accuracy: 0.8931 - val_loss: 0.2694 - val_accuracy: 0.8965\n",
            "Epoch 282/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2756 - accuracy: 0.8915 - val_loss: 0.2689 - val_accuracy: 0.8985\n",
            "Epoch 283/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2759 - accuracy: 0.8938 - val_loss: 0.2694 - val_accuracy: 0.8970\n",
            "Epoch 284/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2754 - accuracy: 0.8922 - val_loss: 0.2675 - val_accuracy: 0.8977\n",
            "Epoch 285/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2742 - accuracy: 0.8933 - val_loss: 0.2690 - val_accuracy: 0.8980\n",
            "Epoch 286/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2739 - accuracy: 0.8927 - val_loss: 0.2665 - val_accuracy: 0.8980\n",
            "Epoch 287/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2724 - accuracy: 0.8934 - val_loss: 0.2701 - val_accuracy: 0.8967\n",
            "Epoch 288/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2726 - accuracy: 0.8932 - val_loss: 0.2688 - val_accuracy: 0.8978\n",
            "Epoch 289/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2725 - accuracy: 0.8946 - val_loss: 0.2679 - val_accuracy: 0.8970\n",
            "Epoch 290/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2714 - accuracy: 0.8944 - val_loss: 0.2665 - val_accuracy: 0.8980\n",
            "Epoch 291/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2744 - accuracy: 0.8935 - val_loss: 0.2661 - val_accuracy: 0.8985\n",
            "Epoch 292/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2739 - accuracy: 0.8936 - val_loss: 0.2662 - val_accuracy: 0.8980\n",
            "Epoch 293/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2720 - accuracy: 0.8934 - val_loss: 0.2678 - val_accuracy: 0.8973\n",
            "Epoch 294/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2731 - accuracy: 0.8945 - val_loss: 0.2664 - val_accuracy: 0.8958\n",
            "Epoch 295/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2720 - accuracy: 0.8941 - val_loss: 0.2677 - val_accuracy: 0.8973\n",
            "Epoch 296/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2702 - accuracy: 0.8955 - val_loss: 0.2681 - val_accuracy: 0.8970\n",
            "Epoch 297/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2714 - accuracy: 0.8950 - val_loss: 0.2644 - val_accuracy: 0.8978\n",
            "Epoch 298/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2721 - accuracy: 0.8937 - val_loss: 0.2716 - val_accuracy: 0.8927\n",
            "Epoch 299/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2698 - accuracy: 0.8947 - val_loss: 0.2648 - val_accuracy: 0.8988\n",
            "Epoch 300/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2690 - accuracy: 0.8953 - val_loss: 0.2661 - val_accuracy: 0.8968\n",
            "Epoch 301/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2707 - accuracy: 0.8949 - val_loss: 0.2642 - val_accuracy: 0.8995\n",
            "Epoch 302/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2705 - accuracy: 0.8948 - val_loss: 0.2653 - val_accuracy: 0.8982\n",
            "Epoch 303/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2680 - accuracy: 0.8961 - val_loss: 0.2667 - val_accuracy: 0.8992\n",
            "Epoch 304/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2704 - accuracy: 0.8944 - val_loss: 0.2664 - val_accuracy: 0.8963\n",
            "Epoch 305/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2698 - accuracy: 0.8942 - val_loss: 0.2643 - val_accuracy: 0.8993\n",
            "Epoch 306/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2687 - accuracy: 0.8947 - val_loss: 0.2669 - val_accuracy: 0.8955\n",
            "Epoch 307/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2680 - accuracy: 0.8957 - val_loss: 0.2658 - val_accuracy: 0.8962\n",
            "Epoch 308/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2692 - accuracy: 0.8961 - val_loss: 0.2627 - val_accuracy: 0.9008\n",
            "Epoch 309/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2642 - accuracy: 0.8964 - val_loss: 0.2652 - val_accuracy: 0.8990\n",
            "Epoch 310/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2641 - accuracy: 0.8969 - val_loss: 0.2629 - val_accuracy: 0.8978\n",
            "Epoch 311/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2677 - accuracy: 0.8961 - val_loss: 0.2615 - val_accuracy: 0.8982\n",
            "Epoch 312/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2677 - accuracy: 0.8965 - val_loss: 0.2633 - val_accuracy: 0.9002\n",
            "Epoch 313/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2659 - accuracy: 0.8977 - val_loss: 0.2649 - val_accuracy: 0.8990\n",
            "Epoch 314/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2635 - accuracy: 0.8973 - val_loss: 0.2630 - val_accuracy: 0.8987\n",
            "Epoch 315/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2635 - accuracy: 0.8978 - val_loss: 0.2681 - val_accuracy: 0.8952\n",
            "Epoch 316/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2647 - accuracy: 0.8972 - val_loss: 0.2632 - val_accuracy: 0.9002\n",
            "Epoch 317/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2661 - accuracy: 0.8962 - val_loss: 0.2632 - val_accuracy: 0.8983\n",
            "Epoch 318/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2647 - accuracy: 0.8961 - val_loss: 0.2625 - val_accuracy: 0.8990\n",
            "Epoch 319/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2642 - accuracy: 0.8959 - val_loss: 0.2626 - val_accuracy: 0.8982\n",
            "Epoch 320/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2638 - accuracy: 0.8977 - val_loss: 0.2648 - val_accuracy: 0.8985\n",
            "Epoch 321/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2613 - accuracy: 0.8973 - val_loss: 0.2629 - val_accuracy: 0.8988\n",
            "Epoch 322/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2627 - accuracy: 0.8966 - val_loss: 0.2659 - val_accuracy: 0.8982\n",
            "Epoch 323/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2625 - accuracy: 0.8987 - val_loss: 0.2635 - val_accuracy: 0.8980\n",
            "Epoch 324/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2631 - accuracy: 0.8982 - val_loss: 0.2612 - val_accuracy: 0.8968\n",
            "Epoch 325/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2631 - accuracy: 0.8967 - val_loss: 0.2606 - val_accuracy: 0.8995\n",
            "Epoch 326/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2643 - accuracy: 0.8976 - val_loss: 0.2622 - val_accuracy: 0.8987\n",
            "Epoch 327/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2625 - accuracy: 0.8988 - val_loss: 0.2647 - val_accuracy: 0.8973\n",
            "Epoch 328/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2638 - accuracy: 0.8971 - val_loss: 0.2595 - val_accuracy: 0.9000\n",
            "Epoch 329/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2608 - accuracy: 0.8975 - val_loss: 0.2617 - val_accuracy: 0.8973\n",
            "Epoch 330/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2612 - accuracy: 0.8984 - val_loss: 0.2620 - val_accuracy: 0.8995\n",
            "Epoch 331/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2604 - accuracy: 0.8979 - val_loss: 0.2602 - val_accuracy: 0.9013\n",
            "Epoch 332/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2594 - accuracy: 0.8991 - val_loss: 0.2614 - val_accuracy: 0.8987\n",
            "Epoch 333/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2610 - accuracy: 0.8968 - val_loss: 0.2602 - val_accuracy: 0.8980\n",
            "Epoch 334/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2630 - accuracy: 0.8983 - val_loss: 0.2595 - val_accuracy: 0.9005\n",
            "Epoch 335/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2608 - accuracy: 0.8992 - val_loss: 0.2632 - val_accuracy: 0.9000\n",
            "Epoch 336/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2590 - accuracy: 0.9001 - val_loss: 0.2597 - val_accuracy: 0.9010\n",
            "Epoch 337/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2590 - accuracy: 0.8991 - val_loss: 0.2616 - val_accuracy: 0.8972\n",
            "Epoch 338/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2611 - accuracy: 0.8963 - val_loss: 0.2594 - val_accuracy: 0.9003\n",
            "Epoch 339/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2581 - accuracy: 0.8987 - val_loss: 0.2633 - val_accuracy: 0.8975\n",
            "Epoch 340/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2610 - accuracy: 0.8977 - val_loss: 0.2589 - val_accuracy: 0.9018\n",
            "Epoch 341/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2604 - accuracy: 0.8984 - val_loss: 0.2587 - val_accuracy: 0.9003\n",
            "Epoch 342/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2568 - accuracy: 0.9005 - val_loss: 0.2617 - val_accuracy: 0.9000\n",
            "Epoch 343/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2580 - accuracy: 0.9000 - val_loss: 0.2569 - val_accuracy: 0.8995\n",
            "Epoch 344/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2589 - accuracy: 0.8994 - val_loss: 0.2584 - val_accuracy: 0.9015\n",
            "Epoch 345/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2599 - accuracy: 0.8983 - val_loss: 0.2578 - val_accuracy: 0.9002\n",
            "Epoch 346/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2573 - accuracy: 0.9000 - val_loss: 0.2590 - val_accuracy: 0.8988\n",
            "Epoch 347/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2581 - accuracy: 0.9001 - val_loss: 0.2581 - val_accuracy: 0.8985\n",
            "Epoch 348/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2554 - accuracy: 0.9003 - val_loss: 0.2584 - val_accuracy: 0.8980\n",
            "Epoch 349/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2566 - accuracy: 0.8997 - val_loss: 0.2634 - val_accuracy: 0.8963\n",
            "Epoch 350/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2570 - accuracy: 0.9000 - val_loss: 0.2575 - val_accuracy: 0.9022\n",
            "Epoch 351/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2575 - accuracy: 0.8998 - val_loss: 0.2572 - val_accuracy: 0.9003\n",
            "Epoch 352/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2590 - accuracy: 0.8985 - val_loss: 0.2589 - val_accuracy: 0.8982\n",
            "Epoch 353/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2563 - accuracy: 0.8993 - val_loss: 0.2627 - val_accuracy: 0.8985\n",
            "Epoch 354/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2572 - accuracy: 0.8989 - val_loss: 0.2568 - val_accuracy: 0.9005\n",
            "Epoch 355/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2545 - accuracy: 0.9004 - val_loss: 0.2583 - val_accuracy: 0.9002\n",
            "Epoch 356/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2559 - accuracy: 0.8999 - val_loss: 0.2574 - val_accuracy: 0.9020\n",
            "Epoch 357/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2532 - accuracy: 0.9021 - val_loss: 0.2569 - val_accuracy: 0.8992\n",
            "Epoch 358/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2532 - accuracy: 0.9016 - val_loss: 0.2572 - val_accuracy: 0.9013\n",
            "Epoch 359/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2539 - accuracy: 0.8991 - val_loss: 0.2588 - val_accuracy: 0.9003\n",
            "Epoch 360/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2524 - accuracy: 0.9010 - val_loss: 0.2552 - val_accuracy: 0.9028\n",
            "Epoch 361/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2511 - accuracy: 0.9032 - val_loss: 0.2599 - val_accuracy: 0.8987\n",
            "Epoch 362/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2536 - accuracy: 0.9013 - val_loss: 0.2568 - val_accuracy: 0.9012\n",
            "Epoch 363/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2508 - accuracy: 0.9024 - val_loss: 0.2542 - val_accuracy: 0.9013\n",
            "Epoch 364/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2509 - accuracy: 0.9022 - val_loss: 0.2536 - val_accuracy: 0.9032\n",
            "Epoch 365/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2535 - accuracy: 0.9022 - val_loss: 0.2552 - val_accuracy: 0.9000\n",
            "Epoch 366/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2508 - accuracy: 0.9016 - val_loss: 0.2556 - val_accuracy: 0.8995\n",
            "Epoch 367/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2507 - accuracy: 0.9025 - val_loss: 0.2573 - val_accuracy: 0.9003\n",
            "Epoch 368/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2523 - accuracy: 0.9005 - val_loss: 0.2529 - val_accuracy: 0.9012\n",
            "Epoch 369/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2518 - accuracy: 0.9020 - val_loss: 0.2540 - val_accuracy: 0.9015\n",
            "Epoch 370/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2511 - accuracy: 0.9019 - val_loss: 0.2557 - val_accuracy: 0.9005\n",
            "Epoch 371/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2521 - accuracy: 0.9018 - val_loss: 0.2539 - val_accuracy: 0.9025\n",
            "Epoch 372/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2508 - accuracy: 0.9010 - val_loss: 0.2549 - val_accuracy: 0.9002\n",
            "Epoch 373/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2492 - accuracy: 0.9027 - val_loss: 0.2555 - val_accuracy: 0.8995\n",
            "Epoch 374/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2501 - accuracy: 0.9024 - val_loss: 0.2554 - val_accuracy: 0.8992\n",
            "Epoch 375/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2521 - accuracy: 0.9021 - val_loss: 0.2561 - val_accuracy: 0.9005\n",
            "Epoch 376/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2513 - accuracy: 0.9014 - val_loss: 0.2573 - val_accuracy: 0.8997\n",
            "Epoch 377/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2489 - accuracy: 0.9028 - val_loss: 0.2530 - val_accuracy: 0.9000\n",
            "Epoch 378/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2478 - accuracy: 0.9036 - val_loss: 0.2536 - val_accuracy: 0.9027\n",
            "Epoch 379/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2486 - accuracy: 0.9021 - val_loss: 0.2540 - val_accuracy: 0.8998\n",
            "Epoch 380/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2493 - accuracy: 0.9027 - val_loss: 0.2598 - val_accuracy: 0.8977\n",
            "Epoch 381/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2500 - accuracy: 0.9018 - val_loss: 0.2530 - val_accuracy: 0.9005\n",
            "Epoch 382/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2487 - accuracy: 0.9029 - val_loss: 0.2560 - val_accuracy: 0.9003\n",
            "Epoch 383/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2456 - accuracy: 0.9035 - val_loss: 0.2525 - val_accuracy: 0.9018\n",
            "Epoch 384/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2483 - accuracy: 0.9031 - val_loss: 0.2549 - val_accuracy: 0.9005\n",
            "Epoch 385/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2479 - accuracy: 0.9031 - val_loss: 0.2582 - val_accuracy: 0.8992\n",
            "Epoch 386/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2477 - accuracy: 0.9033 - val_loss: 0.2546 - val_accuracy: 0.9017\n",
            "Epoch 387/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2454 - accuracy: 0.9043 - val_loss: 0.2534 - val_accuracy: 0.9028\n",
            "Epoch 388/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2443 - accuracy: 0.9039 - val_loss: 0.2534 - val_accuracy: 0.9040\n",
            "Epoch 389/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2470 - accuracy: 0.9044 - val_loss: 0.2521 - val_accuracy: 0.9033\n",
            "Epoch 390/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2442 - accuracy: 0.9061 - val_loss: 0.2526 - val_accuracy: 0.9032\n",
            "Epoch 391/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2473 - accuracy: 0.9025 - val_loss: 0.2519 - val_accuracy: 0.9017\n",
            "Epoch 392/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2449 - accuracy: 0.9043 - val_loss: 0.2516 - val_accuracy: 0.9033\n",
            "Epoch 393/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2494 - accuracy: 0.9021 - val_loss: 0.2521 - val_accuracy: 0.9015\n",
            "Epoch 394/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2457 - accuracy: 0.9039 - val_loss: 0.2514 - val_accuracy: 0.9023\n",
            "Epoch 395/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2440 - accuracy: 0.9042 - val_loss: 0.2523 - val_accuracy: 0.9015\n",
            "Epoch 396/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2458 - accuracy: 0.9042 - val_loss: 0.2495 - val_accuracy: 0.9040\n",
            "Epoch 397/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2417 - accuracy: 0.9052 - val_loss: 0.2540 - val_accuracy: 0.8980\n",
            "Epoch 398/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2429 - accuracy: 0.9050 - val_loss: 0.2524 - val_accuracy: 0.9025\n",
            "Epoch 399/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2439 - accuracy: 0.9039 - val_loss: 0.2502 - val_accuracy: 0.9028\n",
            "Epoch 400/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2427 - accuracy: 0.9050 - val_loss: 0.2518 - val_accuracy: 0.9013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJJKYcCa2-yT",
        "colab_type": "code",
        "outputId": "fbb01bf0-0e32-46e6-d03f-9519e8cbe466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#tanh\n",
        "image_rows = 28\n",
        "image_cols = 28\n",
        "batch_size = 512\n",
        "image_shape = (image_rows,image_cols,1)\n",
        "cnn_modelta = Sequential([\n",
        "    Conv2D(filters=32,kernel_size=5,activation='tanh',padding='same',input_shape = image_shape),\n",
        "    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n",
        "    Conv2D(filters=64,kernel_size=3,activation='tanh',padding='same'),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Conv2D(filters=128,kernel_size=1,activation='tanh',padding='same'),\n",
        "    Dropout(0.2),\n",
        "    Flatten(), # 1flatten out the layers\n",
        "    Dense(1024,activation='tanh'),\n",
        "    Dropout(0.25),\n",
        "    Dense(32,activation='tanh'),\n",
        "    Dense(5,activation = 'softmax')\n",
        "])\n",
        "cnn_modelta.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0001),metrics =['accuracy'])\n",
        "history = cnn_modelta.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=1024,\n",
        "    epochs=400,\n",
        "    verbose=1,\n",
        "    validation_data=(X_test,y_test)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "53/53 [==============================] - 2s 38ms/step - loss: 1.0349 - accuracy: 0.5597 - val_loss: 0.8421 - val_accuracy: 0.6388\n",
            "Epoch 2/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.7701 - accuracy: 0.6791 - val_loss: 0.7075 - val_accuracy: 0.7050\n",
            "Epoch 3/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.6709 - accuracy: 0.7304 - val_loss: 0.6279 - val_accuracy: 0.7503\n",
            "Epoch 4/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.6081 - accuracy: 0.7626 - val_loss: 0.5817 - val_accuracy: 0.7722\n",
            "Epoch 5/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.5638 - accuracy: 0.7822 - val_loss: 0.5394 - val_accuracy: 0.7965\n",
            "Epoch 6/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.5347 - accuracy: 0.7949 - val_loss: 0.5126 - val_accuracy: 0.8040\n",
            "Epoch 7/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.5106 - accuracy: 0.8054 - val_loss: 0.4946 - val_accuracy: 0.8077\n",
            "Epoch 8/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.4924 - accuracy: 0.8119 - val_loss: 0.4761 - val_accuracy: 0.8153\n",
            "Epoch 9/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.4787 - accuracy: 0.8189 - val_loss: 0.4630 - val_accuracy: 0.8168\n",
            "Epoch 10/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.4670 - accuracy: 0.8221 - val_loss: 0.4511 - val_accuracy: 0.8262\n",
            "Epoch 11/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.4547 - accuracy: 0.8272 - val_loss: 0.4398 - val_accuracy: 0.8290\n",
            "Epoch 12/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.4407 - accuracy: 0.8361 - val_loss: 0.4316 - val_accuracy: 0.8360\n",
            "Epoch 13/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.4324 - accuracy: 0.8368 - val_loss: 0.4280 - val_accuracy: 0.8325\n",
            "Epoch 14/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.4289 - accuracy: 0.8370 - val_loss: 0.4182 - val_accuracy: 0.8385\n",
            "Epoch 15/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.4167 - accuracy: 0.8424 - val_loss: 0.4084 - val_accuracy: 0.8425\n",
            "Epoch 16/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.4080 - accuracy: 0.8461 - val_loss: 0.4048 - val_accuracy: 0.8433\n",
            "Epoch 17/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.4028 - accuracy: 0.8489 - val_loss: 0.4006 - val_accuracy: 0.8460\n",
            "Epoch 18/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.3959 - accuracy: 0.8519 - val_loss: 0.4013 - val_accuracy: 0.8415\n",
            "Epoch 19/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.3928 - accuracy: 0.8523 - val_loss: 0.3886 - val_accuracy: 0.8480\n",
            "Epoch 20/400\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.3872 - accuracy: 0.8535 - val_loss: 0.3826 - val_accuracy: 0.8482\n",
            "Epoch 21/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.3815 - accuracy: 0.8567 - val_loss: 0.3918 - val_accuracy: 0.8443\n",
            "Epoch 22/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.3762 - accuracy: 0.8591 - val_loss: 0.3738 - val_accuracy: 0.8575\n",
            "Epoch 23/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.3714 - accuracy: 0.8599 - val_loss: 0.3747 - val_accuracy: 0.8555\n",
            "Epoch 24/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3727 - accuracy: 0.8590 - val_loss: 0.3664 - val_accuracy: 0.8585\n",
            "Epoch 25/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3609 - accuracy: 0.8642 - val_loss: 0.3665 - val_accuracy: 0.8605\n",
            "Epoch 26/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3601 - accuracy: 0.8635 - val_loss: 0.3562 - val_accuracy: 0.8638\n",
            "Epoch 27/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3555 - accuracy: 0.8641 - val_loss: 0.3629 - val_accuracy: 0.8580\n",
            "Epoch 28/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3527 - accuracy: 0.8660 - val_loss: 0.3530 - val_accuracy: 0.8643\n",
            "Epoch 29/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3462 - accuracy: 0.8699 - val_loss: 0.3490 - val_accuracy: 0.8683\n",
            "Epoch 30/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3419 - accuracy: 0.8704 - val_loss: 0.3446 - val_accuracy: 0.8665\n",
            "Epoch 31/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3414 - accuracy: 0.8703 - val_loss: 0.3414 - val_accuracy: 0.8663\n",
            "Epoch 32/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3383 - accuracy: 0.8720 - val_loss: 0.3403 - val_accuracy: 0.8702\n",
            "Epoch 33/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3362 - accuracy: 0.8721 - val_loss: 0.3414 - val_accuracy: 0.8677\n",
            "Epoch 34/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3343 - accuracy: 0.8727 - val_loss: 0.3378 - val_accuracy: 0.8695\n",
            "Epoch 35/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3310 - accuracy: 0.8735 - val_loss: 0.3346 - val_accuracy: 0.8727\n",
            "Epoch 36/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3268 - accuracy: 0.8758 - val_loss: 0.3312 - val_accuracy: 0.8713\n",
            "Epoch 37/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3259 - accuracy: 0.8754 - val_loss: 0.3304 - val_accuracy: 0.8707\n",
            "Epoch 38/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3201 - accuracy: 0.8775 - val_loss: 0.3301 - val_accuracy: 0.8698\n",
            "Epoch 39/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3188 - accuracy: 0.8788 - val_loss: 0.3272 - val_accuracy: 0.8697\n",
            "Epoch 40/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3142 - accuracy: 0.8817 - val_loss: 0.3224 - val_accuracy: 0.8727\n",
            "Epoch 41/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3127 - accuracy: 0.8803 - val_loss: 0.3209 - val_accuracy: 0.8750\n",
            "Epoch 42/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3115 - accuracy: 0.8819 - val_loss: 0.3283 - val_accuracy: 0.8700\n",
            "Epoch 43/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3104 - accuracy: 0.8812 - val_loss: 0.3287 - val_accuracy: 0.8712\n",
            "Epoch 44/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3075 - accuracy: 0.8824 - val_loss: 0.3180 - val_accuracy: 0.8755\n",
            "Epoch 45/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3043 - accuracy: 0.8838 - val_loss: 0.3136 - val_accuracy: 0.8793\n",
            "Epoch 46/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3016 - accuracy: 0.8859 - val_loss: 0.3207 - val_accuracy: 0.8733\n",
            "Epoch 47/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3005 - accuracy: 0.8860 - val_loss: 0.3123 - val_accuracy: 0.8780\n",
            "Epoch 48/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2981 - accuracy: 0.8871 - val_loss: 0.3147 - val_accuracy: 0.8767\n",
            "Epoch 49/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2945 - accuracy: 0.8879 - val_loss: 0.3137 - val_accuracy: 0.8773\n",
            "Epoch 50/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2970 - accuracy: 0.8866 - val_loss: 0.3140 - val_accuracy: 0.8783\n",
            "Epoch 51/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2922 - accuracy: 0.8885 - val_loss: 0.3053 - val_accuracy: 0.8813\n",
            "Epoch 52/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2916 - accuracy: 0.8887 - val_loss: 0.3074 - val_accuracy: 0.8797\n",
            "Epoch 53/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2917 - accuracy: 0.8891 - val_loss: 0.3091 - val_accuracy: 0.8783\n",
            "Epoch 54/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2880 - accuracy: 0.8902 - val_loss: 0.3020 - val_accuracy: 0.8802\n",
            "Epoch 55/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2862 - accuracy: 0.8911 - val_loss: 0.3051 - val_accuracy: 0.8773\n",
            "Epoch 56/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2828 - accuracy: 0.8916 - val_loss: 0.3006 - val_accuracy: 0.8843\n",
            "Epoch 57/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.2832 - accuracy: 0.8916 - val_loss: 0.3100 - val_accuracy: 0.8777\n",
            "Epoch 58/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.2836 - accuracy: 0.8916 - val_loss: 0.3002 - val_accuracy: 0.8843\n",
            "Epoch 59/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2780 - accuracy: 0.8942 - val_loss: 0.3069 - val_accuracy: 0.8795\n",
            "Epoch 60/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2779 - accuracy: 0.8946 - val_loss: 0.2959 - val_accuracy: 0.8830\n",
            "Epoch 61/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2751 - accuracy: 0.8953 - val_loss: 0.2953 - val_accuracy: 0.8873\n",
            "Epoch 62/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.2709 - accuracy: 0.8971 - val_loss: 0.2926 - val_accuracy: 0.8850\n",
            "Epoch 63/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.2732 - accuracy: 0.8950 - val_loss: 0.2945 - val_accuracy: 0.8850\n",
            "Epoch 64/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2693 - accuracy: 0.8970 - val_loss: 0.2902 - val_accuracy: 0.8888\n",
            "Epoch 65/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2675 - accuracy: 0.8986 - val_loss: 0.2929 - val_accuracy: 0.8842\n",
            "Epoch 66/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2693 - accuracy: 0.8975 - val_loss: 0.2940 - val_accuracy: 0.8847\n",
            "Epoch 67/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2652 - accuracy: 0.8976 - val_loss: 0.2868 - val_accuracy: 0.8888\n",
            "Epoch 68/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2656 - accuracy: 0.8981 - val_loss: 0.2894 - val_accuracy: 0.8862\n",
            "Epoch 69/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2650 - accuracy: 0.8980 - val_loss: 0.2905 - val_accuracy: 0.8900\n",
            "Epoch 70/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2678 - accuracy: 0.8979 - val_loss: 0.2830 - val_accuracy: 0.8920\n",
            "Epoch 71/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2622 - accuracy: 0.8998 - val_loss: 0.2891 - val_accuracy: 0.8882\n",
            "Epoch 72/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2575 - accuracy: 0.9011 - val_loss: 0.2923 - val_accuracy: 0.8847\n",
            "Epoch 73/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2584 - accuracy: 0.9018 - val_loss: 0.2881 - val_accuracy: 0.8912\n",
            "Epoch 74/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2568 - accuracy: 0.9023 - val_loss: 0.2858 - val_accuracy: 0.8885\n",
            "Epoch 75/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2546 - accuracy: 0.9029 - val_loss: 0.2807 - val_accuracy: 0.8912\n",
            "Epoch 76/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2530 - accuracy: 0.9026 - val_loss: 0.2814 - val_accuracy: 0.8928\n",
            "Epoch 77/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2518 - accuracy: 0.9048 - val_loss: 0.2798 - val_accuracy: 0.8937\n",
            "Epoch 78/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2510 - accuracy: 0.9041 - val_loss: 0.2814 - val_accuracy: 0.8912\n",
            "Epoch 79/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2500 - accuracy: 0.9057 - val_loss: 0.2838 - val_accuracy: 0.8878\n",
            "Epoch 80/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2490 - accuracy: 0.9034 - val_loss: 0.2783 - val_accuracy: 0.8925\n",
            "Epoch 81/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2479 - accuracy: 0.9063 - val_loss: 0.2794 - val_accuracy: 0.8927\n",
            "Epoch 82/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2482 - accuracy: 0.9042 - val_loss: 0.2820 - val_accuracy: 0.8898\n",
            "Epoch 83/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2477 - accuracy: 0.9046 - val_loss: 0.2790 - val_accuracy: 0.8908\n",
            "Epoch 84/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2429 - accuracy: 0.9070 - val_loss: 0.2913 - val_accuracy: 0.8853\n",
            "Epoch 85/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2467 - accuracy: 0.9062 - val_loss: 0.2758 - val_accuracy: 0.8950\n",
            "Epoch 86/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2391 - accuracy: 0.9088 - val_loss: 0.2818 - val_accuracy: 0.8917\n",
            "Epoch 87/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2422 - accuracy: 0.9073 - val_loss: 0.2787 - val_accuracy: 0.8945\n",
            "Epoch 88/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2385 - accuracy: 0.9084 - val_loss: 0.2765 - val_accuracy: 0.8930\n",
            "Epoch 89/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2377 - accuracy: 0.9092 - val_loss: 0.2779 - val_accuracy: 0.8910\n",
            "Epoch 90/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2413 - accuracy: 0.9081 - val_loss: 0.3105 - val_accuracy: 0.8770\n",
            "Epoch 91/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2383 - accuracy: 0.9082 - val_loss: 0.2781 - val_accuracy: 0.8917\n",
            "Epoch 92/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2340 - accuracy: 0.9108 - val_loss: 0.2755 - val_accuracy: 0.8933\n",
            "Epoch 93/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2325 - accuracy: 0.9116 - val_loss: 0.2742 - val_accuracy: 0.8927\n",
            "Epoch 94/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2305 - accuracy: 0.9127 - val_loss: 0.2728 - val_accuracy: 0.8928\n",
            "Epoch 95/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2281 - accuracy: 0.9130 - val_loss: 0.2731 - val_accuracy: 0.8968\n",
            "Epoch 96/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2290 - accuracy: 0.9133 - val_loss: 0.2696 - val_accuracy: 0.8947\n",
            "Epoch 97/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2293 - accuracy: 0.9123 - val_loss: 0.2771 - val_accuracy: 0.8923\n",
            "Epoch 98/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2300 - accuracy: 0.9118 - val_loss: 0.2743 - val_accuracy: 0.8922\n",
            "Epoch 99/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2281 - accuracy: 0.9131 - val_loss: 0.2711 - val_accuracy: 0.8952\n",
            "Epoch 100/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2266 - accuracy: 0.9148 - val_loss: 0.2708 - val_accuracy: 0.8960\n",
            "Epoch 101/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2236 - accuracy: 0.9151 - val_loss: 0.2666 - val_accuracy: 0.9000\n",
            "Epoch 102/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2273 - accuracy: 0.9124 - val_loss: 0.2725 - val_accuracy: 0.8923\n",
            "Epoch 103/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2288 - accuracy: 0.9116 - val_loss: 0.2707 - val_accuracy: 0.8918\n",
            "Epoch 104/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2218 - accuracy: 0.9159 - val_loss: 0.2678 - val_accuracy: 0.8945\n",
            "Epoch 105/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2210 - accuracy: 0.9171 - val_loss: 0.2679 - val_accuracy: 0.8962\n",
            "Epoch 106/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2179 - accuracy: 0.9159 - val_loss: 0.2654 - val_accuracy: 0.8965\n",
            "Epoch 107/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2212 - accuracy: 0.9165 - val_loss: 0.2653 - val_accuracy: 0.8960\n",
            "Epoch 108/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2175 - accuracy: 0.9190 - val_loss: 0.2657 - val_accuracy: 0.8982\n",
            "Epoch 109/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2168 - accuracy: 0.9181 - val_loss: 0.2647 - val_accuracy: 0.8962\n",
            "Epoch 110/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2147 - accuracy: 0.9185 - val_loss: 0.2665 - val_accuracy: 0.8980\n",
            "Epoch 111/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2166 - accuracy: 0.9177 - val_loss: 0.2676 - val_accuracy: 0.8957\n",
            "Epoch 112/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2135 - accuracy: 0.9195 - val_loss: 0.2715 - val_accuracy: 0.8912\n",
            "Epoch 113/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2121 - accuracy: 0.9187 - val_loss: 0.2648 - val_accuracy: 0.8965\n",
            "Epoch 114/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2111 - accuracy: 0.9209 - val_loss: 0.2649 - val_accuracy: 0.8942\n",
            "Epoch 115/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2095 - accuracy: 0.9200 - val_loss: 0.2695 - val_accuracy: 0.8958\n",
            "Epoch 116/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2102 - accuracy: 0.9195 - val_loss: 0.2634 - val_accuracy: 0.8977\n",
            "Epoch 117/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2104 - accuracy: 0.9200 - val_loss: 0.2768 - val_accuracy: 0.8922\n",
            "Epoch 118/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2080 - accuracy: 0.9211 - val_loss: 0.2692 - val_accuracy: 0.8938\n",
            "Epoch 119/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2100 - accuracy: 0.9207 - val_loss: 0.2710 - val_accuracy: 0.8953\n",
            "Epoch 120/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2051 - accuracy: 0.9240 - val_loss: 0.2683 - val_accuracy: 0.8982\n",
            "Epoch 121/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2046 - accuracy: 0.9216 - val_loss: 0.2676 - val_accuracy: 0.8983\n",
            "Epoch 122/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2083 - accuracy: 0.9204 - val_loss: 0.2606 - val_accuracy: 0.8990\n",
            "Epoch 123/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2055 - accuracy: 0.9222 - val_loss: 0.2642 - val_accuracy: 0.8970\n",
            "Epoch 124/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2017 - accuracy: 0.9236 - val_loss: 0.2620 - val_accuracy: 0.8995\n",
            "Epoch 125/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2026 - accuracy: 0.9230 - val_loss: 0.2600 - val_accuracy: 0.8985\n",
            "Epoch 126/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2051 - accuracy: 0.9220 - val_loss: 0.2667 - val_accuracy: 0.8950\n",
            "Epoch 127/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1989 - accuracy: 0.9245 - val_loss: 0.2617 - val_accuracy: 0.8973\n",
            "Epoch 128/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2004 - accuracy: 0.9228 - val_loss: 0.2607 - val_accuracy: 0.8978\n",
            "Epoch 129/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2009 - accuracy: 0.9240 - val_loss: 0.2627 - val_accuracy: 0.8965\n",
            "Epoch 130/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1982 - accuracy: 0.9257 - val_loss: 0.2715 - val_accuracy: 0.8927\n",
            "Epoch 131/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1974 - accuracy: 0.9247 - val_loss: 0.2598 - val_accuracy: 0.8987\n",
            "Epoch 132/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1946 - accuracy: 0.9254 - val_loss: 0.2574 - val_accuracy: 0.8998\n",
            "Epoch 133/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1948 - accuracy: 0.9256 - val_loss: 0.2616 - val_accuracy: 0.8970\n",
            "Epoch 134/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1961 - accuracy: 0.9248 - val_loss: 0.2599 - val_accuracy: 0.9003\n",
            "Epoch 135/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1943 - accuracy: 0.9270 - val_loss: 0.2598 - val_accuracy: 0.8983\n",
            "Epoch 136/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1922 - accuracy: 0.9278 - val_loss: 0.2573 - val_accuracy: 0.8978\n",
            "Epoch 137/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1926 - accuracy: 0.9269 - val_loss: 0.2575 - val_accuracy: 0.8983\n",
            "Epoch 138/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1922 - accuracy: 0.9272 - val_loss: 0.2594 - val_accuracy: 0.8985\n",
            "Epoch 139/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1895 - accuracy: 0.9277 - val_loss: 0.2584 - val_accuracy: 0.8970\n",
            "Epoch 140/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1888 - accuracy: 0.9282 - val_loss: 0.2572 - val_accuracy: 0.9007\n",
            "Epoch 141/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1850 - accuracy: 0.9309 - val_loss: 0.2582 - val_accuracy: 0.9000\n",
            "Epoch 142/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1881 - accuracy: 0.9286 - val_loss: 0.2588 - val_accuracy: 0.8990\n",
            "Epoch 143/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1850 - accuracy: 0.9304 - val_loss: 0.2562 - val_accuracy: 0.8988\n",
            "Epoch 144/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1846 - accuracy: 0.9310 - val_loss: 0.2602 - val_accuracy: 0.8977\n",
            "Epoch 145/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1862 - accuracy: 0.9295 - val_loss: 0.2660 - val_accuracy: 0.8962\n",
            "Epoch 146/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1824 - accuracy: 0.9315 - val_loss: 0.2603 - val_accuracy: 0.8990\n",
            "Epoch 147/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1874 - accuracy: 0.9287 - val_loss: 0.2581 - val_accuracy: 0.8997\n",
            "Epoch 148/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1855 - accuracy: 0.9285 - val_loss: 0.2679 - val_accuracy: 0.8957\n",
            "Epoch 149/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1808 - accuracy: 0.9314 - val_loss: 0.2543 - val_accuracy: 0.8992\n",
            "Epoch 150/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1801 - accuracy: 0.9320 - val_loss: 0.2604 - val_accuracy: 0.8978\n",
            "Epoch 151/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1781 - accuracy: 0.9329 - val_loss: 0.2564 - val_accuracy: 0.8985\n",
            "Epoch 152/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1800 - accuracy: 0.9314 - val_loss: 0.2629 - val_accuracy: 0.8942\n",
            "Epoch 153/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1784 - accuracy: 0.9325 - val_loss: 0.2543 - val_accuracy: 0.9017\n",
            "Epoch 154/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1788 - accuracy: 0.9326 - val_loss: 0.2519 - val_accuracy: 0.9003\n",
            "Epoch 155/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1776 - accuracy: 0.9333 - val_loss: 0.2728 - val_accuracy: 0.8920\n",
            "Epoch 156/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1835 - accuracy: 0.9299 - val_loss: 0.2669 - val_accuracy: 0.8955\n",
            "Epoch 157/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1770 - accuracy: 0.9329 - val_loss: 0.2614 - val_accuracy: 0.8947\n",
            "Epoch 158/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1735 - accuracy: 0.9346 - val_loss: 0.2562 - val_accuracy: 0.9003\n",
            "Epoch 159/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1739 - accuracy: 0.9347 - val_loss: 0.2552 - val_accuracy: 0.9027\n",
            "Epoch 160/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1738 - accuracy: 0.9346 - val_loss: 0.2538 - val_accuracy: 0.8983\n",
            "Epoch 161/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1734 - accuracy: 0.9351 - val_loss: 0.2595 - val_accuracy: 0.8977\n",
            "Epoch 162/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1694 - accuracy: 0.9354 - val_loss: 0.2555 - val_accuracy: 0.9002\n",
            "Epoch 163/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1718 - accuracy: 0.9346 - val_loss: 0.2549 - val_accuracy: 0.9008\n",
            "Epoch 164/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1709 - accuracy: 0.9364 - val_loss: 0.2606 - val_accuracy: 0.8950\n",
            "Epoch 165/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1721 - accuracy: 0.9345 - val_loss: 0.2540 - val_accuracy: 0.9005\n",
            "Epoch 166/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1718 - accuracy: 0.9349 - val_loss: 0.2651 - val_accuracy: 0.8975\n",
            "Epoch 167/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1701 - accuracy: 0.9353 - val_loss: 0.2547 - val_accuracy: 0.9025\n",
            "Epoch 168/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1679 - accuracy: 0.9366 - val_loss: 0.2616 - val_accuracy: 0.9000\n",
            "Epoch 169/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1675 - accuracy: 0.9364 - val_loss: 0.2553 - val_accuracy: 0.8993\n",
            "Epoch 170/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1655 - accuracy: 0.9381 - val_loss: 0.2571 - val_accuracy: 0.9002\n",
            "Epoch 171/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1655 - accuracy: 0.9383 - val_loss: 0.2535 - val_accuracy: 0.8998\n",
            "Epoch 172/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1670 - accuracy: 0.9369 - val_loss: 0.2531 - val_accuracy: 0.9012\n",
            "Epoch 173/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1656 - accuracy: 0.9377 - val_loss: 0.2536 - val_accuracy: 0.9012\n",
            "Epoch 174/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1639 - accuracy: 0.9376 - val_loss: 0.2591 - val_accuracy: 0.9007\n",
            "Epoch 175/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1696 - accuracy: 0.9349 - val_loss: 0.2660 - val_accuracy: 0.8968\n",
            "Epoch 176/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1693 - accuracy: 0.9359 - val_loss: 0.2562 - val_accuracy: 0.9012\n",
            "Epoch 177/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1623 - accuracy: 0.9380 - val_loss: 0.2559 - val_accuracy: 0.9022\n",
            "Epoch 178/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1608 - accuracy: 0.9397 - val_loss: 0.2617 - val_accuracy: 0.8980\n",
            "Epoch 179/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1628 - accuracy: 0.9389 - val_loss: 0.2581 - val_accuracy: 0.9005\n",
            "Epoch 180/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1580 - accuracy: 0.9416 - val_loss: 0.2600 - val_accuracy: 0.8982\n",
            "Epoch 181/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1598 - accuracy: 0.9396 - val_loss: 0.2628 - val_accuracy: 0.8977\n",
            "Epoch 182/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1579 - accuracy: 0.9402 - val_loss: 0.2517 - val_accuracy: 0.9017\n",
            "Epoch 183/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1577 - accuracy: 0.9406 - val_loss: 0.2527 - val_accuracy: 0.9033\n",
            "Epoch 184/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1569 - accuracy: 0.9410 - val_loss: 0.2499 - val_accuracy: 0.9030\n",
            "Epoch 185/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1592 - accuracy: 0.9393 - val_loss: 0.2539 - val_accuracy: 0.9018\n",
            "Epoch 186/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1567 - accuracy: 0.9412 - val_loss: 0.2573 - val_accuracy: 0.9007\n",
            "Epoch 187/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1577 - accuracy: 0.9408 - val_loss: 0.2627 - val_accuracy: 0.8953\n",
            "Epoch 188/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1558 - accuracy: 0.9408 - val_loss: 0.2600 - val_accuracy: 0.8990\n",
            "Epoch 189/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1534 - accuracy: 0.9439 - val_loss: 0.2524 - val_accuracy: 0.9027\n",
            "Epoch 190/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1534 - accuracy: 0.9414 - val_loss: 0.2570 - val_accuracy: 0.8985\n",
            "Epoch 191/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1541 - accuracy: 0.9424 - val_loss: 0.2619 - val_accuracy: 0.9002\n",
            "Epoch 192/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1538 - accuracy: 0.9429 - val_loss: 0.2546 - val_accuracy: 0.9017\n",
            "Epoch 193/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1533 - accuracy: 0.9424 - val_loss: 0.2658 - val_accuracy: 0.8995\n",
            "Epoch 194/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1503 - accuracy: 0.9443 - val_loss: 0.2547 - val_accuracy: 0.9023\n",
            "Epoch 195/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1503 - accuracy: 0.9439 - val_loss: 0.2519 - val_accuracy: 0.9040\n",
            "Epoch 196/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1477 - accuracy: 0.9445 - val_loss: 0.2553 - val_accuracy: 0.9038\n",
            "Epoch 197/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1472 - accuracy: 0.9449 - val_loss: 0.2539 - val_accuracy: 0.9015\n",
            "Epoch 198/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1491 - accuracy: 0.9441 - val_loss: 0.2493 - val_accuracy: 0.9063\n",
            "Epoch 199/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1479 - accuracy: 0.9451 - val_loss: 0.2552 - val_accuracy: 0.9032\n",
            "Epoch 200/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1458 - accuracy: 0.9447 - val_loss: 0.2496 - val_accuracy: 0.9043\n",
            "Epoch 201/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1472 - accuracy: 0.9449 - val_loss: 0.2510 - val_accuracy: 0.9017\n",
            "Epoch 202/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1472 - accuracy: 0.9448 - val_loss: 0.2545 - val_accuracy: 0.9002\n",
            "Epoch 203/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1453 - accuracy: 0.9452 - val_loss: 0.2514 - val_accuracy: 0.9055\n",
            "Epoch 204/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1439 - accuracy: 0.9454 - val_loss: 0.2496 - val_accuracy: 0.9038\n",
            "Epoch 205/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1439 - accuracy: 0.9467 - val_loss: 0.2544 - val_accuracy: 0.9030\n",
            "Epoch 206/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1532 - accuracy: 0.9423 - val_loss: 0.2583 - val_accuracy: 0.9010\n",
            "Epoch 207/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1460 - accuracy: 0.9450 - val_loss: 0.2524 - val_accuracy: 0.9053\n",
            "Epoch 208/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1408 - accuracy: 0.9479 - val_loss: 0.2558 - val_accuracy: 0.9018\n",
            "Epoch 209/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1386 - accuracy: 0.9487 - val_loss: 0.2491 - val_accuracy: 0.9025\n",
            "Epoch 210/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1414 - accuracy: 0.9481 - val_loss: 0.2744 - val_accuracy: 0.8977\n",
            "Epoch 211/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1416 - accuracy: 0.9473 - val_loss: 0.2502 - val_accuracy: 0.9040\n",
            "Epoch 212/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1400 - accuracy: 0.9483 - val_loss: 0.2557 - val_accuracy: 0.9045\n",
            "Epoch 213/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1404 - accuracy: 0.9469 - val_loss: 0.2557 - val_accuracy: 0.9027\n",
            "Epoch 214/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1405 - accuracy: 0.9472 - val_loss: 0.2487 - val_accuracy: 0.9053\n",
            "Epoch 215/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1406 - accuracy: 0.9477 - val_loss: 0.2577 - val_accuracy: 0.9002\n",
            "Epoch 216/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1376 - accuracy: 0.9488 - val_loss: 0.2522 - val_accuracy: 0.9018\n",
            "Epoch 217/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1369 - accuracy: 0.9488 - val_loss: 0.2850 - val_accuracy: 0.8930\n",
            "Epoch 218/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1398 - accuracy: 0.9477 - val_loss: 0.2540 - val_accuracy: 0.9027\n",
            "Epoch 219/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1344 - accuracy: 0.9500 - val_loss: 0.2543 - val_accuracy: 0.9028\n",
            "Epoch 220/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1328 - accuracy: 0.9511 - val_loss: 0.2520 - val_accuracy: 0.9035\n",
            "Epoch 221/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1361 - accuracy: 0.9495 - val_loss: 0.2619 - val_accuracy: 0.8985\n",
            "Epoch 222/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1347 - accuracy: 0.9499 - val_loss: 0.2601 - val_accuracy: 0.8997\n",
            "Epoch 223/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1348 - accuracy: 0.9496 - val_loss: 0.2577 - val_accuracy: 0.9013\n",
            "Epoch 224/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1329 - accuracy: 0.9499 - val_loss: 0.2558 - val_accuracy: 0.9027\n",
            "Epoch 225/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1292 - accuracy: 0.9520 - val_loss: 0.2564 - val_accuracy: 0.9047\n",
            "Epoch 226/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1297 - accuracy: 0.9528 - val_loss: 0.2538 - val_accuracy: 0.9038\n",
            "Epoch 227/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1330 - accuracy: 0.9498 - val_loss: 0.2555 - val_accuracy: 0.9030\n",
            "Epoch 228/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1294 - accuracy: 0.9515 - val_loss: 0.2562 - val_accuracy: 0.9013\n",
            "Epoch 229/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1296 - accuracy: 0.9513 - val_loss: 0.2532 - val_accuracy: 0.9025\n",
            "Epoch 230/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1305 - accuracy: 0.9518 - val_loss: 0.2582 - val_accuracy: 0.9022\n",
            "Epoch 231/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1331 - accuracy: 0.9495 - val_loss: 0.2660 - val_accuracy: 0.8972\n",
            "Epoch 232/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1293 - accuracy: 0.9527 - val_loss: 0.2554 - val_accuracy: 0.9023\n",
            "Epoch 233/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1294 - accuracy: 0.9519 - val_loss: 0.2526 - val_accuracy: 0.9058\n",
            "Epoch 234/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1286 - accuracy: 0.9527 - val_loss: 0.2569 - val_accuracy: 0.9040\n",
            "Epoch 235/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1289 - accuracy: 0.9532 - val_loss: 0.2545 - val_accuracy: 0.9028\n",
            "Epoch 236/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1251 - accuracy: 0.9534 - val_loss: 0.2594 - val_accuracy: 0.9040\n",
            "Epoch 237/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1250 - accuracy: 0.9546 - val_loss: 0.2564 - val_accuracy: 0.9010\n",
            "Epoch 238/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1258 - accuracy: 0.9536 - val_loss: 0.2553 - val_accuracy: 0.9022\n",
            "Epoch 239/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1239 - accuracy: 0.9545 - val_loss: 0.2599 - val_accuracy: 0.9003\n",
            "Epoch 240/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1246 - accuracy: 0.9535 - val_loss: 0.2549 - val_accuracy: 0.9027\n",
            "Epoch 241/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1258 - accuracy: 0.9533 - val_loss: 0.2537 - val_accuracy: 0.9018\n",
            "Epoch 242/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1212 - accuracy: 0.9561 - val_loss: 0.2549 - val_accuracy: 0.9012\n",
            "Epoch 243/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1227 - accuracy: 0.9554 - val_loss: 0.2571 - val_accuracy: 0.9027\n",
            "Epoch 244/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1224 - accuracy: 0.9546 - val_loss: 0.2554 - val_accuracy: 0.9028\n",
            "Epoch 245/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1219 - accuracy: 0.9555 - val_loss: 0.2613 - val_accuracy: 0.8997\n",
            "Epoch 246/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1233 - accuracy: 0.9543 - val_loss: 0.2599 - val_accuracy: 0.9012\n",
            "Epoch 247/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1191 - accuracy: 0.9567 - val_loss: 0.2619 - val_accuracy: 0.8982\n",
            "Epoch 248/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1235 - accuracy: 0.9544 - val_loss: 0.2726 - val_accuracy: 0.8962\n",
            "Epoch 249/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1214 - accuracy: 0.9562 - val_loss: 0.2573 - val_accuracy: 0.9022\n",
            "Epoch 250/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1195 - accuracy: 0.9559 - val_loss: 0.2603 - val_accuracy: 0.9030\n",
            "Epoch 251/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1172 - accuracy: 0.9574 - val_loss: 0.2566 - val_accuracy: 0.9043\n",
            "Epoch 252/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1164 - accuracy: 0.9581 - val_loss: 0.2580 - val_accuracy: 0.9017\n",
            "Epoch 253/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1199 - accuracy: 0.9560 - val_loss: 0.2575 - val_accuracy: 0.9013\n",
            "Epoch 254/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1183 - accuracy: 0.9566 - val_loss: 0.2587 - val_accuracy: 0.9023\n",
            "Epoch 255/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1169 - accuracy: 0.9570 - val_loss: 0.2621 - val_accuracy: 0.9012\n",
            "Epoch 256/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1157 - accuracy: 0.9581 - val_loss: 0.2591 - val_accuracy: 0.9027\n",
            "Epoch 257/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1165 - accuracy: 0.9573 - val_loss: 0.2593 - val_accuracy: 0.9027\n",
            "Epoch 258/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1151 - accuracy: 0.9586 - val_loss: 0.2622 - val_accuracy: 0.9007\n",
            "Epoch 259/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1142 - accuracy: 0.9578 - val_loss: 0.2584 - val_accuracy: 0.9008\n",
            "Epoch 260/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1142 - accuracy: 0.9582 - val_loss: 0.2566 - val_accuracy: 0.9045\n",
            "Epoch 261/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1149 - accuracy: 0.9583 - val_loss: 0.2599 - val_accuracy: 0.9023\n",
            "Epoch 262/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1119 - accuracy: 0.9591 - val_loss: 0.2603 - val_accuracy: 0.9013\n",
            "Epoch 263/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1167 - accuracy: 0.9569 - val_loss: 0.2606 - val_accuracy: 0.9037\n",
            "Epoch 264/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1170 - accuracy: 0.9568 - val_loss: 0.2615 - val_accuracy: 0.9047\n",
            "Epoch 265/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1147 - accuracy: 0.9573 - val_loss: 0.2618 - val_accuracy: 0.9028\n",
            "Epoch 266/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1119 - accuracy: 0.9596 - val_loss: 0.2627 - val_accuracy: 0.9012\n",
            "Epoch 267/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1111 - accuracy: 0.9595 - val_loss: 0.2578 - val_accuracy: 0.9043\n",
            "Epoch 268/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1102 - accuracy: 0.9598 - val_loss: 0.2588 - val_accuracy: 0.9043\n",
            "Epoch 269/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1114 - accuracy: 0.9597 - val_loss: 0.2639 - val_accuracy: 0.9015\n",
            "Epoch 270/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1125 - accuracy: 0.9590 - val_loss: 0.2600 - val_accuracy: 0.9020\n",
            "Epoch 271/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1087 - accuracy: 0.9609 - val_loss: 0.2614 - val_accuracy: 0.9018\n",
            "Epoch 272/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1095 - accuracy: 0.9600 - val_loss: 0.2639 - val_accuracy: 0.9025\n",
            "Epoch 273/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1076 - accuracy: 0.9612 - val_loss: 0.2702 - val_accuracy: 0.8997\n",
            "Epoch 274/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1081 - accuracy: 0.9607 - val_loss: 0.2609 - val_accuracy: 0.9025\n",
            "Epoch 275/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1066 - accuracy: 0.9619 - val_loss: 0.2639 - val_accuracy: 0.9020\n",
            "Epoch 276/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1073 - accuracy: 0.9615 - val_loss: 0.2648 - val_accuracy: 0.9027\n",
            "Epoch 277/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1101 - accuracy: 0.9595 - val_loss: 0.2616 - val_accuracy: 0.9018\n",
            "Epoch 278/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1055 - accuracy: 0.9619 - val_loss: 0.2600 - val_accuracy: 0.9018\n",
            "Epoch 279/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1069 - accuracy: 0.9612 - val_loss: 0.2603 - val_accuracy: 0.9025\n",
            "Epoch 280/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1051 - accuracy: 0.9613 - val_loss: 0.2618 - val_accuracy: 0.9042\n",
            "Epoch 281/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1032 - accuracy: 0.9622 - val_loss: 0.2612 - val_accuracy: 0.9047\n",
            "Epoch 282/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1042 - accuracy: 0.9619 - val_loss: 0.2690 - val_accuracy: 0.9027\n",
            "Epoch 283/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1049 - accuracy: 0.9614 - val_loss: 0.2610 - val_accuracy: 0.9037\n",
            "Epoch 284/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1007 - accuracy: 0.9644 - val_loss: 0.2631 - val_accuracy: 0.9013\n",
            "Epoch 285/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1020 - accuracy: 0.9633 - val_loss: 0.2644 - val_accuracy: 0.9022\n",
            "Epoch 286/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1024 - accuracy: 0.9625 - val_loss: 0.2632 - val_accuracy: 0.9013\n",
            "Epoch 287/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1039 - accuracy: 0.9623 - val_loss: 0.2639 - val_accuracy: 0.9035\n",
            "Epoch 288/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1028 - accuracy: 0.9616 - val_loss: 0.2656 - val_accuracy: 0.9008\n",
            "Epoch 289/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0992 - accuracy: 0.9644 - val_loss: 0.2715 - val_accuracy: 0.9007\n",
            "Epoch 290/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1019 - accuracy: 0.9632 - val_loss: 0.2648 - val_accuracy: 0.9048\n",
            "Epoch 291/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1010 - accuracy: 0.9634 - val_loss: 0.2681 - val_accuracy: 0.9037\n",
            "Epoch 292/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0996 - accuracy: 0.9650 - val_loss: 0.2632 - val_accuracy: 0.9043\n",
            "Epoch 293/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0981 - accuracy: 0.9650 - val_loss: 0.2695 - val_accuracy: 0.9035\n",
            "Epoch 294/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0983 - accuracy: 0.9645 - val_loss: 0.2682 - val_accuracy: 0.9023\n",
            "Epoch 295/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0990 - accuracy: 0.9647 - val_loss: 0.2643 - val_accuracy: 0.9030\n",
            "Epoch 296/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0964 - accuracy: 0.9655 - val_loss: 0.2672 - val_accuracy: 0.9028\n",
            "Epoch 297/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0968 - accuracy: 0.9654 - val_loss: 0.2668 - val_accuracy: 0.9032\n",
            "Epoch 298/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0953 - accuracy: 0.9663 - val_loss: 0.2657 - val_accuracy: 0.9010\n",
            "Epoch 299/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0973 - accuracy: 0.9653 - val_loss: 0.2717 - val_accuracy: 0.9010\n",
            "Epoch 300/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0960 - accuracy: 0.9659 - val_loss: 0.2662 - val_accuracy: 0.9043\n",
            "Epoch 301/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0959 - accuracy: 0.9652 - val_loss: 0.2674 - val_accuracy: 0.9022\n",
            "Epoch 302/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0964 - accuracy: 0.9652 - val_loss: 0.2688 - val_accuracy: 0.9020\n",
            "Epoch 303/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0964 - accuracy: 0.9647 - val_loss: 0.2746 - val_accuracy: 0.8990\n",
            "Epoch 304/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0962 - accuracy: 0.9656 - val_loss: 0.2692 - val_accuracy: 0.9018\n",
            "Epoch 305/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0945 - accuracy: 0.9661 - val_loss: 0.2688 - val_accuracy: 0.9017\n",
            "Epoch 306/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0948 - accuracy: 0.9662 - val_loss: 0.2725 - val_accuracy: 0.9030\n",
            "Epoch 307/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0934 - accuracy: 0.9675 - val_loss: 0.2738 - val_accuracy: 0.9018\n",
            "Epoch 308/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0926 - accuracy: 0.9670 - val_loss: 0.2696 - val_accuracy: 0.9023\n",
            "Epoch 309/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0947 - accuracy: 0.9666 - val_loss: 0.2752 - val_accuracy: 0.8997\n",
            "Epoch 310/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0952 - accuracy: 0.9651 - val_loss: 0.2684 - val_accuracy: 0.9038\n",
            "Epoch 311/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0927 - accuracy: 0.9663 - val_loss: 0.2773 - val_accuracy: 0.9000\n",
            "Epoch 312/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0912 - accuracy: 0.9681 - val_loss: 0.2717 - val_accuracy: 0.9028\n",
            "Epoch 313/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0900 - accuracy: 0.9688 - val_loss: 0.2686 - val_accuracy: 0.9033\n",
            "Epoch 314/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0902 - accuracy: 0.9683 - val_loss: 0.2737 - val_accuracy: 0.9015\n",
            "Epoch 315/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0903 - accuracy: 0.9677 - val_loss: 0.2725 - val_accuracy: 0.9020\n",
            "Epoch 316/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0886 - accuracy: 0.9690 - val_loss: 0.2679 - val_accuracy: 0.9018\n",
            "Epoch 317/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0874 - accuracy: 0.9693 - val_loss: 0.2737 - val_accuracy: 0.9007\n",
            "Epoch 318/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0869 - accuracy: 0.9690 - val_loss: 0.2763 - val_accuracy: 0.9025\n",
            "Epoch 319/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0879 - accuracy: 0.9696 - val_loss: 0.2794 - val_accuracy: 0.9005\n",
            "Epoch 320/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0866 - accuracy: 0.9695 - val_loss: 0.2757 - val_accuracy: 0.9002\n",
            "Epoch 321/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0879 - accuracy: 0.9691 - val_loss: 0.2710 - val_accuracy: 0.9032\n",
            "Epoch 322/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0885 - accuracy: 0.9692 - val_loss: 0.2723 - val_accuracy: 0.9020\n",
            "Epoch 323/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0879 - accuracy: 0.9694 - val_loss: 0.2784 - val_accuracy: 0.9013\n",
            "Epoch 324/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0878 - accuracy: 0.9685 - val_loss: 0.2751 - val_accuracy: 0.9027\n",
            "Epoch 325/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0872 - accuracy: 0.9693 - val_loss: 0.2782 - val_accuracy: 0.8998\n",
            "Epoch 326/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0868 - accuracy: 0.9695 - val_loss: 0.2713 - val_accuracy: 0.9032\n",
            "Epoch 327/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0886 - accuracy: 0.9684 - val_loss: 0.2737 - val_accuracy: 0.9023\n",
            "Epoch 328/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0867 - accuracy: 0.9688 - val_loss: 0.2739 - val_accuracy: 0.9010\n",
            "Epoch 329/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0841 - accuracy: 0.9706 - val_loss: 0.2718 - val_accuracy: 0.9038\n",
            "Epoch 330/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0850 - accuracy: 0.9700 - val_loss: 0.2751 - val_accuracy: 0.9022\n",
            "Epoch 331/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0835 - accuracy: 0.9711 - val_loss: 0.2768 - val_accuracy: 0.9007\n",
            "Epoch 332/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0823 - accuracy: 0.9714 - val_loss: 0.2790 - val_accuracy: 0.9010\n",
            "Epoch 333/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0837 - accuracy: 0.9709 - val_loss: 0.2776 - val_accuracy: 0.9028\n",
            "Epoch 334/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0850 - accuracy: 0.9700 - val_loss: 0.2731 - val_accuracy: 0.9020\n",
            "Epoch 335/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0822 - accuracy: 0.9710 - val_loss: 0.2755 - val_accuracy: 0.9053\n",
            "Epoch 336/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0820 - accuracy: 0.9711 - val_loss: 0.2754 - val_accuracy: 0.9050\n",
            "Epoch 337/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0830 - accuracy: 0.9702 - val_loss: 0.2909 - val_accuracy: 0.8995\n",
            "Epoch 338/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0845 - accuracy: 0.9703 - val_loss: 0.2724 - val_accuracy: 0.9042\n",
            "Epoch 339/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0821 - accuracy: 0.9709 - val_loss: 0.2716 - val_accuracy: 0.9050\n",
            "Epoch 340/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0843 - accuracy: 0.9697 - val_loss: 0.2782 - val_accuracy: 0.9033\n",
            "Epoch 341/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0832 - accuracy: 0.9708 - val_loss: 0.2956 - val_accuracy: 0.8975\n",
            "Epoch 342/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0815 - accuracy: 0.9713 - val_loss: 0.2779 - val_accuracy: 0.9033\n",
            "Epoch 343/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0795 - accuracy: 0.9729 - val_loss: 0.2785 - val_accuracy: 0.9013\n",
            "Epoch 344/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0784 - accuracy: 0.9731 - val_loss: 0.2752 - val_accuracy: 0.9025\n",
            "Epoch 345/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0777 - accuracy: 0.9733 - val_loss: 0.2779 - val_accuracy: 0.9023\n",
            "Epoch 346/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0781 - accuracy: 0.9735 - val_loss: 0.2780 - val_accuracy: 0.9038\n",
            "Epoch 347/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0802 - accuracy: 0.9722 - val_loss: 0.2832 - val_accuracy: 0.9008\n",
            "Epoch 348/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0782 - accuracy: 0.9729 - val_loss: 0.2775 - val_accuracy: 0.9020\n",
            "Epoch 349/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0769 - accuracy: 0.9733 - val_loss: 0.2760 - val_accuracy: 0.9047\n",
            "Epoch 350/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0800 - accuracy: 0.9724 - val_loss: 0.2822 - val_accuracy: 0.9003\n",
            "Epoch 351/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0766 - accuracy: 0.9735 - val_loss: 0.2842 - val_accuracy: 0.9033\n",
            "Epoch 352/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0767 - accuracy: 0.9731 - val_loss: 0.2784 - val_accuracy: 0.9022\n",
            "Epoch 353/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0758 - accuracy: 0.9737 - val_loss: 0.2798 - val_accuracy: 0.9015\n",
            "Epoch 354/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0784 - accuracy: 0.9727 - val_loss: 0.2849 - val_accuracy: 0.8977\n",
            "Epoch 355/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0768 - accuracy: 0.9729 - val_loss: 0.2947 - val_accuracy: 0.8970\n",
            "Epoch 356/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0761 - accuracy: 0.9732 - val_loss: 0.2856 - val_accuracy: 0.8982\n",
            "Epoch 357/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0757 - accuracy: 0.9738 - val_loss: 0.2775 - val_accuracy: 0.9022\n",
            "Epoch 358/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0755 - accuracy: 0.9731 - val_loss: 0.2843 - val_accuracy: 0.9008\n",
            "Epoch 359/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0737 - accuracy: 0.9750 - val_loss: 0.2805 - val_accuracy: 0.9033\n",
            "Epoch 360/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0751 - accuracy: 0.9737 - val_loss: 0.2797 - val_accuracy: 0.9053\n",
            "Epoch 361/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0715 - accuracy: 0.9759 - val_loss: 0.2839 - val_accuracy: 0.9028\n",
            "Epoch 362/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0745 - accuracy: 0.9743 - val_loss: 0.2811 - val_accuracy: 0.9048\n",
            "Epoch 363/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0753 - accuracy: 0.9737 - val_loss: 0.2824 - val_accuracy: 0.9045\n",
            "Epoch 364/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0715 - accuracy: 0.9761 - val_loss: 0.2840 - val_accuracy: 0.9022\n",
            "Epoch 365/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0732 - accuracy: 0.9745 - val_loss: 0.2812 - val_accuracy: 0.9030\n",
            "Epoch 366/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0717 - accuracy: 0.9757 - val_loss: 0.2847 - val_accuracy: 0.9053\n",
            "Epoch 367/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0725 - accuracy: 0.9749 - val_loss: 0.2850 - val_accuracy: 0.9033\n",
            "Epoch 368/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0722 - accuracy: 0.9753 - val_loss: 0.2843 - val_accuracy: 0.9027\n",
            "Epoch 369/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0718 - accuracy: 0.9758 - val_loss: 0.2820 - val_accuracy: 0.9035\n",
            "Epoch 370/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0702 - accuracy: 0.9764 - val_loss: 0.2815 - val_accuracy: 0.9047\n",
            "Epoch 371/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0694 - accuracy: 0.9759 - val_loss: 0.2967 - val_accuracy: 0.8995\n",
            "Epoch 372/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0726 - accuracy: 0.9752 - val_loss: 0.2987 - val_accuracy: 0.8973\n",
            "Epoch 373/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0712 - accuracy: 0.9756 - val_loss: 0.2856 - val_accuracy: 0.9067\n",
            "Epoch 374/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0717 - accuracy: 0.9754 - val_loss: 0.2860 - val_accuracy: 0.9035\n",
            "Epoch 375/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0728 - accuracy: 0.9747 - val_loss: 0.2831 - val_accuracy: 0.9048\n",
            "Epoch 376/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0678 - accuracy: 0.9771 - val_loss: 0.2906 - val_accuracy: 0.9005\n",
            "Epoch 377/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0702 - accuracy: 0.9759 - val_loss: 0.2855 - val_accuracy: 0.9038\n",
            "Epoch 378/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0676 - accuracy: 0.9774 - val_loss: 0.2851 - val_accuracy: 0.9037\n",
            "Epoch 379/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0683 - accuracy: 0.9770 - val_loss: 0.2930 - val_accuracy: 0.8988\n",
            "Epoch 380/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0694 - accuracy: 0.9765 - val_loss: 0.2870 - val_accuracy: 0.9015\n",
            "Epoch 381/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0672 - accuracy: 0.9766 - val_loss: 0.2871 - val_accuracy: 0.9030\n",
            "Epoch 382/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0670 - accuracy: 0.9775 - val_loss: 0.2871 - val_accuracy: 0.9047\n",
            "Epoch 383/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0671 - accuracy: 0.9770 - val_loss: 0.2871 - val_accuracy: 0.9042\n",
            "Epoch 384/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0668 - accuracy: 0.9775 - val_loss: 0.2940 - val_accuracy: 0.9048\n",
            "Epoch 385/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0677 - accuracy: 0.9769 - val_loss: 0.2878 - val_accuracy: 0.9028\n",
            "Epoch 386/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0652 - accuracy: 0.9779 - val_loss: 0.2841 - val_accuracy: 0.9050\n",
            "Epoch 387/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0663 - accuracy: 0.9779 - val_loss: 0.2913 - val_accuracy: 0.9022\n",
            "Epoch 388/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0644 - accuracy: 0.9785 - val_loss: 0.2900 - val_accuracy: 0.9010\n",
            "Epoch 389/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0644 - accuracy: 0.9781 - val_loss: 0.2888 - val_accuracy: 0.9007\n",
            "Epoch 390/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0669 - accuracy: 0.9774 - val_loss: 0.2875 - val_accuracy: 0.9025\n",
            "Epoch 391/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0667 - accuracy: 0.9768 - val_loss: 0.2987 - val_accuracy: 0.8990\n",
            "Epoch 392/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0648 - accuracy: 0.9774 - val_loss: 0.2895 - val_accuracy: 0.9015\n",
            "Epoch 393/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0640 - accuracy: 0.9786 - val_loss: 0.2907 - val_accuracy: 0.9047\n",
            "Epoch 394/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0654 - accuracy: 0.9781 - val_loss: 0.2930 - val_accuracy: 0.9020\n",
            "Epoch 395/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0646 - accuracy: 0.9782 - val_loss: 0.2904 - val_accuracy: 0.9022\n",
            "Epoch 396/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0650 - accuracy: 0.9773 - val_loss: 0.2922 - val_accuracy: 0.9035\n",
            "Epoch 397/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0628 - accuracy: 0.9792 - val_loss: 0.3048 - val_accuracy: 0.8988\n",
            "Epoch 398/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0664 - accuracy: 0.9770 - val_loss: 0.2884 - val_accuracy: 0.9040\n",
            "Epoch 399/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0634 - accuracy: 0.9794 - val_loss: 0.2917 - val_accuracy: 0.9035\n",
            "Epoch 400/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0630 - accuracy: 0.9780 - val_loss: 0.2928 - val_accuracy: 0.9023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JnRxenV4a9G",
        "colab_type": "code",
        "outputId": "fb12e6d0-76cf-48ad-b790-0de46c4c310d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# sgd\n",
        "image_rows = 28\n",
        "image_cols = 28\n",
        "batch_size = 512\n",
        "image_shape = (image_rows,image_cols,1)\n",
        "cnn_modelsg = Sequential([\n",
        "    Conv2D(filters=32,kernel_size=5,activation='relu',padding='same',input_shape = image_shape),\n",
        "    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n",
        "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same'),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Conv2D(filters=128,kernel_size=1,activation='relu',padding='same'),\n",
        "    Dropout(0.2),\n",
        "    Flatten(), # 1flatten out the layers\n",
        "    Dense(1024,activation='relu'),\n",
        "    Dropout(0.25),\n",
        "    Dense(32,activation='relu'),\n",
        "    Dense(5,activation = 'softmax')\n",
        "])\n",
        "cnn_modelsg.compile(loss ='sparse_categorical_crossentropy', optimizer=SGD(),metrics =['accuracy'])\n",
        "history = cnn_modelsg.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=1024,\n",
        "    epochs=400,\n",
        "    verbose=1,\n",
        "    validation_data=(X_test,y_test)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 1.5890 - accuracy: 0.2207 - val_loss: 1.5680 - val_accuracy: 0.2235\n",
            "Epoch 2/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.5455 - accuracy: 0.2746 - val_loss: 1.4999 - val_accuracy: 0.3555\n",
            "Epoch 3/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.4537 - accuracy: 0.3846 - val_loss: 1.3573 - val_accuracy: 0.4788\n",
            "Epoch 4/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.2958 - accuracy: 0.4666 - val_loss: 1.1751 - val_accuracy: 0.5123\n",
            "Epoch 5/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.1498 - accuracy: 0.5086 - val_loss: 1.0580 - val_accuracy: 0.5360\n",
            "Epoch 6/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 1.0435 - accuracy: 0.5500 - val_loss: 0.9536 - val_accuracy: 0.5835\n",
            "Epoch 7/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.9563 - accuracy: 0.5840 - val_loss: 0.8760 - val_accuracy: 0.6205\n",
            "Epoch 8/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.9082 - accuracy: 0.6054 - val_loss: 0.8438 - val_accuracy: 0.6372\n",
            "Epoch 9/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.8740 - accuracy: 0.6169 - val_loss: 0.8365 - val_accuracy: 0.6360\n",
            "Epoch 10/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.8575 - accuracy: 0.6249 - val_loss: 0.7811 - val_accuracy: 0.6662\n",
            "Epoch 11/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.8323 - accuracy: 0.6359 - val_loss: 0.7833 - val_accuracy: 0.6595\n",
            "Epoch 12/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.8031 - accuracy: 0.6510 - val_loss: 0.7492 - val_accuracy: 0.6797\n",
            "Epoch 13/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.7962 - accuracy: 0.6556 - val_loss: 0.7262 - val_accuracy: 0.6868\n",
            "Epoch 14/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.7831 - accuracy: 0.6641 - val_loss: 0.7229 - val_accuracy: 0.6913\n",
            "Epoch 15/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.7696 - accuracy: 0.6714 - val_loss: 0.7174 - val_accuracy: 0.6968\n",
            "Epoch 16/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.7540 - accuracy: 0.6784 - val_loss: 0.7046 - val_accuracy: 0.7028\n",
            "Epoch 17/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.7332 - accuracy: 0.6887 - val_loss: 0.6942 - val_accuracy: 0.7088\n",
            "Epoch 18/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.7215 - accuracy: 0.6932 - val_loss: 0.6706 - val_accuracy: 0.7165\n",
            "Epoch 19/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.7175 - accuracy: 0.6967 - val_loss: 0.7507 - val_accuracy: 0.6830\n",
            "Epoch 20/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.7123 - accuracy: 0.6997 - val_loss: 0.6402 - val_accuracy: 0.7415\n",
            "Epoch 21/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.7039 - accuracy: 0.7049 - val_loss: 0.6754 - val_accuracy: 0.7260\n",
            "Epoch 22/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.6832 - accuracy: 0.7165 - val_loss: 0.6334 - val_accuracy: 0.7427\n",
            "Epoch 23/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.6819 - accuracy: 0.7166 - val_loss: 0.6055 - val_accuracy: 0.7545\n",
            "Epoch 24/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6697 - accuracy: 0.7197 - val_loss: 0.6145 - val_accuracy: 0.7527\n",
            "Epoch 25/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6761 - accuracy: 0.7190 - val_loss: 0.6643 - val_accuracy: 0.7323\n",
            "Epoch 26/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6584 - accuracy: 0.7262 - val_loss: 0.5835 - val_accuracy: 0.7648\n",
            "Epoch 27/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6556 - accuracy: 0.7301 - val_loss: 0.6110 - val_accuracy: 0.7565\n",
            "Epoch 28/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6403 - accuracy: 0.7363 - val_loss: 0.6365 - val_accuracy: 0.7360\n",
            "Epoch 29/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6433 - accuracy: 0.7332 - val_loss: 0.6311 - val_accuracy: 0.7402\n",
            "Epoch 30/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6245 - accuracy: 0.7430 - val_loss: 0.5569 - val_accuracy: 0.7755\n",
            "Epoch 31/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6337 - accuracy: 0.7367 - val_loss: 0.6306 - val_accuracy: 0.7430\n",
            "Epoch 32/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6210 - accuracy: 0.7460 - val_loss: 0.5771 - val_accuracy: 0.7720\n",
            "Epoch 33/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6120 - accuracy: 0.7478 - val_loss: 0.5813 - val_accuracy: 0.7627\n",
            "Epoch 34/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6003 - accuracy: 0.7542 - val_loss: 0.5651 - val_accuracy: 0.7718\n",
            "Epoch 35/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.6067 - accuracy: 0.7520 - val_loss: 0.5745 - val_accuracy: 0.7693\n",
            "Epoch 36/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5975 - accuracy: 0.7549 - val_loss: 0.5305 - val_accuracy: 0.7885\n",
            "Epoch 37/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5911 - accuracy: 0.7592 - val_loss: 0.6009 - val_accuracy: 0.7565\n",
            "Epoch 38/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5885 - accuracy: 0.7584 - val_loss: 0.5775 - val_accuracy: 0.7602\n",
            "Epoch 39/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5813 - accuracy: 0.7608 - val_loss: 0.5505 - val_accuracy: 0.7762\n",
            "Epoch 40/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5730 - accuracy: 0.7654 - val_loss: 0.5130 - val_accuracy: 0.7985\n",
            "Epoch 41/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5824 - accuracy: 0.7630 - val_loss: 0.5442 - val_accuracy: 0.7835\n",
            "Epoch 42/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5711 - accuracy: 0.7666 - val_loss: 0.5587 - val_accuracy: 0.7682\n",
            "Epoch 43/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5641 - accuracy: 0.7697 - val_loss: 0.5416 - val_accuracy: 0.7787\n",
            "Epoch 44/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5605 - accuracy: 0.7717 - val_loss: 0.4957 - val_accuracy: 0.8100\n",
            "Epoch 45/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5489 - accuracy: 0.7785 - val_loss: 0.4981 - val_accuracy: 0.8053\n",
            "Epoch 46/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5592 - accuracy: 0.7739 - val_loss: 0.5853 - val_accuracy: 0.7545\n",
            "Epoch 47/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5533 - accuracy: 0.7742 - val_loss: 0.4958 - val_accuracy: 0.8082\n",
            "Epoch 48/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5436 - accuracy: 0.7802 - val_loss: 0.4773 - val_accuracy: 0.8138\n",
            "Epoch 49/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5409 - accuracy: 0.7810 - val_loss: 0.5025 - val_accuracy: 0.8005\n",
            "Epoch 50/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5394 - accuracy: 0.7808 - val_loss: 0.4741 - val_accuracy: 0.8163\n",
            "Epoch 51/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5431 - accuracy: 0.7798 - val_loss: 0.4758 - val_accuracy: 0.8140\n",
            "Epoch 52/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5280 - accuracy: 0.7876 - val_loss: 0.4823 - val_accuracy: 0.8103\n",
            "Epoch 53/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5396 - accuracy: 0.7818 - val_loss: 0.4677 - val_accuracy: 0.8207\n",
            "Epoch 54/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5188 - accuracy: 0.7920 - val_loss: 0.4794 - val_accuracy: 0.8132\n",
            "Epoch 55/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5247 - accuracy: 0.7881 - val_loss: 0.4648 - val_accuracy: 0.8192\n",
            "Epoch 56/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5248 - accuracy: 0.7878 - val_loss: 0.5471 - val_accuracy: 0.7747\n",
            "Epoch 57/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5126 - accuracy: 0.7956 - val_loss: 0.4608 - val_accuracy: 0.8188\n",
            "Epoch 58/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5194 - accuracy: 0.7914 - val_loss: 0.4991 - val_accuracy: 0.7965\n",
            "Epoch 59/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.5044 - accuracy: 0.7984 - val_loss: 0.5003 - val_accuracy: 0.7982\n",
            "Epoch 60/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5055 - accuracy: 0.7978 - val_loss: 0.4567 - val_accuracy: 0.8207\n",
            "Epoch 61/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5073 - accuracy: 0.7950 - val_loss: 0.4411 - val_accuracy: 0.8315\n",
            "Epoch 62/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5012 - accuracy: 0.7994 - val_loss: 0.4506 - val_accuracy: 0.8247\n",
            "Epoch 63/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4983 - accuracy: 0.8023 - val_loss: 0.4345 - val_accuracy: 0.8327\n",
            "Epoch 64/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5036 - accuracy: 0.7990 - val_loss: 0.4529 - val_accuracy: 0.8203\n",
            "Epoch 65/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4872 - accuracy: 0.8072 - val_loss: 0.4363 - val_accuracy: 0.8305\n",
            "Epoch 66/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.5004 - accuracy: 0.7994 - val_loss: 0.4473 - val_accuracy: 0.8235\n",
            "Epoch 67/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4832 - accuracy: 0.8067 - val_loss: 0.4312 - val_accuracy: 0.8325\n",
            "Epoch 68/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4870 - accuracy: 0.8064 - val_loss: 0.4591 - val_accuracy: 0.8153\n",
            "Epoch 69/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4953 - accuracy: 0.7996 - val_loss: 0.4433 - val_accuracy: 0.8233\n",
            "Epoch 70/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.4797 - accuracy: 0.8085 - val_loss: 0.4214 - val_accuracy: 0.8370\n",
            "Epoch 71/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4769 - accuracy: 0.8090 - val_loss: 0.4207 - val_accuracy: 0.8355\n",
            "Epoch 72/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.4905 - accuracy: 0.8044 - val_loss: 0.4285 - val_accuracy: 0.8300\n",
            "Epoch 73/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4735 - accuracy: 0.8111 - val_loss: 0.4163 - val_accuracy: 0.8368\n",
            "Epoch 74/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4807 - accuracy: 0.8058 - val_loss: 0.4183 - val_accuracy: 0.8357\n",
            "Epoch 75/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4700 - accuracy: 0.8135 - val_loss: 0.4312 - val_accuracy: 0.8288\n",
            "Epoch 76/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4798 - accuracy: 0.8066 - val_loss: 0.4134 - val_accuracy: 0.8403\n",
            "Epoch 77/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4633 - accuracy: 0.8166 - val_loss: 0.4100 - val_accuracy: 0.8392\n",
            "Epoch 78/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4654 - accuracy: 0.8142 - val_loss: 0.4661 - val_accuracy: 0.8070\n",
            "Epoch 79/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4722 - accuracy: 0.8113 - val_loss: 0.4105 - val_accuracy: 0.8373\n",
            "Epoch 80/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4593 - accuracy: 0.8184 - val_loss: 0.4235 - val_accuracy: 0.8268\n",
            "Epoch 81/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4666 - accuracy: 0.8134 - val_loss: 0.4208 - val_accuracy: 0.8328\n",
            "Epoch 82/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4622 - accuracy: 0.8168 - val_loss: 0.4065 - val_accuracy: 0.8407\n",
            "Epoch 83/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4594 - accuracy: 0.8163 - val_loss: 0.4019 - val_accuracy: 0.8423\n",
            "Epoch 84/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4527 - accuracy: 0.8195 - val_loss: 0.3993 - val_accuracy: 0.8435\n",
            "Epoch 85/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4559 - accuracy: 0.8196 - val_loss: 0.3954 - val_accuracy: 0.8453\n",
            "Epoch 86/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4483 - accuracy: 0.8207 - val_loss: 0.4609 - val_accuracy: 0.8083\n",
            "Epoch 87/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4550 - accuracy: 0.8186 - val_loss: 0.3946 - val_accuracy: 0.8407\n",
            "Epoch 88/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4407 - accuracy: 0.8255 - val_loss: 0.3937 - val_accuracy: 0.8452\n",
            "Epoch 89/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4576 - accuracy: 0.8153 - val_loss: 0.3925 - val_accuracy: 0.8458\n",
            "Epoch 90/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4418 - accuracy: 0.8234 - val_loss: 0.4156 - val_accuracy: 0.8330\n",
            "Epoch 91/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4426 - accuracy: 0.8235 - val_loss: 0.3952 - val_accuracy: 0.8438\n",
            "Epoch 92/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4380 - accuracy: 0.8270 - val_loss: 0.3909 - val_accuracy: 0.8440\n",
            "Epoch 93/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4504 - accuracy: 0.8217 - val_loss: 0.4874 - val_accuracy: 0.7940\n",
            "Epoch 94/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4443 - accuracy: 0.8230 - val_loss: 0.3856 - val_accuracy: 0.8517\n",
            "Epoch 95/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4498 - accuracy: 0.8196 - val_loss: 0.4275 - val_accuracy: 0.8233\n",
            "Epoch 96/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4363 - accuracy: 0.8260 - val_loss: 0.3825 - val_accuracy: 0.8488\n",
            "Epoch 97/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4441 - accuracy: 0.8210 - val_loss: 0.3823 - val_accuracy: 0.8487\n",
            "Epoch 98/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4260 - accuracy: 0.8314 - val_loss: 0.4253 - val_accuracy: 0.8272\n",
            "Epoch 99/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4385 - accuracy: 0.8243 - val_loss: 0.3853 - val_accuracy: 0.8487\n",
            "Epoch 100/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4326 - accuracy: 0.8280 - val_loss: 0.3833 - val_accuracy: 0.8480\n",
            "Epoch 101/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4290 - accuracy: 0.8292 - val_loss: 0.4453 - val_accuracy: 0.8158\n",
            "Epoch 102/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4301 - accuracy: 0.8289 - val_loss: 0.4219 - val_accuracy: 0.8280\n",
            "Epoch 103/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4299 - accuracy: 0.8281 - val_loss: 0.4074 - val_accuracy: 0.8310\n",
            "Epoch 104/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4331 - accuracy: 0.8272 - val_loss: 0.4225 - val_accuracy: 0.8275\n",
            "Epoch 105/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4356 - accuracy: 0.8260 - val_loss: 0.3927 - val_accuracy: 0.8385\n",
            "Epoch 106/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4145 - accuracy: 0.8360 - val_loss: 0.3840 - val_accuracy: 0.8432\n",
            "Epoch 107/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4223 - accuracy: 0.8335 - val_loss: 0.3729 - val_accuracy: 0.8543\n",
            "Epoch 108/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4197 - accuracy: 0.8320 - val_loss: 0.3673 - val_accuracy: 0.8568\n",
            "Epoch 109/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4215 - accuracy: 0.8318 - val_loss: 0.4172 - val_accuracy: 0.8267\n",
            "Epoch 110/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4252 - accuracy: 0.8300 - val_loss: 0.3811 - val_accuracy: 0.8467\n",
            "Epoch 111/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4061 - accuracy: 0.8388 - val_loss: 0.3646 - val_accuracy: 0.8605\n",
            "Epoch 112/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4235 - accuracy: 0.8310 - val_loss: 0.3934 - val_accuracy: 0.8355\n",
            "Epoch 113/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4175 - accuracy: 0.8327 - val_loss: 0.3660 - val_accuracy: 0.8567\n",
            "Epoch 114/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4105 - accuracy: 0.8372 - val_loss: 0.4004 - val_accuracy: 0.8338\n",
            "Epoch 115/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4201 - accuracy: 0.8313 - val_loss: 0.3731 - val_accuracy: 0.8503\n",
            "Epoch 116/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4133 - accuracy: 0.8350 - val_loss: 0.3753 - val_accuracy: 0.8500\n",
            "Epoch 117/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4055 - accuracy: 0.8399 - val_loss: 0.3727 - val_accuracy: 0.8487\n",
            "Epoch 118/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4169 - accuracy: 0.8326 - val_loss: 0.3580 - val_accuracy: 0.8620\n",
            "Epoch 119/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4082 - accuracy: 0.8378 - val_loss: 0.3625 - val_accuracy: 0.8557\n",
            "Epoch 120/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4066 - accuracy: 0.8378 - val_loss: 0.3719 - val_accuracy: 0.8473\n",
            "Epoch 121/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4026 - accuracy: 0.8383 - val_loss: 0.3795 - val_accuracy: 0.8437\n",
            "Epoch 122/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4046 - accuracy: 0.8388 - val_loss: 0.3708 - val_accuracy: 0.8503\n",
            "Epoch 123/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4050 - accuracy: 0.8396 - val_loss: 0.5500 - val_accuracy: 0.7708\n",
            "Epoch 124/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4097 - accuracy: 0.8371 - val_loss: 0.3520 - val_accuracy: 0.8652\n",
            "Epoch 125/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4131 - accuracy: 0.8354 - val_loss: 0.3538 - val_accuracy: 0.8645\n",
            "Epoch 126/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4046 - accuracy: 0.8378 - val_loss: 0.3510 - val_accuracy: 0.8633\n",
            "Epoch 127/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3974 - accuracy: 0.8408 - val_loss: 0.3507 - val_accuracy: 0.8638\n",
            "Epoch 128/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3890 - accuracy: 0.8460 - val_loss: 0.3484 - val_accuracy: 0.8665\n",
            "Epoch 129/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3987 - accuracy: 0.8415 - val_loss: 0.3803 - val_accuracy: 0.8432\n",
            "Epoch 130/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3985 - accuracy: 0.8420 - val_loss: 0.3484 - val_accuracy: 0.8638\n",
            "Epoch 131/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4044 - accuracy: 0.8363 - val_loss: 0.3514 - val_accuracy: 0.8640\n",
            "Epoch 132/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3991 - accuracy: 0.8393 - val_loss: 0.3489 - val_accuracy: 0.8652\n",
            "Epoch 133/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3917 - accuracy: 0.8431 - val_loss: 0.3519 - val_accuracy: 0.8633\n",
            "Epoch 134/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4033 - accuracy: 0.8388 - val_loss: 0.4104 - val_accuracy: 0.8282\n",
            "Epoch 135/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3949 - accuracy: 0.8416 - val_loss: 0.3859 - val_accuracy: 0.8410\n",
            "Epoch 136/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3937 - accuracy: 0.8434 - val_loss: 0.3473 - val_accuracy: 0.8640\n",
            "Epoch 137/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4014 - accuracy: 0.8383 - val_loss: 0.3799 - val_accuracy: 0.8427\n",
            "Epoch 138/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3875 - accuracy: 0.8456 - val_loss: 0.3943 - val_accuracy: 0.8352\n",
            "Epoch 139/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3966 - accuracy: 0.8409 - val_loss: 0.3421 - val_accuracy: 0.8655\n",
            "Epoch 140/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3837 - accuracy: 0.8467 - val_loss: 0.3413 - val_accuracy: 0.8685\n",
            "Epoch 141/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3898 - accuracy: 0.8452 - val_loss: 0.3458 - val_accuracy: 0.8625\n",
            "Epoch 142/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3890 - accuracy: 0.8451 - val_loss: 0.3495 - val_accuracy: 0.8593\n",
            "Epoch 143/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3732 - accuracy: 0.8521 - val_loss: 0.3904 - val_accuracy: 0.8377\n",
            "Epoch 144/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3957 - accuracy: 0.8402 - val_loss: 0.3925 - val_accuracy: 0.8335\n",
            "Epoch 145/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3843 - accuracy: 0.8483 - val_loss: 0.4241 - val_accuracy: 0.8202\n",
            "Epoch 146/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3912 - accuracy: 0.8435 - val_loss: 0.3671 - val_accuracy: 0.8528\n",
            "Epoch 147/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3791 - accuracy: 0.8495 - val_loss: 0.3630 - val_accuracy: 0.8535\n",
            "Epoch 148/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3851 - accuracy: 0.8460 - val_loss: 0.3410 - val_accuracy: 0.8672\n",
            "Epoch 149/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3766 - accuracy: 0.8511 - val_loss: 0.3386 - val_accuracy: 0.8647\n",
            "Epoch 150/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3746 - accuracy: 0.8505 - val_loss: 0.3355 - val_accuracy: 0.8688\n",
            "Epoch 151/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3829 - accuracy: 0.8465 - val_loss: 0.3370 - val_accuracy: 0.8680\n",
            "Epoch 152/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3856 - accuracy: 0.8453 - val_loss: 0.3516 - val_accuracy: 0.8572\n",
            "Epoch 153/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3916 - accuracy: 0.8423 - val_loss: 0.3402 - val_accuracy: 0.8655\n",
            "Epoch 154/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3729 - accuracy: 0.8518 - val_loss: 0.3476 - val_accuracy: 0.8603\n",
            "Epoch 155/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3811 - accuracy: 0.8478 - val_loss: 0.3783 - val_accuracy: 0.8420\n",
            "Epoch 156/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3733 - accuracy: 0.8519 - val_loss: 0.3294 - val_accuracy: 0.8723\n",
            "Epoch 157/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3743 - accuracy: 0.8511 - val_loss: 0.3451 - val_accuracy: 0.8608\n",
            "Epoch 158/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3776 - accuracy: 0.8493 - val_loss: 0.3379 - val_accuracy: 0.8657\n",
            "Epoch 159/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3655 - accuracy: 0.8545 - val_loss: 0.3296 - val_accuracy: 0.8710\n",
            "Epoch 160/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3714 - accuracy: 0.8519 - val_loss: 0.4459 - val_accuracy: 0.8128\n",
            "Epoch 161/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3803 - accuracy: 0.8481 - val_loss: 0.3505 - val_accuracy: 0.8597\n",
            "Epoch 162/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3673 - accuracy: 0.8525 - val_loss: 0.3352 - val_accuracy: 0.8682\n",
            "Epoch 163/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3728 - accuracy: 0.8509 - val_loss: 0.3296 - val_accuracy: 0.8670\n",
            "Epoch 164/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3639 - accuracy: 0.8557 - val_loss: 0.3244 - val_accuracy: 0.8752\n",
            "Epoch 165/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3757 - accuracy: 0.8488 - val_loss: 0.3621 - val_accuracy: 0.8497\n",
            "Epoch 166/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3682 - accuracy: 0.8531 - val_loss: 0.3283 - val_accuracy: 0.8685\n",
            "Epoch 167/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3601 - accuracy: 0.8561 - val_loss: 0.3244 - val_accuracy: 0.8732\n",
            "Epoch 168/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3735 - accuracy: 0.8506 - val_loss: 0.3260 - val_accuracy: 0.8690\n",
            "Epoch 169/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3702 - accuracy: 0.8521 - val_loss: 0.4180 - val_accuracy: 0.8235\n",
            "Epoch 170/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3643 - accuracy: 0.8555 - val_loss: 0.3343 - val_accuracy: 0.8675\n",
            "Epoch 171/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3706 - accuracy: 0.8493 - val_loss: 0.3346 - val_accuracy: 0.8638\n",
            "Epoch 172/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3650 - accuracy: 0.8539 - val_loss: 0.3431 - val_accuracy: 0.8603\n",
            "Epoch 173/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3702 - accuracy: 0.8509 - val_loss: 0.3613 - val_accuracy: 0.8512\n",
            "Epoch 174/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3619 - accuracy: 0.8545 - val_loss: 0.3218 - val_accuracy: 0.8758\n",
            "Epoch 175/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3624 - accuracy: 0.8548 - val_loss: 0.3651 - val_accuracy: 0.8492\n",
            "Epoch 176/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3537 - accuracy: 0.8594 - val_loss: 0.3263 - val_accuracy: 0.8702\n",
            "Epoch 177/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3746 - accuracy: 0.8479 - val_loss: 0.3218 - val_accuracy: 0.8743\n",
            "Epoch 178/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3678 - accuracy: 0.8521 - val_loss: 0.3231 - val_accuracy: 0.8747\n",
            "Epoch 179/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3490 - accuracy: 0.8618 - val_loss: 0.3174 - val_accuracy: 0.8782\n",
            "Epoch 180/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3672 - accuracy: 0.8520 - val_loss: 0.3172 - val_accuracy: 0.8742\n",
            "Epoch 181/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3634 - accuracy: 0.8551 - val_loss: 0.3211 - val_accuracy: 0.8717\n",
            "Epoch 182/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3587 - accuracy: 0.8565 - val_loss: 0.3288 - val_accuracy: 0.8655\n",
            "Epoch 183/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3561 - accuracy: 0.8576 - val_loss: 0.3816 - val_accuracy: 0.8422\n",
            "Epoch 184/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3573 - accuracy: 0.8575 - val_loss: 0.3477 - val_accuracy: 0.8558\n",
            "Epoch 185/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3535 - accuracy: 0.8564 - val_loss: 0.3174 - val_accuracy: 0.8762\n",
            "Epoch 186/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3571 - accuracy: 0.8563 - val_loss: 0.3360 - val_accuracy: 0.8652\n",
            "Epoch 187/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3644 - accuracy: 0.8538 - val_loss: 0.3383 - val_accuracy: 0.8655\n",
            "Epoch 188/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3430 - accuracy: 0.8621 - val_loss: 0.3133 - val_accuracy: 0.8755\n",
            "Epoch 189/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3614 - accuracy: 0.8535 - val_loss: 0.3133 - val_accuracy: 0.8795\n",
            "Epoch 190/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3471 - accuracy: 0.8631 - val_loss: 0.3105 - val_accuracy: 0.8797\n",
            "Epoch 191/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3579 - accuracy: 0.8560 - val_loss: 0.3140 - val_accuracy: 0.8792\n",
            "Epoch 192/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3472 - accuracy: 0.8619 - val_loss: 0.3385 - val_accuracy: 0.8607\n",
            "Epoch 193/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3477 - accuracy: 0.8618 - val_loss: 0.3515 - val_accuracy: 0.8562\n",
            "Epoch 194/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3645 - accuracy: 0.8527 - val_loss: 0.3337 - val_accuracy: 0.8655\n",
            "Epoch 195/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3530 - accuracy: 0.8579 - val_loss: 0.3486 - val_accuracy: 0.8572\n",
            "Epoch 196/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3394 - accuracy: 0.8631 - val_loss: 0.3130 - val_accuracy: 0.8768\n",
            "Epoch 197/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3548 - accuracy: 0.8556 - val_loss: 0.3376 - val_accuracy: 0.8642\n",
            "Epoch 198/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3507 - accuracy: 0.8580 - val_loss: 0.3311 - val_accuracy: 0.8695\n",
            "Epoch 199/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3517 - accuracy: 0.8590 - val_loss: 0.3700 - val_accuracy: 0.8467\n",
            "Epoch 200/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3375 - accuracy: 0.8665 - val_loss: 0.3108 - val_accuracy: 0.8787\n",
            "Epoch 201/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3471 - accuracy: 0.8605 - val_loss: 0.3317 - val_accuracy: 0.8645\n",
            "Epoch 202/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3420 - accuracy: 0.8634 - val_loss: 0.3097 - val_accuracy: 0.8777\n",
            "Epoch 203/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3463 - accuracy: 0.8614 - val_loss: 0.3658 - val_accuracy: 0.8490\n",
            "Epoch 204/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3543 - accuracy: 0.8583 - val_loss: 0.3156 - val_accuracy: 0.8747\n",
            "Epoch 205/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3408 - accuracy: 0.8635 - val_loss: 0.3106 - val_accuracy: 0.8768\n",
            "Epoch 206/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3433 - accuracy: 0.8634 - val_loss: 0.3052 - val_accuracy: 0.8810\n",
            "Epoch 207/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3529 - accuracy: 0.8565 - val_loss: 0.3246 - val_accuracy: 0.8675\n",
            "Epoch 208/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3334 - accuracy: 0.8693 - val_loss: 0.3304 - val_accuracy: 0.8663\n",
            "Epoch 209/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3420 - accuracy: 0.8634 - val_loss: 0.3110 - val_accuracy: 0.8760\n",
            "Epoch 210/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3436 - accuracy: 0.8626 - val_loss: 0.3037 - val_accuracy: 0.8813\n",
            "Epoch 211/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3432 - accuracy: 0.8626 - val_loss: 0.3105 - val_accuracy: 0.8770\n",
            "Epoch 212/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3446 - accuracy: 0.8618 - val_loss: 0.3977 - val_accuracy: 0.8353\n",
            "Epoch 213/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3380 - accuracy: 0.8652 - val_loss: 0.3391 - val_accuracy: 0.8610\n",
            "Epoch 214/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3391 - accuracy: 0.8630 - val_loss: 0.3156 - val_accuracy: 0.8720\n",
            "Epoch 215/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3422 - accuracy: 0.8632 - val_loss: 0.3072 - val_accuracy: 0.8798\n",
            "Epoch 216/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3445 - accuracy: 0.8616 - val_loss: 0.3280 - val_accuracy: 0.8682\n",
            "Epoch 217/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3359 - accuracy: 0.8647 - val_loss: 0.3102 - val_accuracy: 0.8765\n",
            "Epoch 218/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3395 - accuracy: 0.8639 - val_loss: 0.3033 - val_accuracy: 0.8802\n",
            "Epoch 219/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3247 - accuracy: 0.8709 - val_loss: 0.3091 - val_accuracy: 0.8765\n",
            "Epoch 220/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3477 - accuracy: 0.8592 - val_loss: 0.3070 - val_accuracy: 0.8798\n",
            "Epoch 221/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3254 - accuracy: 0.8713 - val_loss: 0.3572 - val_accuracy: 0.8512\n",
            "Epoch 222/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3415 - accuracy: 0.8624 - val_loss: 0.3102 - val_accuracy: 0.8748\n",
            "Epoch 223/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3392 - accuracy: 0.8637 - val_loss: 0.3157 - val_accuracy: 0.8742\n",
            "Epoch 224/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3406 - accuracy: 0.8625 - val_loss: 0.3133 - val_accuracy: 0.8768\n",
            "Epoch 225/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3353 - accuracy: 0.8658 - val_loss: 0.3340 - val_accuracy: 0.8650\n",
            "Epoch 226/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3269 - accuracy: 0.8685 - val_loss: 0.3007 - val_accuracy: 0.8847\n",
            "Epoch 227/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3354 - accuracy: 0.8662 - val_loss: 0.3022 - val_accuracy: 0.8810\n",
            "Epoch 228/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3301 - accuracy: 0.8669 - val_loss: 0.3033 - val_accuracy: 0.8805\n",
            "Epoch 229/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3427 - accuracy: 0.8624 - val_loss: 0.2995 - val_accuracy: 0.8832\n",
            "Epoch 230/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3203 - accuracy: 0.8733 - val_loss: 0.3361 - val_accuracy: 0.8617\n",
            "Epoch 231/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3337 - accuracy: 0.8655 - val_loss: 0.2993 - val_accuracy: 0.8825\n",
            "Epoch 232/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3348 - accuracy: 0.8644 - val_loss: 0.3272 - val_accuracy: 0.8687\n",
            "Epoch 233/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3284 - accuracy: 0.8680 - val_loss: 0.3042 - val_accuracy: 0.8793\n",
            "Epoch 234/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3308 - accuracy: 0.8688 - val_loss: 0.3088 - val_accuracy: 0.8780\n",
            "Epoch 235/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3278 - accuracy: 0.8701 - val_loss: 0.3413 - val_accuracy: 0.8588\n",
            "Epoch 236/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3255 - accuracy: 0.8703 - val_loss: 0.2971 - val_accuracy: 0.8848\n",
            "Epoch 237/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3295 - accuracy: 0.8669 - val_loss: 0.3066 - val_accuracy: 0.8780\n",
            "Epoch 238/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3303 - accuracy: 0.8681 - val_loss: 0.2998 - val_accuracy: 0.8817\n",
            "Epoch 239/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3216 - accuracy: 0.8714 - val_loss: 0.2980 - val_accuracy: 0.8840\n",
            "Epoch 240/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3301 - accuracy: 0.8675 - val_loss: 0.3024 - val_accuracy: 0.8810\n",
            "Epoch 241/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3220 - accuracy: 0.8715 - val_loss: 0.3364 - val_accuracy: 0.8628\n",
            "Epoch 242/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3270 - accuracy: 0.8680 - val_loss: 0.2934 - val_accuracy: 0.8872\n",
            "Epoch 243/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3222 - accuracy: 0.8717 - val_loss: 0.3080 - val_accuracy: 0.8765\n",
            "Epoch 244/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3354 - accuracy: 0.8631 - val_loss: 0.2962 - val_accuracy: 0.8857\n",
            "Epoch 245/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3346 - accuracy: 0.8650 - val_loss: 0.3149 - val_accuracy: 0.8722\n",
            "Epoch 246/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3134 - accuracy: 0.8753 - val_loss: 0.3206 - val_accuracy: 0.8723\n",
            "Epoch 247/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3316 - accuracy: 0.8647 - val_loss: 0.3148 - val_accuracy: 0.8755\n",
            "Epoch 248/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3191 - accuracy: 0.8716 - val_loss: 0.3080 - val_accuracy: 0.8785\n",
            "Epoch 249/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3327 - accuracy: 0.8657 - val_loss: 0.3131 - val_accuracy: 0.8743\n",
            "Epoch 250/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3142 - accuracy: 0.8751 - val_loss: 0.2916 - val_accuracy: 0.8852\n",
            "Epoch 251/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3233 - accuracy: 0.8699 - val_loss: 0.3138 - val_accuracy: 0.8730\n",
            "Epoch 252/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3273 - accuracy: 0.8689 - val_loss: 0.3096 - val_accuracy: 0.8767\n",
            "Epoch 253/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3209 - accuracy: 0.8712 - val_loss: 0.2910 - val_accuracy: 0.8888\n",
            "Epoch 254/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3260 - accuracy: 0.8693 - val_loss: 0.3403 - val_accuracy: 0.8567\n",
            "Epoch 255/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3146 - accuracy: 0.8736 - val_loss: 0.2939 - val_accuracy: 0.8850\n",
            "Epoch 256/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3153 - accuracy: 0.8727 - val_loss: 0.2898 - val_accuracy: 0.8892\n",
            "Epoch 257/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3097 - accuracy: 0.8775 - val_loss: 0.2894 - val_accuracy: 0.8888\n",
            "Epoch 258/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3186 - accuracy: 0.8727 - val_loss: 0.2949 - val_accuracy: 0.8860\n",
            "Epoch 259/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3240 - accuracy: 0.8700 - val_loss: 0.2922 - val_accuracy: 0.8878\n",
            "Epoch 260/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3234 - accuracy: 0.8706 - val_loss: 0.2941 - val_accuracy: 0.8852\n",
            "Epoch 261/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3153 - accuracy: 0.8745 - val_loss: 0.2886 - val_accuracy: 0.8880\n",
            "Epoch 262/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3122 - accuracy: 0.8741 - val_loss: 0.2893 - val_accuracy: 0.8878\n",
            "Epoch 263/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3120 - accuracy: 0.8751 - val_loss: 0.2913 - val_accuracy: 0.8857\n",
            "Epoch 264/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3224 - accuracy: 0.8689 - val_loss: 0.2985 - val_accuracy: 0.8835\n",
            "Epoch 265/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3166 - accuracy: 0.8732 - val_loss: 0.2987 - val_accuracy: 0.8823\n",
            "Epoch 266/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3146 - accuracy: 0.8739 - val_loss: 0.3111 - val_accuracy: 0.8733\n",
            "Epoch 267/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3209 - accuracy: 0.8708 - val_loss: 0.3257 - val_accuracy: 0.8672\n",
            "Epoch 268/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3214 - accuracy: 0.8709 - val_loss: 0.2972 - val_accuracy: 0.8828\n",
            "Epoch 269/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3169 - accuracy: 0.8725 - val_loss: 0.3721 - val_accuracy: 0.8472\n",
            "Epoch 270/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3166 - accuracy: 0.8731 - val_loss: 0.2873 - val_accuracy: 0.8887\n",
            "Epoch 271/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3121 - accuracy: 0.8752 - val_loss: 0.2970 - val_accuracy: 0.8797\n",
            "Epoch 272/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3100 - accuracy: 0.8758 - val_loss: 0.3220 - val_accuracy: 0.8695\n",
            "Epoch 273/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3062 - accuracy: 0.8754 - val_loss: 0.2961 - val_accuracy: 0.8807\n",
            "Epoch 274/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3177 - accuracy: 0.8723 - val_loss: 0.2865 - val_accuracy: 0.8913\n",
            "Epoch 275/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3164 - accuracy: 0.8731 - val_loss: 0.2872 - val_accuracy: 0.8885\n",
            "Epoch 276/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3123 - accuracy: 0.8751 - val_loss: 0.3573 - val_accuracy: 0.8493\n",
            "Epoch 277/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3208 - accuracy: 0.8707 - val_loss: 0.3069 - val_accuracy: 0.8755\n",
            "Epoch 278/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3145 - accuracy: 0.8733 - val_loss: 0.2899 - val_accuracy: 0.8865\n",
            "Epoch 279/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3097 - accuracy: 0.8758 - val_loss: 0.2864 - val_accuracy: 0.8893\n",
            "Epoch 280/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3109 - accuracy: 0.8756 - val_loss: 0.3368 - val_accuracy: 0.8602\n",
            "Epoch 281/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3172 - accuracy: 0.8716 - val_loss: 0.2936 - val_accuracy: 0.8820\n",
            "Epoch 282/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3142 - accuracy: 0.8723 - val_loss: 0.3052 - val_accuracy: 0.8778\n",
            "Epoch 283/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3111 - accuracy: 0.8745 - val_loss: 0.3303 - val_accuracy: 0.8625\n",
            "Epoch 284/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3071 - accuracy: 0.8768 - val_loss: 0.3312 - val_accuracy: 0.8618\n",
            "Epoch 285/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3149 - accuracy: 0.8730 - val_loss: 0.3163 - val_accuracy: 0.8700\n",
            "Epoch 286/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3156 - accuracy: 0.8730 - val_loss: 0.3511 - val_accuracy: 0.8553\n",
            "Epoch 287/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3059 - accuracy: 0.8785 - val_loss: 0.3194 - val_accuracy: 0.8707\n",
            "Epoch 288/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3068 - accuracy: 0.8760 - val_loss: 0.2842 - val_accuracy: 0.8898\n",
            "Epoch 289/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3048 - accuracy: 0.8777 - val_loss: 0.2992 - val_accuracy: 0.8793\n",
            "Epoch 290/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3126 - accuracy: 0.8747 - val_loss: 0.3123 - val_accuracy: 0.8735\n",
            "Epoch 291/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3052 - accuracy: 0.8772 - val_loss: 0.2855 - val_accuracy: 0.8897\n",
            "Epoch 292/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3157 - accuracy: 0.8725 - val_loss: 0.3083 - val_accuracy: 0.8780\n",
            "Epoch 293/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3078 - accuracy: 0.8753 - val_loss: 0.2931 - val_accuracy: 0.8837\n",
            "Epoch 294/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3019 - accuracy: 0.8800 - val_loss: 0.3208 - val_accuracy: 0.8667\n",
            "Epoch 295/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3086 - accuracy: 0.8759 - val_loss: 0.2983 - val_accuracy: 0.8818\n",
            "Epoch 296/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3029 - accuracy: 0.8789 - val_loss: 0.3335 - val_accuracy: 0.8610\n",
            "Epoch 297/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3000 - accuracy: 0.8786 - val_loss: 0.3208 - val_accuracy: 0.8677\n",
            "Epoch 298/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3006 - accuracy: 0.8789 - val_loss: 0.2801 - val_accuracy: 0.8905\n",
            "Epoch 299/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3102 - accuracy: 0.8756 - val_loss: 0.2811 - val_accuracy: 0.8878\n",
            "Epoch 300/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3065 - accuracy: 0.8768 - val_loss: 0.3660 - val_accuracy: 0.8467\n",
            "Epoch 301/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3063 - accuracy: 0.8761 - val_loss: 0.2945 - val_accuracy: 0.8828\n",
            "Epoch 302/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3052 - accuracy: 0.8778 - val_loss: 0.2899 - val_accuracy: 0.8845\n",
            "Epoch 303/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2949 - accuracy: 0.8820 - val_loss: 0.2800 - val_accuracy: 0.8912\n",
            "Epoch 304/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3123 - accuracy: 0.8741 - val_loss: 0.2896 - val_accuracy: 0.8847\n",
            "Epoch 305/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3028 - accuracy: 0.8786 - val_loss: 0.2922 - val_accuracy: 0.8852\n",
            "Epoch 306/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2925 - accuracy: 0.8822 - val_loss: 0.2832 - val_accuracy: 0.8885\n",
            "Epoch 307/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3040 - accuracy: 0.8788 - val_loss: 0.2797 - val_accuracy: 0.8902\n",
            "Epoch 308/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2910 - accuracy: 0.8837 - val_loss: 0.2789 - val_accuracy: 0.8902\n",
            "Epoch 309/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3107 - accuracy: 0.8747 - val_loss: 0.3340 - val_accuracy: 0.8635\n",
            "Epoch 310/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3065 - accuracy: 0.8769 - val_loss: 0.2781 - val_accuracy: 0.8918\n",
            "Epoch 311/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2950 - accuracy: 0.8810 - val_loss: 0.2765 - val_accuracy: 0.8955\n",
            "Epoch 312/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3034 - accuracy: 0.8781 - val_loss: 0.2932 - val_accuracy: 0.8842\n",
            "Epoch 313/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2923 - accuracy: 0.8845 - val_loss: 0.2761 - val_accuracy: 0.8932\n",
            "Epoch 314/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3002 - accuracy: 0.8790 - val_loss: 0.2999 - val_accuracy: 0.8795\n",
            "Epoch 315/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3006 - accuracy: 0.8791 - val_loss: 0.2934 - val_accuracy: 0.8832\n",
            "Epoch 316/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3002 - accuracy: 0.8802 - val_loss: 0.2784 - val_accuracy: 0.8925\n",
            "Epoch 317/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2950 - accuracy: 0.8805 - val_loss: 0.2779 - val_accuracy: 0.8932\n",
            "Epoch 318/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3056 - accuracy: 0.8773 - val_loss: 0.2765 - val_accuracy: 0.8927\n",
            "Epoch 319/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2910 - accuracy: 0.8841 - val_loss: 0.3045 - val_accuracy: 0.8758\n",
            "Epoch 320/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3008 - accuracy: 0.8784 - val_loss: 0.3004 - val_accuracy: 0.8802\n",
            "Epoch 321/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2980 - accuracy: 0.8802 - val_loss: 0.2741 - val_accuracy: 0.8952\n",
            "Epoch 322/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3051 - accuracy: 0.8771 - val_loss: 0.2781 - val_accuracy: 0.8928\n",
            "Epoch 323/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2929 - accuracy: 0.8830 - val_loss: 0.2790 - val_accuracy: 0.8908\n",
            "Epoch 324/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2986 - accuracy: 0.8784 - val_loss: 0.2896 - val_accuracy: 0.8847\n",
            "Epoch 325/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2899 - accuracy: 0.8841 - val_loss: 0.2864 - val_accuracy: 0.8867\n",
            "Epoch 326/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3033 - accuracy: 0.8767 - val_loss: 0.4069 - val_accuracy: 0.8322\n",
            "Epoch 327/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2941 - accuracy: 0.8809 - val_loss: 0.2932 - val_accuracy: 0.8828\n",
            "Epoch 328/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2868 - accuracy: 0.8862 - val_loss: 0.2800 - val_accuracy: 0.8885\n",
            "Epoch 329/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3007 - accuracy: 0.8786 - val_loss: 0.2750 - val_accuracy: 0.8945\n",
            "Epoch 330/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2890 - accuracy: 0.8841 - val_loss: 0.2922 - val_accuracy: 0.8817\n",
            "Epoch 331/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3046 - accuracy: 0.8773 - val_loss: 0.2755 - val_accuracy: 0.8957\n",
            "Epoch 332/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2864 - accuracy: 0.8856 - val_loss: 0.2826 - val_accuracy: 0.8878\n",
            "Epoch 333/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2912 - accuracy: 0.8822 - val_loss: 0.2864 - val_accuracy: 0.8863\n",
            "Epoch 334/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2908 - accuracy: 0.8824 - val_loss: 0.2729 - val_accuracy: 0.8945\n",
            "Epoch 335/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2934 - accuracy: 0.8813 - val_loss: 0.2981 - val_accuracy: 0.8783\n",
            "Epoch 336/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2928 - accuracy: 0.8824 - val_loss: 0.2757 - val_accuracy: 0.8927\n",
            "Epoch 337/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3020 - accuracy: 0.8769 - val_loss: 0.2890 - val_accuracy: 0.8847\n",
            "Epoch 338/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2865 - accuracy: 0.8853 - val_loss: 0.2762 - val_accuracy: 0.8922\n",
            "Epoch 339/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2877 - accuracy: 0.8841 - val_loss: 0.2825 - val_accuracy: 0.8892\n",
            "Epoch 340/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2930 - accuracy: 0.8813 - val_loss: 0.2715 - val_accuracy: 0.8958\n",
            "Epoch 341/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2971 - accuracy: 0.8792 - val_loss: 0.2775 - val_accuracy: 0.8902\n",
            "Epoch 342/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2840 - accuracy: 0.8867 - val_loss: 0.2727 - val_accuracy: 0.8937\n",
            "Epoch 343/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2975 - accuracy: 0.8783 - val_loss: 0.2742 - val_accuracy: 0.8950\n",
            "Epoch 344/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2844 - accuracy: 0.8866 - val_loss: 0.2687 - val_accuracy: 0.8977\n",
            "Epoch 345/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2882 - accuracy: 0.8840 - val_loss: 0.2730 - val_accuracy: 0.8947\n",
            "Epoch 346/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2888 - accuracy: 0.8833 - val_loss: 0.3133 - val_accuracy: 0.8727\n",
            "Epoch 347/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2893 - accuracy: 0.8835 - val_loss: 0.2701 - val_accuracy: 0.8965\n",
            "Epoch 348/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2936 - accuracy: 0.8815 - val_loss: 0.2731 - val_accuracy: 0.8935\n",
            "Epoch 349/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2759 - accuracy: 0.8909 - val_loss: 0.2739 - val_accuracy: 0.8927\n",
            "Epoch 350/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2909 - accuracy: 0.8813 - val_loss: 0.2717 - val_accuracy: 0.8963\n",
            "Epoch 351/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2758 - accuracy: 0.8895 - val_loss: 0.2815 - val_accuracy: 0.8872\n",
            "Epoch 352/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.3046 - accuracy: 0.8770 - val_loss: 0.2728 - val_accuracy: 0.8953\n",
            "Epoch 353/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2789 - accuracy: 0.8888 - val_loss: 0.2702 - val_accuracy: 0.8952\n",
            "Epoch 354/400\n",
            "53/53 [==============================] - 2s 34ms/step - loss: 0.2828 - accuracy: 0.8871 - val_loss: 0.2939 - val_accuracy: 0.8802\n",
            "Epoch 355/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2925 - accuracy: 0.8819 - val_loss: 0.3749 - val_accuracy: 0.8442\n",
            "Epoch 356/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2883 - accuracy: 0.8836 - val_loss: 0.2780 - val_accuracy: 0.8882\n",
            "Epoch 357/400\n",
            "53/53 [==============================] - 2s 34ms/step - loss: 0.2828 - accuracy: 0.8864 - val_loss: 0.2706 - val_accuracy: 0.8957\n",
            "Epoch 358/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2815 - accuracy: 0.8869 - val_loss: 0.3006 - val_accuracy: 0.8780\n",
            "Epoch 359/400\n",
            "53/53 [==============================] - 2s 34ms/step - loss: 0.2916 - accuracy: 0.8831 - val_loss: 0.2734 - val_accuracy: 0.8913\n",
            "Epoch 360/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2859 - accuracy: 0.8856 - val_loss: 0.2820 - val_accuracy: 0.8873\n",
            "Epoch 361/400\n",
            "53/53 [==============================] - 2s 34ms/step - loss: 0.2861 - accuracy: 0.8847 - val_loss: 0.2674 - val_accuracy: 0.8968\n",
            "Epoch 362/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2847 - accuracy: 0.8844 - val_loss: 0.2834 - val_accuracy: 0.8853\n",
            "Epoch 363/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2928 - accuracy: 0.8817 - val_loss: 0.2814 - val_accuracy: 0.8877\n",
            "Epoch 364/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2756 - accuracy: 0.8904 - val_loss: 0.2682 - val_accuracy: 0.8955\n",
            "Epoch 365/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2859 - accuracy: 0.8855 - val_loss: 0.2732 - val_accuracy: 0.8925\n",
            "Epoch 366/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2823 - accuracy: 0.8878 - val_loss: 0.2850 - val_accuracy: 0.8825\n",
            "Epoch 367/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2834 - accuracy: 0.8862 - val_loss: 0.2700 - val_accuracy: 0.8938\n",
            "Epoch 368/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2806 - accuracy: 0.8878 - val_loss: 0.2764 - val_accuracy: 0.8913\n",
            "Epoch 369/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2847 - accuracy: 0.8856 - val_loss: 0.2696 - val_accuracy: 0.8943\n",
            "Epoch 370/400\n",
            "53/53 [==============================] - 2s 34ms/step - loss: 0.2821 - accuracy: 0.8866 - val_loss: 0.2699 - val_accuracy: 0.8945\n",
            "Epoch 371/400\n",
            "53/53 [==============================] - 2s 34ms/step - loss: 0.2733 - accuracy: 0.8911 - val_loss: 0.2721 - val_accuracy: 0.8920\n",
            "Epoch 372/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2765 - accuracy: 0.8897 - val_loss: 0.2654 - val_accuracy: 0.8977\n",
            "Epoch 373/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2921 - accuracy: 0.8812 - val_loss: 0.2859 - val_accuracy: 0.8843\n",
            "Epoch 374/400\n",
            "53/53 [==============================] - 2s 34ms/step - loss: 0.2800 - accuracy: 0.8871 - val_loss: 0.2703 - val_accuracy: 0.8932\n",
            "Epoch 375/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2861 - accuracy: 0.8838 - val_loss: 0.2705 - val_accuracy: 0.8922\n",
            "Epoch 376/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2779 - accuracy: 0.8894 - val_loss: 0.2749 - val_accuracy: 0.8918\n",
            "Epoch 377/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2730 - accuracy: 0.8900 - val_loss: 0.2892 - val_accuracy: 0.8803\n",
            "Epoch 378/400\n",
            "53/53 [==============================] - 2s 34ms/step - loss: 0.2824 - accuracy: 0.8846 - val_loss: 0.2648 - val_accuracy: 0.8975\n",
            "Epoch 379/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2805 - accuracy: 0.8867 - val_loss: 0.2652 - val_accuracy: 0.8970\n",
            "Epoch 380/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2828 - accuracy: 0.8855 - val_loss: 0.2763 - val_accuracy: 0.8887\n",
            "Epoch 381/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2801 - accuracy: 0.8872 - val_loss: 0.2747 - val_accuracy: 0.8920\n",
            "Epoch 382/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2877 - accuracy: 0.8834 - val_loss: 0.2758 - val_accuracy: 0.8887\n",
            "Epoch 383/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2856 - accuracy: 0.8852 - val_loss: 0.2661 - val_accuracy: 0.8952\n",
            "Epoch 384/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2741 - accuracy: 0.8906 - val_loss: 0.2669 - val_accuracy: 0.8958\n",
            "Epoch 385/400\n",
            "53/53 [==============================] - 2s 34ms/step - loss: 0.2755 - accuracy: 0.8896 - val_loss: 0.2652 - val_accuracy: 0.8953\n",
            "Epoch 386/400\n",
            "53/53 [==============================] - 2s 34ms/step - loss: 0.2645 - accuracy: 0.8951 - val_loss: 0.2817 - val_accuracy: 0.8880\n",
            "Epoch 387/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2841 - accuracy: 0.8850 - val_loss: 0.2891 - val_accuracy: 0.8825\n",
            "Epoch 388/400\n",
            "53/53 [==============================] - 2s 34ms/step - loss: 0.2758 - accuracy: 0.8895 - val_loss: 0.2652 - val_accuracy: 0.8973\n",
            "Epoch 389/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2720 - accuracy: 0.8913 - val_loss: 0.2626 - val_accuracy: 0.8995\n",
            "Epoch 390/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2780 - accuracy: 0.8884 - val_loss: 0.3005 - val_accuracy: 0.8763\n",
            "Epoch 391/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2705 - accuracy: 0.8920 - val_loss: 0.2669 - val_accuracy: 0.8960\n",
            "Epoch 392/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2805 - accuracy: 0.8866 - val_loss: 0.2699 - val_accuracy: 0.8918\n",
            "Epoch 393/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2727 - accuracy: 0.8911 - val_loss: 0.3359 - val_accuracy: 0.8598\n",
            "Epoch 394/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2684 - accuracy: 0.8927 - val_loss: 0.2785 - val_accuracy: 0.8885\n",
            "Epoch 395/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2766 - accuracy: 0.8878 - val_loss: 0.2747 - val_accuracy: 0.8905\n",
            "Epoch 396/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2862 - accuracy: 0.8833 - val_loss: 0.2763 - val_accuracy: 0.8873\n",
            "Epoch 397/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2706 - accuracy: 0.8906 - val_loss: 0.2661 - val_accuracy: 0.8932\n",
            "Epoch 398/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2716 - accuracy: 0.8910 - val_loss: 0.2838 - val_accuracy: 0.8845\n",
            "Epoch 399/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2747 - accuracy: 0.8911 - val_loss: 0.2627 - val_accuracy: 0.8995\n",
            "Epoch 400/400\n",
            "53/53 [==============================] - 2s 35ms/step - loss: 0.2679 - accuracy: 0.8926 - val_loss: 0.2622 - val_accuracy: 0.8972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftQDygmb5LWn",
        "colab_type": "code",
        "outputId": "16f77a34-3b09-4bd9-a16d-a3f4fc933d36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# RMS\n",
        "image_rows = 28\n",
        "image_cols = 28\n",
        "batch_size = 512\n",
        "image_shape = (image_rows,image_cols,1)\n",
        "cnn_modelrm = Sequential([\n",
        "    Conv2D(filters=32,kernel_size=5,activation='relu',padding='same',input_shape = image_shape),\n",
        "    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n",
        "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same'),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Conv2D(filters=128,kernel_size=1,activation='relu',padding='same'),\n",
        "    Dropout(0.2),\n",
        "    Flatten(), # 1flatten out the layers\n",
        "    Dense(1024,activation='relu'),\n",
        "    Dropout(0.25),\n",
        "    Dense(32,activation='relu'),\n",
        "    Dense(5,activation = 'softmax')\n",
        "])\n",
        "cnn_modelrm.compile(loss ='sparse_categorical_crossentropy', optimizer=RMSprop(),metrics =['accuracy'])\n",
        "history = cnn_modelrm.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=1024,\n",
        "    epochs=400,\n",
        "    verbose=1,\n",
        "    validation_data=(X_test,y_test)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "53/53 [==============================] - 2s 38ms/step - loss: 1.0585 - accuracy: 0.5395 - val_loss: 0.8537 - val_accuracy: 0.6427\n",
            "Epoch 2/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.7372 - accuracy: 0.6834 - val_loss: 0.6431 - val_accuracy: 0.7107\n",
            "Epoch 3/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.6262 - accuracy: 0.7303 - val_loss: 0.5474 - val_accuracy: 0.7693\n",
            "Epoch 4/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.5764 - accuracy: 0.7533 - val_loss: 0.5508 - val_accuracy: 0.7573\n",
            "Epoch 5/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.5340 - accuracy: 0.7720 - val_loss: 0.4575 - val_accuracy: 0.8090\n",
            "Epoch 6/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.5011 - accuracy: 0.7883 - val_loss: 0.5233 - val_accuracy: 0.7702\n",
            "Epoch 7/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.4772 - accuracy: 0.7983 - val_loss: 0.6592 - val_accuracy: 0.7078\n",
            "Epoch 8/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.4485 - accuracy: 0.8094 - val_loss: 0.4052 - val_accuracy: 0.8313\n",
            "Epoch 9/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.4408 - accuracy: 0.8142 - val_loss: 0.4737 - val_accuracy: 0.8000\n",
            "Epoch 10/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.4134 - accuracy: 0.8241 - val_loss: 0.5819 - val_accuracy: 0.7447\n",
            "Epoch 11/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.4050 - accuracy: 0.8270 - val_loss: 0.4052 - val_accuracy: 0.8302\n",
            "Epoch 12/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.3927 - accuracy: 0.8336 - val_loss: 0.3686 - val_accuracy: 0.8477\n",
            "Epoch 13/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.3729 - accuracy: 0.8427 - val_loss: 0.4044 - val_accuracy: 0.8282\n",
            "Epoch 14/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.3547 - accuracy: 0.8503 - val_loss: 0.3783 - val_accuracy: 0.8473\n",
            "Epoch 15/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.3518 - accuracy: 0.8524 - val_loss: 0.4592 - val_accuracy: 0.7975\n",
            "Epoch 16/400\n",
            "53/53 [==============================] - 2s 39ms/step - loss: 0.3368 - accuracy: 0.8581 - val_loss: 0.4126 - val_accuracy: 0.8288\n",
            "Epoch 17/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.3284 - accuracy: 0.8640 - val_loss: 0.4262 - val_accuracy: 0.8278\n",
            "Epoch 18/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.3128 - accuracy: 0.8692 - val_loss: 0.3883 - val_accuracy: 0.8450\n",
            "Epoch 19/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.2998 - accuracy: 0.8743 - val_loss: 0.4713 - val_accuracy: 0.8020\n",
            "Epoch 20/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.3005 - accuracy: 0.8740 - val_loss: 0.4051 - val_accuracy: 0.8365\n",
            "Epoch 21/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2812 - accuracy: 0.8821 - val_loss: 0.3898 - val_accuracy: 0.8337\n",
            "Epoch 22/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2790 - accuracy: 0.8831 - val_loss: 0.3765 - val_accuracy: 0.8370\n",
            "Epoch 23/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2593 - accuracy: 0.8918 - val_loss: 0.4511 - val_accuracy: 0.8265\n",
            "Epoch 24/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.2591 - accuracy: 0.8927 - val_loss: 0.3359 - val_accuracy: 0.8643\n",
            "Epoch 25/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2414 - accuracy: 0.9001 - val_loss: 0.4836 - val_accuracy: 0.8185\n",
            "Epoch 26/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2384 - accuracy: 0.9013 - val_loss: 0.3739 - val_accuracy: 0.8527\n",
            "Epoch 27/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2296 - accuracy: 0.9056 - val_loss: 0.3780 - val_accuracy: 0.8518\n",
            "Epoch 28/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2155 - accuracy: 0.9120 - val_loss: 0.3308 - val_accuracy: 0.8712\n",
            "Epoch 29/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.2103 - accuracy: 0.9142 - val_loss: 0.4378 - val_accuracy: 0.8300\n",
            "Epoch 30/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.2039 - accuracy: 0.9175 - val_loss: 0.4533 - val_accuracy: 0.8177\n",
            "Epoch 31/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1929 - accuracy: 0.9216 - val_loss: 0.3550 - val_accuracy: 0.8673\n",
            "Epoch 32/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.1890 - accuracy: 0.9239 - val_loss: 0.3474 - val_accuracy: 0.8695\n",
            "Epoch 33/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.1817 - accuracy: 0.9252 - val_loss: 0.3526 - val_accuracy: 0.8690\n",
            "Epoch 34/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1739 - accuracy: 0.9305 - val_loss: 0.3835 - val_accuracy: 0.8497\n",
            "Epoch 35/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1671 - accuracy: 0.9325 - val_loss: 0.4763 - val_accuracy: 0.8340\n",
            "Epoch 36/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1612 - accuracy: 0.9358 - val_loss: 0.4107 - val_accuracy: 0.8642\n",
            "Epoch 37/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1528 - accuracy: 0.9396 - val_loss: 0.3829 - val_accuracy: 0.8582\n",
            "Epoch 38/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1482 - accuracy: 0.9419 - val_loss: 0.3889 - val_accuracy: 0.8680\n",
            "Epoch 39/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1420 - accuracy: 0.9426 - val_loss: 0.4025 - val_accuracy: 0.8605\n",
            "Epoch 40/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1376 - accuracy: 0.9455 - val_loss: 0.3985 - val_accuracy: 0.8680\n",
            "Epoch 41/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1393 - accuracy: 0.9458 - val_loss: 0.3940 - val_accuracy: 0.8655\n",
            "Epoch 42/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1242 - accuracy: 0.9513 - val_loss: 0.4525 - val_accuracy: 0.8392\n",
            "Epoch 43/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1189 - accuracy: 0.9529 - val_loss: 0.4120 - val_accuracy: 0.8672\n",
            "Epoch 44/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1190 - accuracy: 0.9534 - val_loss: 0.4250 - val_accuracy: 0.8590\n",
            "Epoch 45/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1098 - accuracy: 0.9564 - val_loss: 0.6029 - val_accuracy: 0.8385\n",
            "Epoch 46/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1069 - accuracy: 0.9581 - val_loss: 0.4246 - val_accuracy: 0.8718\n",
            "Epoch 47/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0981 - accuracy: 0.9625 - val_loss: 0.5622 - val_accuracy: 0.8337\n",
            "Epoch 48/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0995 - accuracy: 0.9607 - val_loss: 0.4555 - val_accuracy: 0.8680\n",
            "Epoch 49/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0908 - accuracy: 0.9649 - val_loss: 0.4546 - val_accuracy: 0.8725\n",
            "Epoch 50/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0934 - accuracy: 0.9636 - val_loss: 0.4824 - val_accuracy: 0.8605\n",
            "Epoch 51/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0797 - accuracy: 0.9704 - val_loss: 0.6373 - val_accuracy: 0.8173\n",
            "Epoch 52/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0871 - accuracy: 0.9668 - val_loss: 0.4895 - val_accuracy: 0.8638\n",
            "Epoch 53/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0860 - accuracy: 0.9679 - val_loss: 0.4369 - val_accuracy: 0.8613\n",
            "Epoch 54/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0718 - accuracy: 0.9726 - val_loss: 0.4789 - val_accuracy: 0.8723\n",
            "Epoch 55/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0743 - accuracy: 0.9721 - val_loss: 0.5407 - val_accuracy: 0.8582\n",
            "Epoch 56/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0729 - accuracy: 0.9721 - val_loss: 0.4812 - val_accuracy: 0.8673\n",
            "Epoch 57/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0662 - accuracy: 0.9755 - val_loss: 0.5209 - val_accuracy: 0.8658\n",
            "Epoch 58/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0649 - accuracy: 0.9755 - val_loss: 0.6981 - val_accuracy: 0.8410\n",
            "Epoch 59/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0658 - accuracy: 0.9751 - val_loss: 0.5367 - val_accuracy: 0.8650\n",
            "Epoch 60/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0581 - accuracy: 0.9783 - val_loss: 0.6440 - val_accuracy: 0.8465\n",
            "Epoch 61/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0599 - accuracy: 0.9779 - val_loss: 0.5532 - val_accuracy: 0.8607\n",
            "Epoch 62/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0627 - accuracy: 0.9766 - val_loss: 0.6438 - val_accuracy: 0.8310\n",
            "Epoch 63/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0554 - accuracy: 0.9801 - val_loss: 0.5210 - val_accuracy: 0.8693\n",
            "Epoch 64/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0532 - accuracy: 0.9800 - val_loss: 0.5325 - val_accuracy: 0.8642\n",
            "Epoch 65/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0514 - accuracy: 0.9820 - val_loss: 0.6260 - val_accuracy: 0.8305\n",
            "Epoch 66/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0484 - accuracy: 0.9826 - val_loss: 0.6086 - val_accuracy: 0.8628\n",
            "Epoch 67/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0461 - accuracy: 0.9831 - val_loss: 0.5687 - val_accuracy: 0.8672\n",
            "Epoch 68/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0477 - accuracy: 0.9817 - val_loss: 0.6423 - val_accuracy: 0.8427\n",
            "Epoch 69/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0461 - accuracy: 0.9837 - val_loss: 0.6413 - val_accuracy: 0.8670\n",
            "Epoch 70/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0430 - accuracy: 0.9840 - val_loss: 0.6336 - val_accuracy: 0.8655\n",
            "Epoch 71/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0469 - accuracy: 0.9830 - val_loss: 0.5526 - val_accuracy: 0.8533\n",
            "Epoch 72/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0406 - accuracy: 0.9855 - val_loss: 0.6301 - val_accuracy: 0.8673\n",
            "Epoch 73/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0422 - accuracy: 0.9849 - val_loss: 0.6181 - val_accuracy: 0.8680\n",
            "Epoch 74/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0376 - accuracy: 0.9859 - val_loss: 0.6754 - val_accuracy: 0.8507\n",
            "Epoch 75/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0429 - accuracy: 0.9854 - val_loss: 0.6619 - val_accuracy: 0.8615\n",
            "Epoch 76/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.6477 - val_accuracy: 0.8452\n",
            "Epoch 77/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0446 - accuracy: 0.9846 - val_loss: 0.5618 - val_accuracy: 0.8572\n",
            "Epoch 78/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0348 - accuracy: 0.9876 - val_loss: 0.6511 - val_accuracy: 0.8560\n",
            "Epoch 79/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0349 - accuracy: 0.9883 - val_loss: 0.6978 - val_accuracy: 0.8530\n",
            "Epoch 80/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0368 - accuracy: 0.9871 - val_loss: 0.6688 - val_accuracy: 0.8670\n",
            "Epoch 81/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0302 - accuracy: 0.9894 - val_loss: 0.6877 - val_accuracy: 0.8643\n",
            "Epoch 82/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0437 - accuracy: 0.9855 - val_loss: 0.7164 - val_accuracy: 0.8027\n",
            "Epoch 83/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0401 - accuracy: 0.9866 - val_loss: 0.6312 - val_accuracy: 0.8463\n",
            "Epoch 84/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0230 - accuracy: 0.9922 - val_loss: 0.7306 - val_accuracy: 0.8620\n",
            "Epoch 85/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0366 - accuracy: 0.9880 - val_loss: 0.5619 - val_accuracy: 0.8477\n",
            "Epoch 86/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.6444 - val_accuracy: 0.8512\n",
            "Epoch 87/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.5738 - val_accuracy: 0.8433\n",
            "Epoch 88/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0327 - accuracy: 0.9886 - val_loss: 0.6683 - val_accuracy: 0.8658\n",
            "Epoch 89/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 0.7364 - val_accuracy: 0.8323\n",
            "Epoch 90/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.6930 - val_accuracy: 0.8620\n",
            "Epoch 91/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.7723 - val_accuracy: 0.8642\n",
            "Epoch 92/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0272 - accuracy: 0.9903 - val_loss: 0.8093 - val_accuracy: 0.8530\n",
            "Epoch 93/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0311 - accuracy: 0.9893 - val_loss: 0.7934 - val_accuracy: 0.8500\n",
            "Epoch 94/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0334 - accuracy: 0.9881 - val_loss: 0.7417 - val_accuracy: 0.8652\n",
            "Epoch 95/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0292 - accuracy: 0.9907 - val_loss: 0.6472 - val_accuracy: 0.8633\n",
            "Epoch 96/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.8028 - val_accuracy: 0.8445\n",
            "Epoch 97/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0351 - accuracy: 0.9883 - val_loss: 0.6368 - val_accuracy: 0.8633\n",
            "Epoch 98/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0246 - accuracy: 0.9908 - val_loss: 0.7064 - val_accuracy: 0.8692\n",
            "Epoch 99/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0254 - accuracy: 0.9914 - val_loss: 0.7229 - val_accuracy: 0.8650\n",
            "Epoch 100/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0276 - accuracy: 0.9913 - val_loss: 0.7331 - val_accuracy: 0.8650\n",
            "Epoch 101/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.8293 - val_accuracy: 0.8528\n",
            "Epoch 102/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.7604 - val_accuracy: 0.8653\n",
            "Epoch 103/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.7383 - val_accuracy: 0.8645\n",
            "Epoch 104/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0234 - accuracy: 0.9919 - val_loss: 0.7214 - val_accuracy: 0.8545\n",
            "Epoch 105/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.7702 - val_accuracy: 0.8578\n",
            "Epoch 106/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 0.7532 - val_accuracy: 0.8632\n",
            "Epoch 107/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.8832 - val_accuracy: 0.8610\n",
            "Epoch 108/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 0.7046 - val_accuracy: 0.8597\n",
            "Epoch 109/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.7845 - val_accuracy: 0.8635\n",
            "Epoch 110/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0270 - accuracy: 0.9918 - val_loss: 0.8239 - val_accuracy: 0.8625\n",
            "Epoch 111/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.7983 - val_accuracy: 0.8648\n",
            "Epoch 112/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0254 - accuracy: 0.9917 - val_loss: 0.8070 - val_accuracy: 0.8332\n",
            "Epoch 113/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.7252 - val_accuracy: 0.8620\n",
            "Epoch 114/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0182 - accuracy: 0.9935 - val_loss: 0.7764 - val_accuracy: 0.8653\n",
            "Epoch 115/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.9988 - val_accuracy: 0.8520\n",
            "Epoch 116/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.7727 - val_accuracy: 0.8628\n",
            "Epoch 117/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.7784 - val_accuracy: 0.8648\n",
            "Epoch 118/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 0.8739 - val_accuracy: 0.8618\n",
            "Epoch 119/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0202 - accuracy: 0.9930 - val_loss: 0.8061 - val_accuracy: 0.8593\n",
            "Epoch 120/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.7813 - val_accuracy: 0.8660\n",
            "Epoch 121/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.7820 - val_accuracy: 0.8600\n",
            "Epoch 122/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.8337 - val_accuracy: 0.8673\n",
            "Epoch 123/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.8407 - val_accuracy: 0.8662\n",
            "Epoch 124/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.7560 - val_accuracy: 0.8497\n",
            "Epoch 125/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.8615 - val_accuracy: 0.8670\n",
            "Epoch 126/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.8096 - val_accuracy: 0.8632\n",
            "Epoch 127/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 0.8067 - val_accuracy: 0.8638\n",
            "Epoch 128/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.8452 - val_accuracy: 0.8663\n",
            "Epoch 129/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.8618 - val_accuracy: 0.8572\n",
            "Epoch 130/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.9713 - val_accuracy: 0.8602\n",
            "Epoch 131/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.8582 - val_accuracy: 0.8583\n",
            "Epoch 132/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 1.0421 - val_accuracy: 0.8470\n",
            "Epoch 133/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.8012 - val_accuracy: 0.8455\n",
            "Epoch 134/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.8319 - val_accuracy: 0.8625\n",
            "Epoch 135/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0202 - accuracy: 0.9930 - val_loss: 0.8325 - val_accuracy: 0.8583\n",
            "Epoch 136/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.8581 - val_accuracy: 0.8650\n",
            "Epoch 137/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.9526 - val_accuracy: 0.8583\n",
            "Epoch 138/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.8995 - val_accuracy: 0.8670\n",
            "Epoch 139/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.7984 - val_accuracy: 0.8580\n",
            "Epoch 140/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 1.1149 - val_accuracy: 0.8258\n",
            "Epoch 141/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.8245 - val_accuracy: 0.8652\n",
            "Epoch 142/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.9642 - val_accuracy: 0.8673\n",
            "Epoch 143/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.9213 - val_accuracy: 0.8663\n",
            "Epoch 144/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.9088 - val_accuracy: 0.8608\n",
            "Epoch 145/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.9356 - val_accuracy: 0.8665\n",
            "Epoch 146/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0197 - accuracy: 0.9931 - val_loss: 0.8547 - val_accuracy: 0.8623\n",
            "Epoch 147/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.9212 - val_accuracy: 0.8570\n",
            "Epoch 148/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.8822 - val_accuracy: 0.8458\n",
            "Epoch 149/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.9724 - val_accuracy: 0.8630\n",
            "Epoch 150/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.9279 - val_accuracy: 0.8573\n",
            "Epoch 151/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.9106 - val_accuracy: 0.8602\n",
            "Epoch 152/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.8330 - val_accuracy: 0.8650\n",
            "Epoch 153/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.8883 - val_accuracy: 0.8557\n",
            "Epoch 154/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.8937 - val_accuracy: 0.8627\n",
            "Epoch 155/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 1.0709 - val_accuracy: 0.8590\n",
            "Epoch 156/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.9832 - val_accuracy: 0.8607\n",
            "Epoch 157/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 0.9813 - val_accuracy: 0.8572\n",
            "Epoch 158/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.8832 - val_accuracy: 0.8568\n",
            "Epoch 159/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 1.0922 - val_accuracy: 0.8612\n",
            "Epoch 160/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.8773 - val_accuracy: 0.8627\n",
            "Epoch 161/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.8687 - val_accuracy: 0.8592\n",
            "Epoch 162/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.9192 - val_accuracy: 0.8622\n",
            "Epoch 163/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.8580 - val_accuracy: 0.8602\n",
            "Epoch 164/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.9199 - val_accuracy: 0.8650\n",
            "Epoch 165/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 1.0264 - val_accuracy: 0.8632\n",
            "Epoch 166/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 1.1441 - val_accuracy: 0.8263\n",
            "Epoch 167/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.8634 - val_accuracy: 0.8353\n",
            "Epoch 168/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 1.1415 - val_accuracy: 0.8455\n",
            "Epoch 169/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 1.0074 - val_accuracy: 0.8487\n",
            "Epoch 170/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.9511 - val_accuracy: 0.8637\n",
            "Epoch 171/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 1.0407 - val_accuracy: 0.8605\n",
            "Epoch 172/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.9475 - val_accuracy: 0.8630\n",
            "Epoch 173/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.8809 - val_accuracy: 0.8595\n",
            "Epoch 174/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0273 - accuracy: 0.9919 - val_loss: 0.8544 - val_accuracy: 0.8575\n",
            "Epoch 175/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.8922 - val_accuracy: 0.8648\n",
            "Epoch 176/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.8854 - val_accuracy: 0.8628\n",
            "Epoch 177/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.8996 - val_accuracy: 0.8602\n",
            "Epoch 178/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.8748 - val_accuracy: 0.8625\n",
            "Epoch 179/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.9684 - val_accuracy: 0.8587\n",
            "Epoch 180/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.9385 - val_accuracy: 0.8610\n",
            "Epoch 181/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.9391 - val_accuracy: 0.8645\n",
            "Epoch 182/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.0931 - val_accuracy: 0.8635\n",
            "Epoch 183/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.8885 - val_accuracy: 0.8630\n",
            "Epoch 184/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 1.1564 - val_accuracy: 0.8317\n",
            "Epoch 185/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 1.0401 - val_accuracy: 0.8603\n",
            "Epoch 186/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.8624 - val_accuracy: 0.8563\n",
            "Epoch 187/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.9570 - val_accuracy: 0.8608\n",
            "Epoch 188/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 1.0121 - val_accuracy: 0.8608\n",
            "Epoch 189/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 1.0352 - val_accuracy: 0.8578\n",
            "Epoch 190/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.8515 - val_accuracy: 0.8578\n",
            "Epoch 191/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.9952 - val_accuracy: 0.8610\n",
            "Epoch 192/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 1.0106 - val_accuracy: 0.8640\n",
            "Epoch 193/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 1.0222 - val_accuracy: 0.8630\n",
            "Epoch 194/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 1.0442 - val_accuracy: 0.8637\n",
            "Epoch 195/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.9203 - val_accuracy: 0.8557\n",
            "Epoch 196/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.9534 - val_accuracy: 0.8595\n",
            "Epoch 197/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.9775 - val_accuracy: 0.8365\n",
            "Epoch 198/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.9840 - val_accuracy: 0.8567\n",
            "Epoch 199/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 1.3051 - val_accuracy: 0.8305\n",
            "Epoch 200/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.9343 - val_accuracy: 0.8627\n",
            "Epoch 201/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 1.0043 - val_accuracy: 0.8638\n",
            "Epoch 202/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.9778 - val_accuracy: 0.8617\n",
            "Epoch 203/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 1.0225 - val_accuracy: 0.8622\n",
            "Epoch 204/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.8770 - val_accuracy: 0.8612\n",
            "Epoch 205/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.9899 - val_accuracy: 0.8657\n",
            "Epoch 206/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 1.0513 - val_accuracy: 0.8640\n",
            "Epoch 207/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.8738 - val_accuracy: 0.8613\n",
            "Epoch 208/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 1.0497 - val_accuracy: 0.8662\n",
            "Epoch 209/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.9125 - val_accuracy: 0.8635\n",
            "Epoch 210/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.9543 - val_accuracy: 0.8622\n",
            "Epoch 211/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 1.0453 - val_accuracy: 0.8533\n",
            "Epoch 212/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.9142 - val_accuracy: 0.8612\n",
            "Epoch 213/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 1.0398 - val_accuracy: 0.8625\n",
            "Epoch 214/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.9473 - val_accuracy: 0.8655\n",
            "Epoch 215/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 1.0895 - val_accuracy: 0.8622\n",
            "Epoch 216/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 1.1064 - val_accuracy: 0.8618\n",
            "Epoch 217/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.9618 - val_accuracy: 0.8635\n",
            "Epoch 218/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 1.0311 - val_accuracy: 0.8585\n",
            "Epoch 219/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.9370 - val_accuracy: 0.8632\n",
            "Epoch 220/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.8527 - val_accuracy: 0.8573\n",
            "Epoch 221/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.9878 - val_accuracy: 0.8523\n",
            "Epoch 222/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.8657 - val_accuracy: 0.8600\n",
            "Epoch 223/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.9312 - val_accuracy: 0.8605\n",
            "Epoch 224/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.9973 - val_accuracy: 0.8595\n",
            "Epoch 225/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.8313 - val_accuracy: 0.8532\n",
            "Epoch 226/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.9337 - val_accuracy: 0.8583\n",
            "Epoch 227/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 1.0181 - val_accuracy: 0.8657\n",
            "Epoch 228/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 1.0519 - val_accuracy: 0.8620\n",
            "Epoch 229/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.9719 - val_accuracy: 0.8645\n",
            "Epoch 230/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 1.1139 - val_accuracy: 0.8660\n",
            "Epoch 231/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 1.0799 - val_accuracy: 0.8643\n",
            "Epoch 232/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 1.0980 - val_accuracy: 0.8165\n",
            "Epoch 233/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.8981 - val_accuracy: 0.8628\n",
            "Epoch 234/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.8696 - val_accuracy: 0.8623\n",
            "Epoch 235/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.9282 - val_accuracy: 0.8660\n",
            "Epoch 236/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 1.0231 - val_accuracy: 0.8605\n",
            "Epoch 237/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.9129 - val_accuracy: 0.8532\n",
            "Epoch 238/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.9286 - val_accuracy: 0.8597\n",
            "Epoch 239/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.9076 - val_accuracy: 0.8610\n",
            "Epoch 240/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.9996 - val_accuracy: 0.8632\n",
            "Epoch 241/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.9208 - val_accuracy: 0.8673\n",
            "Epoch 242/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.9994 - val_accuracy: 0.8638\n",
            "Epoch 243/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 1.1897 - val_accuracy: 0.8602\n",
            "Epoch 244/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0222 - accuracy: 0.9935 - val_loss: 1.0587 - val_accuracy: 0.8677\n",
            "Epoch 245/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 1.2185 - val_accuracy: 0.8393\n",
            "Epoch 246/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 1.1715 - val_accuracy: 0.8625\n",
            "Epoch 247/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 1.1028 - val_accuracy: 0.8645\n",
            "Epoch 248/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.9417 - val_accuracy: 0.8577\n",
            "Epoch 249/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 1.0720 - val_accuracy: 0.8650\n",
            "Epoch 250/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.9248 - val_accuracy: 0.8592\n",
            "Epoch 251/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 1.0776 - val_accuracy: 0.8502\n",
            "Epoch 252/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 1.1353 - val_accuracy: 0.8612\n",
            "Epoch 253/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.9775 - val_accuracy: 0.8655\n",
            "Epoch 254/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.9891 - val_accuracy: 0.8638\n",
            "Epoch 255/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.9321 - val_accuracy: 0.8603\n",
            "Epoch 256/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.9118 - val_accuracy: 0.8672\n",
            "Epoch 257/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 1.0623 - val_accuracy: 0.8668\n",
            "Epoch 258/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.9929 - val_accuracy: 0.8623\n",
            "Epoch 259/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.9957 - val_accuracy: 0.8642\n",
            "Epoch 260/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 1.0336 - val_accuracy: 0.8677\n",
            "Epoch 261/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 1.0775 - val_accuracy: 0.8543\n",
            "Epoch 262/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.9877 - val_accuracy: 0.8575\n",
            "Epoch 263/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.9225 - val_accuracy: 0.8470\n",
            "Epoch 264/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.7690 - val_accuracy: 0.8583\n",
            "Epoch 265/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.7124 - val_accuracy: 0.8558\n",
            "Epoch 266/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.9440 - val_accuracy: 0.8565\n",
            "Epoch 267/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 1.1540 - val_accuracy: 0.8643\n",
            "Epoch 268/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.8673 - val_accuracy: 0.8545\n",
            "Epoch 269/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 1.1483 - val_accuracy: 0.8625\n",
            "Epoch 270/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 1.0981 - val_accuracy: 0.8592\n",
            "Epoch 271/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.9110 - val_accuracy: 0.8555\n",
            "Epoch 272/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 1.0531 - val_accuracy: 0.8520\n",
            "Epoch 273/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 1.1460 - val_accuracy: 0.8615\n",
            "Epoch 274/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 1.0171 - val_accuracy: 0.8587\n",
            "Epoch 275/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 1.0651 - val_accuracy: 0.8655\n",
            "Epoch 276/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 1.0745 - val_accuracy: 0.8617\n",
            "Epoch 277/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.9953 - val_accuracy: 0.8528\n",
            "Epoch 278/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 1.0514 - val_accuracy: 0.8533\n",
            "Epoch 279/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 1.6023 - val_accuracy: 0.8425\n",
            "Epoch 280/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 1.0021 - val_accuracy: 0.8520\n",
            "Epoch 281/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 1.0240 - val_accuracy: 0.8568\n",
            "Epoch 282/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 1.1103 - val_accuracy: 0.8663\n",
            "Epoch 283/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.8691 - val_accuracy: 0.8600\n",
            "Epoch 284/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.9666 - val_accuracy: 0.8613\n",
            "Epoch 285/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 1.0884 - val_accuracy: 0.8642\n",
            "Epoch 286/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 1.1387 - val_accuracy: 0.8655\n",
            "Epoch 287/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 1.0297 - val_accuracy: 0.8665\n",
            "Epoch 288/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 1.1913 - val_accuracy: 0.8528\n",
            "Epoch 289/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.9136 - val_accuracy: 0.8633\n",
            "Epoch 290/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 1.0140 - val_accuracy: 0.8652\n",
            "Epoch 291/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 1.3215 - val_accuracy: 0.8587\n",
            "Epoch 292/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 1.3342 - val_accuracy: 0.8625\n",
            "Epoch 293/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0186 - accuracy: 0.9948 - val_loss: 1.1774 - val_accuracy: 0.8617\n",
            "Epoch 294/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 1.1138 - val_accuracy: 0.8615\n",
            "Epoch 295/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.9123 - val_accuracy: 0.8648\n",
            "Epoch 296/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 1.0219 - val_accuracy: 0.8565\n",
            "Epoch 297/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.9908 - val_accuracy: 0.8543\n",
            "Epoch 298/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 1.1004 - val_accuracy: 0.8625\n",
            "Epoch 299/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0215 - accuracy: 0.9938 - val_loss: 1.2564 - val_accuracy: 0.8583\n",
            "Epoch 300/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 1.1522 - val_accuracy: 0.8622\n",
            "Epoch 301/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 1.1077 - val_accuracy: 0.8652\n",
            "Epoch 302/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.9100 - val_accuracy: 0.8530\n",
            "Epoch 303/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 1.0127 - val_accuracy: 0.8605\n",
            "Epoch 304/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 1.2127 - val_accuracy: 0.8657\n",
            "Epoch 305/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.8659 - val_accuracy: 0.8577\n",
            "Epoch 306/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 1.0191 - val_accuracy: 0.8630\n",
            "Epoch 307/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 1.1046 - val_accuracy: 0.8618\n",
            "Epoch 308/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 1.1170 - val_accuracy: 0.8670\n",
            "Epoch 309/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 1.1885 - val_accuracy: 0.8492\n",
            "Epoch 310/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0178 - accuracy: 0.9950 - val_loss: 1.0492 - val_accuracy: 0.8580\n",
            "Epoch 311/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.8788 - val_accuracy: 0.8603\n",
            "Epoch 312/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.8737 - val_accuracy: 0.8697\n",
            "Epoch 313/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 1.2054 - val_accuracy: 0.8643\n",
            "Epoch 314/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 1.1228 - val_accuracy: 0.8608\n",
            "Epoch 315/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0260 - accuracy: 0.9923 - val_loss: 0.9082 - val_accuracy: 0.8602\n",
            "Epoch 316/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 1.0031 - val_accuracy: 0.8428\n",
            "Epoch 317/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.8844 - val_accuracy: 0.8625\n",
            "Epoch 318/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 1.1300 - val_accuracy: 0.8598\n",
            "Epoch 319/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 1.1110 - val_accuracy: 0.8642\n",
            "Epoch 320/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.9941 - val_accuracy: 0.8642\n",
            "Epoch 321/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 1.3223 - val_accuracy: 0.8637\n",
            "Epoch 322/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 1.0971 - val_accuracy: 0.8673\n",
            "Epoch 323/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.9182 - val_accuracy: 0.8633\n",
            "Epoch 324/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 1.2266 - val_accuracy: 0.8605\n",
            "Epoch 325/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 1.0006 - val_accuracy: 0.8648\n",
            "Epoch 326/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.9053 - val_accuracy: 0.8603\n",
            "Epoch 327/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 1.0085 - val_accuracy: 0.8693\n",
            "Epoch 328/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 1.0279 - val_accuracy: 0.8643\n",
            "Epoch 329/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 1.3315 - val_accuracy: 0.8678\n",
            "Epoch 330/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0269 - accuracy: 0.9925 - val_loss: 1.0716 - val_accuracy: 0.8715\n",
            "Epoch 331/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 1.0361 - val_accuracy: 0.8660\n",
            "Epoch 332/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 1.2328 - val_accuracy: 0.8658\n",
            "Epoch 333/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 1.2210 - val_accuracy: 0.8667\n",
            "Epoch 334/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 1.0978 - val_accuracy: 0.8655\n",
            "Epoch 335/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0196 - accuracy: 0.9941 - val_loss: 1.1583 - val_accuracy: 0.8655\n",
            "Epoch 336/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 1.1587 - val_accuracy: 0.8675\n",
            "Epoch 337/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 1.0872 - val_accuracy: 0.8597\n",
            "Epoch 338/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 1.0466 - val_accuracy: 0.8685\n",
            "Epoch 339/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 1.0068 - val_accuracy: 0.8665\n",
            "Epoch 340/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 1.0280 - val_accuracy: 0.8633\n",
            "Epoch 341/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 1.2700 - val_accuracy: 0.8617\n",
            "Epoch 342/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.8706 - val_accuracy: 0.8588\n",
            "Epoch 343/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.8908 - val_accuracy: 0.8540\n",
            "Epoch 344/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 1.3907 - val_accuracy: 0.8662\n",
            "Epoch 345/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 1.1611 - val_accuracy: 0.8598\n",
            "Epoch 346/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 1.5668 - val_accuracy: 0.8388\n",
            "Epoch 347/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 1.0765 - val_accuracy: 0.8657\n",
            "Epoch 348/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 1.1786 - val_accuracy: 0.8618\n",
            "Epoch 349/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 1.0990 - val_accuracy: 0.8625\n",
            "Epoch 350/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.9720 - val_accuracy: 0.8638\n",
            "Epoch 351/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.8603 - val_accuracy: 0.8525\n",
            "Epoch 352/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 1.2008 - val_accuracy: 0.8623\n",
            "Epoch 353/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.8381 - val_accuracy: 0.8608\n",
            "Epoch 354/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 1.2243 - val_accuracy: 0.8500\n",
            "Epoch 355/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.9898 - val_accuracy: 0.8522\n",
            "Epoch 356/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 1.1504 - val_accuracy: 0.8607\n",
            "Epoch 357/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 1.1213 - val_accuracy: 0.8622\n",
            "Epoch 358/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 1.0375 - val_accuracy: 0.8670\n",
            "Epoch 359/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 1.1982 - val_accuracy: 0.8623\n",
            "Epoch 360/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 1.1152 - val_accuracy: 0.8663\n",
            "Epoch 361/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.9651 - val_accuracy: 0.8668\n",
            "Epoch 362/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 1.3251 - val_accuracy: 0.8620\n",
            "Epoch 363/400\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.9976 - val_accuracy: 0.8575\n",
            "Epoch 364/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 1.0251 - val_accuracy: 0.8682\n",
            "Epoch 365/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 0.8939 - val_accuracy: 0.8622\n",
            "Epoch 366/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0187 - accuracy: 0.9949 - val_loss: 0.7839 - val_accuracy: 0.8568\n",
            "Epoch 367/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.8856 - val_accuracy: 0.8598\n",
            "Epoch 368/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.7807 - val_accuracy: 0.8642\n",
            "Epoch 369/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 1.0133 - val_accuracy: 0.8602\n",
            "Epoch 370/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.8629 - val_accuracy: 0.8505\n",
            "Epoch 371/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0200 - accuracy: 0.9945 - val_loss: 0.9185 - val_accuracy: 0.8640\n",
            "Epoch 372/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.9982 - val_accuracy: 0.8638\n",
            "Epoch 373/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 1.2631 - val_accuracy: 0.8665\n",
            "Epoch 374/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0181 - accuracy: 0.9946 - val_loss: 1.2210 - val_accuracy: 0.8670\n",
            "Epoch 375/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.9476 - val_accuracy: 0.8638\n",
            "Epoch 376/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 0.9169 - val_accuracy: 0.8453\n",
            "Epoch 377/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.9435 - val_accuracy: 0.8657\n",
            "Epoch 378/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 1.0886 - val_accuracy: 0.8685\n",
            "Epoch 379/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0178 - accuracy: 0.9952 - val_loss: 1.0929 - val_accuracy: 0.8688\n",
            "Epoch 380/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 1.0517 - val_accuracy: 0.8678\n",
            "Epoch 381/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.9071 - val_accuracy: 0.8543\n",
            "Epoch 382/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 1.1568 - val_accuracy: 0.8683\n",
            "Epoch 383/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 1.1500 - val_accuracy: 0.8645\n",
            "Epoch 384/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 1.1892 - val_accuracy: 0.8673\n",
            "Epoch 385/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.8875 - val_accuracy: 0.8518\n",
            "Epoch 386/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 1.1807 - val_accuracy: 0.8652\n",
            "Epoch 387/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 1.0515 - val_accuracy: 0.8653\n",
            "Epoch 388/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 1.0039 - val_accuracy: 0.8628\n",
            "Epoch 389/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.8753 - val_accuracy: 0.8653\n",
            "Epoch 390/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 1.2336 - val_accuracy: 0.8680\n",
            "Epoch 391/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 1.2132 - val_accuracy: 0.8638\n",
            "Epoch 392/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 1.0500 - val_accuracy: 0.8520\n",
            "Epoch 393/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0168 - accuracy: 0.9950 - val_loss: 1.0870 - val_accuracy: 0.8645\n",
            "Epoch 394/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 1.0520 - val_accuracy: 0.8625\n",
            "Epoch 395/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.9946 - val_accuracy: 0.8577\n",
            "Epoch 396/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 1.0672 - val_accuracy: 0.8640\n",
            "Epoch 397/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 1.0079 - val_accuracy: 0.8627\n",
            "Epoch 398/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 1.1648 - val_accuracy: 0.8633\n",
            "Epoch 399/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 1.2638 - val_accuracy: 0.8602\n",
            "Epoch 400/400\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 1.0896 - val_accuracy: 0.8625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUjjINjl5ogl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}